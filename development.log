05/03/2022 12:23:39 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=[], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type=None, eval_bs=16, log_filepath='development.log', lr=3e-05, max_epochs=100, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='development.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=16, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 12:23:40 - INFO - data -  Load 14986 sentences from data/train.txt
05/03/2022 12:23:40 - INFO - data -  Load 3465 sentences from data/dev.txt
05/03/2022 12:23:40 - INFO - data -  Load 3683 sentences from data/test.txt
05/03/2022 12:23:56 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=[], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=16, log_filepath='development.log', lr=3e-05, max_epochs=100, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='development.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=16, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 12:23:57 - INFO - data -  Load 14986 sentences from data/train.txt
05/03/2022 12:23:57 - INFO - data -  Load 3465 sentences from data/dev.txt
05/03/2022 12:23:57 - INFO - data -  Load 3683 sentences from data/test.txt
05/03/2022 12:24:06 - INFO - train -  # sentences in training set: 14986
05/03/2022 12:24:06 - INFO - train -  # sentences in development set: 3465
05/03/2022 12:24:06 - INFO - train -  No data augmentation used
05/03/2022 12:24:06 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:24:06 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:24:10 - INFO - train -  epoch 1/100 - batch 1/937 - loss 29.580047607421875 - samples/second: 4.57487997298246
05/03/2022 12:24:29 - INFO - train -  epoch 1/100 - batch 94/937 - loss 8.397705724898804 - samples/second: 66.11043051977268
05/03/2022 12:24:48 - INFO - train -  epoch 1/100 - batch 187/937 - loss 5.959057838521539 - samples/second: 70.7343225778291
05/03/2022 12:25:08 - INFO - train -  epoch 1/100 - batch 280/937 - loss 4.979322711910521 - samples/second: 72.85762461465256
05/03/2022 12:25:27 - INFO - train -  epoch 1/100 - batch 373/937 - loss 4.3803772101773015 - samples/second: 74.2088333214334
05/03/2022 12:25:46 - INFO - train -  epoch 1/100 - batch 466/937 - loss 4.006385237682019 - samples/second: 74.54580444348643
05/03/2022 12:26:05 - INFO - train -  epoch 1/100 - batch 559/937 - loss 3.724454934940355 - samples/second: 74.96883497670308
05/03/2022 12:26:24 - INFO - train -  epoch 1/100 - batch 652/937 - loss 3.510365512701997 - samples/second: 75.64730673357008
05/03/2022 12:26:44 - INFO - train -  epoch 1/100 - batch 745/937 - loss 3.3497717960968916 - samples/second: 75.53123832880608
05/03/2022 12:27:03 - INFO - train -  epoch 1/100 - batch 838/937 - loss 3.2156531258457317 - samples/second: 76.01767228191589
05/03/2022 12:27:21 - INFO - train -  epoch 1/100 - batch 931/937 - loss 3.1011640701270897 - samples/second: 76.48052779262443
05/03/2022 12:27:33 - INFO - train -  Finish evaluation: 10.435316562652588 s
05/03/2022 12:27:34 - INFO - train -  micro-avg: acc 0.8684251599812705 - micro-avg-f1-score 0.929579817893242
05/03/2022 12:27:34 - INFO - train -  New best model found
05/03/2022 12:27:34 - INFO - train -  No data augmentation used
05/03/2022 12:27:34 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:27:34 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:27:34 - INFO - train -  epoch 2/100 - batch 1/937 - loss 1.2347710132598877 - samples/second: 61.56110072487566
05/03/2022 12:27:52 - INFO - train -  epoch 2/100 - batch 94/937 - loss 1.8990836676130904 - samples/second: 83.95396325446393
05/03/2022 12:28:09 - INFO - train -  epoch 2/100 - batch 187/937 - loss 1.743016177001484 - samples/second: 84.94993771158482
05/03/2022 12:28:28 - INFO - train -  epoch 2/100 - batch 280/937 - loss 1.7778456841196333 - samples/second: 83.83428500801288
05/03/2022 12:28:45 - INFO - train -  epoch 2/100 - batch 373/937 - loss 1.7619933979760545 - samples/second: 83.71347202243867
05/03/2022 12:29:03 - INFO - train -  epoch 2/100 - batch 466/937 - loss 1.738597215884745 - samples/second: 83.65237908299945
05/03/2022 12:29:20 - INFO - train -  epoch 2/100 - batch 559/937 - loss 1.7240775086798694 - samples/second: 84.23397214407206
05/03/2022 12:29:39 - INFO - train -  epoch 2/100 - batch 652/937 - loss 1.6883147591096492 - samples/second: 83.77673241164447
05/03/2022 12:29:56 - INFO - train -  epoch 2/100 - batch 745/937 - loss 1.6622873153862536 - samples/second: 84.08095920750493
05/03/2022 12:30:14 - INFO - train -  epoch 2/100 - batch 838/937 - loss 1.6250726304290404 - samples/second: 83.6727860366852
05/03/2022 12:30:33 - INFO - train -  epoch 2/100 - batch 931/937 - loss 1.59947789906175 - samples/second: 83.19516249450389
05/03/2022 12:30:42 - INFO - train -  Finish evaluation: 6.850264072418213 s
05/03/2022 12:30:42 - INFO - train -  micro-avg: acc 0.8838750394446198 - micro-avg-f1-score 0.9383584589614741
05/03/2022 12:30:42 - INFO - train -  New best model found
05/03/2022 12:30:43 - INFO - train -  No data augmentation used
05/03/2022 12:30:43 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:30:43 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:30:43 - INFO - train -  epoch 3/100 - batch 1/937 - loss 1.2420717477798462 - samples/second: 58.235366500256426
05/03/2022 12:31:04 - INFO - train -  epoch 3/100 - batch 94/937 - loss 1.1715313614682947 - samples/second: 73.34956176187319
05/03/2022 12:31:23 - INFO - train -  epoch 3/100 - batch 187/937 - loss 1.1669728089781368 - samples/second: 74.16729660678654
05/03/2022 12:31:43 - INFO - train -  epoch 3/100 - batch 280/937 - loss 1.1512250216943878 - samples/second: 74.51361127514062
05/03/2022 12:32:02 - INFO - train -  epoch 3/100 - batch 373/937 - loss 1.1355704699540585 - samples/second: 75.80535606334583
05/03/2022 12:32:21 - INFO - train -  epoch 3/100 - batch 466/937 - loss 1.120141336270668 - samples/second: 76.21404619350392
05/03/2022 12:32:41 - INFO - train -  epoch 3/100 - batch 559/937 - loss 1.1063885740495965 - samples/second: 75.94818463357281
05/03/2022 12:33:00 - INFO - train -  epoch 3/100 - batch 652/937 - loss 1.0959278989149017 - samples/second: 76.08871371915649
05/03/2022 12:33:19 - INFO - train -  epoch 3/100 - batch 745/937 - loss 1.0744236356460009 - samples/second: 76.56665936572197
05/03/2022 12:33:38 - INFO - train -  epoch 3/100 - batch 838/937 - loss 1.0549622842406317 - samples/second: 76.4786263940088
05/03/2022 12:33:59 - INFO - train -  epoch 3/100 - batch 931/937 - loss 1.0470969958028784 - samples/second: 76.09565324831642
05/03/2022 12:34:11 - INFO - train -  Finish evaluation: 9.514284610748291 s
05/03/2022 12:34:11 - INFO - train -  micro-avg: acc 0.8879556259904913 - micro-avg-f1-score 0.9406530680768908
05/03/2022 12:34:11 - INFO - train -  New best model found
05/03/2022 12:34:12 - INFO - train -  No data augmentation used
05/03/2022 12:34:12 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:34:12 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:34:12 - INFO - train -  epoch 4/100 - batch 1/937 - loss 0.5304055213928223 - samples/second: 61.561608976717004
05/03/2022 12:34:34 - INFO - train -  epoch 4/100 - batch 94/937 - loss 0.7998474769769831 - samples/second: 68.87005445751717
05/03/2022 12:34:54 - INFO - train -  epoch 4/100 - batch 187/937 - loss 0.815384357848907 - samples/second: 71.44146568821499
05/03/2022 12:35:15 - INFO - train -  epoch 4/100 - batch 280/937 - loss 0.8082766717033727 - samples/second: 71.73461587923
05/03/2022 12:35:34 - INFO - train -  epoch 4/100 - batch 373/937 - loss 0.7928294088821309 - samples/second: 73.01616179182146
05/03/2022 12:35:54 - INFO - train -  epoch 4/100 - batch 466/937 - loss 0.791273761524663 - samples/second: 72.8911000475175
05/03/2022 12:36:13 - INFO - train -  epoch 4/100 - batch 559/937 - loss 0.7800804072714449 - samples/second: 73.8447713599445
05/03/2022 12:36:34 - INFO - train -  epoch 4/100 - batch 652/937 - loss 0.7853349606317976 - samples/second: 73.71495322018724
05/03/2022 12:36:56 - INFO - train -  epoch 4/100 - batch 745/937 - loss 0.7854700704148951 - samples/second: 72.87782519878229
05/03/2022 12:37:15 - INFO - train -  epoch 4/100 - batch 838/937 - loss 0.7840128915477766 - samples/second: 73.15911513945262
05/03/2022 12:37:35 - INFO - train -  epoch 4/100 - batch 931/937 - loss 0.7825510927609035 - samples/second: 73.37957776923463
05/03/2022 12:37:45 - INFO - train -  Finish evaluation: 7.32444167137146 s
05/03/2022 12:37:45 - INFO - train -  micro-avg: acc 0.8966613672496025 - micro-avg-f1-score 0.9455155071248954
05/03/2022 12:37:45 - INFO - train -  New best model found
05/03/2022 12:37:46 - INFO - train -  No data augmentation used
05/03/2022 12:37:46 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:37:46 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:37:46 - INFO - train -  epoch 5/100 - batch 1/937 - loss 1.006522297859192 - samples/second: 101.44661604579763
05/03/2022 12:38:05 - INFO - train -  epoch 5/100 - batch 94/937 - loss 0.6720398379133102 - samples/second: 80.34085801832106
05/03/2022 12:38:25 - INFO - train -  epoch 5/100 - batch 187/937 - loss 0.7094537046025781 - samples/second: 76.96509375202427
05/03/2022 12:38:44 - INFO - train -  epoch 5/100 - batch 280/937 - loss 0.6768667441393648 - samples/second: 76.94065245514949
05/03/2022 12:39:04 - INFO - train -  epoch 5/100 - batch 373/937 - loss 0.6953125413876756 - samples/second: 76.81419456337453
05/03/2022 12:39:25 - INFO - train -  epoch 5/100 - batch 466/937 - loss 0.6966861950097678 - samples/second: 75.26255662534547
05/03/2022 12:39:45 - INFO - train -  epoch 5/100 - batch 559/937 - loss 0.6876992368687458 - samples/second: 75.29432822235596
05/03/2022 12:40:04 - INFO - train -  epoch 5/100 - batch 652/937 - loss 0.6960132824359861 - samples/second: 75.36244968191278
05/03/2022 12:40:23 - INFO - train -  epoch 5/100 - batch 745/937 - loss 0.6967165398717726 - samples/second: 75.70658644664239
05/03/2022 12:40:42 - INFO - train -  epoch 5/100 - batch 838/937 - loss 0.700897611357574 - samples/second: 76.00242005038882
05/03/2022 12:41:04 - INFO - train -  epoch 5/100 - batch 931/937 - loss 0.6985374279520309 - samples/second: 75.27296138779937
05/03/2022 12:41:13 - INFO - train -  Finish evaluation: 7.417194128036499 s
05/03/2022 12:41:14 - INFO - train -  micro-avg: acc 0.8948877209746775 - micro-avg-f1-score 0.9445284921835603
05/03/2022 12:41:14 - INFO - train -  No improvement since last 1 epochs, best score is 0.9455155071248954
05/03/2022 12:41:14 - INFO - train -  No data augmentation used
05/03/2022 12:41:14 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:41:14 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:41:14 - INFO - train -  epoch 6/100 - batch 1/937 - loss 0.9396016001701355 - samples/second: 45.14215141543321
05/03/2022 12:41:33 - INFO - train -  epoch 6/100 - batch 94/937 - loss 0.6636990265960389 - samples/second: 76.03431643668924
05/03/2022 12:41:52 - INFO - train -  epoch 6/100 - batch 187/937 - loss 0.6458057258377738 - samples/second: 76.92327513925542
05/03/2022 12:42:13 - INFO - train -  epoch 6/100 - batch 280/937 - loss 0.6302615104509252 - samples/second: 74.99838949180331
05/03/2022 12:42:36 - INFO - train -  epoch 6/100 - batch 373/937 - loss 0.6385254402502613 - samples/second: 72.32821790188073
05/03/2022 12:42:56 - INFO - train -  epoch 6/100 - batch 466/937 - loss 0.6285446415707278 - samples/second: 72.95555676139578
05/03/2022 12:43:17 - INFO - train -  epoch 6/100 - batch 559/937 - loss 0.6393673962418637 - samples/second: 72.62921313091299
05/03/2022 12:43:36 - INFO - train -  epoch 6/100 - batch 652/937 - loss 0.638962945140944 - samples/second: 72.96994616734945
05/03/2022 12:43:58 - INFO - train -  epoch 6/100 - batch 745/937 - loss 0.659465866920932 - samples/second: 72.62780002569714
05/03/2022 12:44:18 - INFO - train -  epoch 6/100 - batch 838/937 - loss 0.6615098373417638 - samples/second: 72.64050840859463
05/03/2022 12:44:40 - INFO - train -  epoch 6/100 - batch 931/937 - loss 0.6690432924365126 - samples/second: 72.27739321699498
05/03/2022 12:44:51 - INFO - train -  Finish evaluation: 8.607097625732422 s
05/03/2022 12:44:51 - INFO - train -  micro-avg: acc 0.890391345847916 - micro-avg-f1-score 0.9420180089203064
05/03/2022 12:44:51 - INFO - train -  No improvement since last 2 epochs, best score is 0.9455155071248954
05/03/2022 12:44:51 - INFO - train -  No data augmentation used
05/03/2022 12:44:51 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:44:51 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:44:51 - INFO - train -  epoch 7/100 - batch 1/937 - loss 0.9536093473434448 - samples/second: 90.61149142207496
05/03/2022 12:45:12 - INFO - train -  epoch 7/100 - batch 94/937 - loss 0.5640287668781078 - samples/second: 71.9446406229473
05/03/2022 12:45:32 - INFO - train -  epoch 7/100 - batch 187/937 - loss 0.6121834282250328 - samples/second: 73.80512396102208
05/03/2022 12:45:53 - INFO - train -  epoch 7/100 - batch 280/937 - loss 0.6277402085917336 - samples/second: 72.40945320280493
05/03/2022 12:46:12 - INFO - train -  epoch 7/100 - batch 373/937 - loss 0.6091676712355729 - samples/second: 73.3728525443901
05/03/2022 12:46:33 - INFO - train -  epoch 7/100 - batch 466/937 - loss 0.6129575790637553 - samples/second: 72.99477939632492
05/03/2022 12:46:54 - INFO - train -  epoch 7/100 - batch 559/937 - loss 0.6204697483607396 - samples/second: 72.93032737911695
05/03/2022 12:47:15 - INFO - train -  epoch 7/100 - batch 652/937 - loss 0.61548939180429 - samples/second: 72.31239376080538
05/03/2022 12:47:35 - INFO - train -  epoch 7/100 - batch 745/937 - loss 0.6253404255481374 - samples/second: 72.567452556256
05/03/2022 12:47:53 - INFO - train -  epoch 7/100 - batch 838/937 - loss 0.621713697216818 - samples/second: 73.52469860091408
05/03/2022 12:48:12 - INFO - train -  epoch 7/100 - batch 931/937 - loss 0.6272776820861947 - samples/second: 74.03859435315904
05/03/2022 12:48:23 - INFO - train -  Finish evaluation: 8.250472068786621 s
05/03/2022 12:48:23 - INFO - train -  micro-avg: acc 0.8897000476114902 - micro-avg-f1-score 0.9416309733770052
05/03/2022 12:48:23 - INFO - train -  No improvement since last 3 epochs, best score is 0.9455155071248954
05/03/2022 12:48:23 - INFO - train -  No data augmentation used
05/03/2022 12:48:23 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:48:23 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:48:23 - INFO - train -  epoch 8/100 - batch 1/937 - loss 0.4196470081806183 - samples/second: 79.46683023698355
05/03/2022 12:48:43 - INFO - train -  epoch 8/100 - batch 94/937 - loss 0.5743056703755196 - samples/second: 75.3896665813286
05/03/2022 12:49:02 - INFO - train -  epoch 8/100 - batch 187/937 - loss 0.5921417383108547 - samples/second: 76.70097422008183
05/03/2022 12:49:22 - INFO - train -  epoch 8/100 - batch 280/937 - loss 0.6192997669535024 - samples/second: 76.24118601561199
05/03/2022 12:49:41 - INFO - train -  epoch 8/100 - batch 373/937 - loss 0.6173158637160591 - samples/second: 76.60836796706592
05/03/2022 12:50:00 - INFO - train -  epoch 8/100 - batch 466/937 - loss 0.6233138776516198 - samples/second: 76.53933191486297
05/03/2022 12:50:20 - INFO - train -  epoch 8/100 - batch 559/937 - loss 0.6223210438632795 - samples/second: 76.48682057501226
05/03/2022 12:50:40 - INFO - train -  epoch 8/100 - batch 652/937 - loss 0.633689050934066 - samples/second: 76.08686808532872
05/03/2022 12:51:00 - INFO - train -  epoch 8/100 - batch 745/937 - loss 0.6316748008231988 - samples/second: 75.96032766649132
05/03/2022 12:51:19 - INFO - train -  epoch 8/100 - batch 838/937 - loss 0.6307879037674969 - samples/second: 76.00312837484495
05/03/2022 12:51:38 - INFO - train -  epoch 8/100 - batch 931/937 - loss 0.6318830954177039 - samples/second: 76.1816684116342
05/03/2022 12:51:49 - INFO - train -  Finish evaluation: 7.455383539199829 s
05/03/2022 12:51:49 - INFO - train -  micro-avg: acc 0.893698281349459 - micro-avg-f1-score 0.9438655462184875
05/03/2022 12:51:49 - INFO - train -  change lr from 3e-05 to 1.5e-05
05/03/2022 12:51:49 - INFO - train -  No improvement since last 4 epochs, best score is 0.9455155071248954
05/03/2022 12:51:49 - INFO - train -  No data augmentation used
05/03/2022 12:51:49 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:51:49 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:51:49 - INFO - train -  epoch 9/100 - batch 1/937 - loss 0.9456965923309326 - samples/second: 59.298011349076894
05/03/2022 12:52:07 - INFO - train -  epoch 9/100 - batch 94/937 - loss 0.6021802203452333 - samples/second: 80.19828860789194
05/03/2022 12:52:27 - INFO - train -  epoch 9/100 - batch 187/937 - loss 0.6049543094826254 - samples/second: 77.43150849742321
05/03/2022 12:52:47 - INFO - train -  epoch 9/100 - batch 280/937 - loss 0.5939398114170347 - samples/second: 77.17402174004202
05/03/2022 12:53:06 - INFO - train -  epoch 9/100 - batch 373/937 - loss 0.5840494299542169 - samples/second: 77.32557290178435
05/03/2022 12:53:26 - INFO - train -  epoch 9/100 - batch 466/937 - loss 0.5803562619847289 - samples/second: 76.82816443306666
05/03/2022 12:53:46 - INFO - train -  epoch 9/100 - batch 559/937 - loss 0.586013952686663 - samples/second: 76.27111926362632
05/03/2022 12:54:07 - INFO - train -  epoch 9/100 - batch 652/937 - loss 0.5749393751604791 - samples/second: 75.63190530468209
05/03/2022 12:54:26 - INFO - train -  epoch 9/100 - batch 745/937 - loss 0.5810004346522709 - samples/second: 75.91654664818407
05/03/2022 12:54:45 - INFO - train -  epoch 9/100 - batch 838/937 - loss 0.583936100527822 - samples/second: 76.04494464772084
05/03/2022 12:55:05 - INFO - train -  epoch 9/100 - batch 931/937 - loss 0.5770844716246607 - samples/second: 75.93356359408226
05/03/2022 12:55:15 - INFO - train -  Finish evaluation: 7.457895517349243 s
05/03/2022 12:55:15 - INFO - train -  micro-avg: acc 0.9012662285622696 - micro-avg-f1-score 0.9480694655201484
05/03/2022 12:55:15 - INFO - train -  New best model found
05/03/2022 12:55:16 - INFO - train -  No data augmentation used
05/03/2022 12:55:16 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:55:16 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:55:16 - INFO - train -  epoch 10/100 - batch 1/937 - loss 0.09547573328018188 - samples/second: 94.32383800931308
05/03/2022 12:55:35 - INFO - train -  epoch 10/100 - batch 94/937 - loss 0.5628003276726032 - samples/second: 76.29505389880585
05/03/2022 12:55:54 - INFO - train -  epoch 10/100 - batch 187/937 - loss 0.5703017208824821 - samples/second: 77.44535754692485
05/03/2022 12:56:14 - INFO - train -  epoch 10/100 - batch 280/937 - loss 0.5622791784682444 - samples/second: 77.1425332146948
05/03/2022 12:56:33 - INFO - train -  epoch 10/100 - batch 373/937 - loss 0.5703618194478447 - samples/second: 77.3249912631147
05/03/2022 12:56:52 - INFO - train -  epoch 10/100 - batch 466/937 - loss 0.5702710499259536 - samples/second: 77.27659748514388
05/03/2022 12:57:12 - INFO - train -  epoch 10/100 - batch 559/937 - loss 0.5708288781491503 - samples/second: 77.1495550914755
05/03/2022 12:57:31 - INFO - train -  epoch 10/100 - batch 652/937 - loss 0.5742309890184666 - samples/second: 77.1719263690759
05/03/2022 12:57:51 - INFO - train -  epoch 10/100 - batch 745/937 - loss 0.5710942767810502 - samples/second: 76.91425509826836
05/03/2022 12:58:10 - INFO - train -  epoch 10/100 - batch 838/937 - loss 0.5703509814841651 - samples/second: 76.77103925232156
05/03/2022 12:58:30 - INFO - train -  epoch 10/100 - batch 931/937 - loss 0.5729265900930964 - samples/second: 76.54911018152595
05/03/2022 12:58:41 - INFO - train -  Finish evaluation: 7.67759108543396 s
05/03/2022 12:58:41 - INFO - train -  micro-avg: acc 0.8971783835485414 - micro-avg-f1-score 0.9458028737080917
05/03/2022 12:58:41 - INFO - train -  No improvement since last 1 epochs, best score is 0.9480694655201484
05/03/2022 12:58:41 - INFO - train -  No data augmentation used
05/03/2022 12:58:41 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 12:58:41 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 12:58:41 - INFO - train -  epoch 11/100 - batch 1/937 - loss 0.832005500793457 - samples/second: 81.66449937512397
05/03/2022 12:59:00 - INFO - train -  epoch 11/100 - batch 94/937 - loss 0.5940768121087805 - samples/second: 77.07238887227275
05/03/2022 12:59:19 - INFO - train -  epoch 11/100 - batch 187/937 - loss 0.5797952032662967 - samples/second: 77.7338649544734
05/03/2022 12:59:39 - INFO - train -  epoch 11/100 - batch 280/937 - loss 0.5575117191565888 - samples/second: 77.57512697234294
05/03/2022 12:59:58 - INFO - train -  epoch 11/100 - batch 373/937 - loss 0.5580606927580872 - samples/second: 77.76892032842426
05/03/2022 13:00:17 - INFO - train -  epoch 11/100 - batch 466/937 - loss 0.5587817914943838 - samples/second: 77.24187882627443
05/03/2022 13:00:37 - INFO - train -  epoch 11/100 - batch 559/937 - loss 0.5489823072082455 - samples/second: 76.93823686453779
05/03/2022 13:00:56 - INFO - train -  epoch 11/100 - batch 652/937 - loss 0.5441788033085184 - samples/second: 77.12274743481389
05/03/2022 13:01:16 - INFO - train -  epoch 11/100 - batch 745/937 - loss 0.5441861595383426 - samples/second: 77.00626602919854
05/03/2022 13:01:35 - INFO - train -  epoch 11/100 - batch 838/937 - loss 0.5556390027655622 - samples/second: 76.89024818090876
05/03/2022 13:01:54 - INFO - train -  epoch 11/100 - batch 931/937 - loss 0.557583679350055 - samples/second: 77.14737088545077
05/03/2022 13:02:04 - INFO - train -  Finish evaluation: 7.509944200515747 s
05/03/2022 13:02:04 - INFO - train -  micro-avg: acc 0.9019169329073482 - micro-avg-f1-score 0.9484293633462121
05/03/2022 13:02:04 - INFO - train -  New best model found
05/03/2022 13:02:05 - INFO - train -  No data augmentation used
05/03/2022 13:02:05 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:02:05 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 13:02:05 - INFO - train -  epoch 12/100 - batch 1/937 - loss 1.0647693872451782 - samples/second: 91.63358507621241
05/03/2022 13:02:26 - INFO - train -  epoch 12/100 - batch 94/937 - loss 0.6581549861646713 - samples/second: 72.75741283605304
05/03/2022 13:02:45 - INFO - train -  epoch 12/100 - batch 187/937 - loss 0.5630071732927772 - samples/second: 75.31479335083367
05/03/2022 13:03:04 - INFO - train -  epoch 12/100 - batch 280/937 - loss 0.5435929933296783 - samples/second: 75.81225215370165
05/03/2022 13:03:24 - INFO - train -  epoch 12/100 - batch 373/937 - loss 0.5539125464157508 - samples/second: 75.56081452446351
05/03/2022 13:03:44 - INFO - train -  epoch 12/100 - batch 466/937 - loss 0.5606757088728217 - samples/second: 75.6632401736211
05/03/2022 13:04:03 - INFO - train -  epoch 12/100 - batch 559/937 - loss 0.5549309103081606 - samples/second: 75.55294069841784
05/03/2022 13:04:23 - INFO - train -  epoch 12/100 - batch 652/937 - loss 0.5591603910401921 - samples/second: 75.8914833107993
05/03/2022 13:04:42 - INFO - train -  epoch 12/100 - batch 745/937 - loss 0.5565458565950394 - samples/second: 76.1708583646154
05/03/2022 13:05:01 - INFO - train -  epoch 12/100 - batch 838/937 - loss 0.5567643501949197 - samples/second: 76.1274384423449
05/03/2022 13:05:20 - INFO - train -  epoch 12/100 - batch 931/937 - loss 0.5613583604996237 - samples/second: 76.35402327369887
05/03/2022 13:05:30 - INFO - train -  Finish evaluation: 8.122506618499756 s
05/03/2022 13:05:30 - INFO - train -  micro-avg: acc 0.9013273628658244 - micro-avg-f1-score 0.9481032887543107
05/03/2022 13:05:30 - INFO - train -  No improvement since last 1 epochs, best score is 0.9484293633462121
05/03/2022 13:05:30 - INFO - train -  No data augmentation used
05/03/2022 13:05:30 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:05:30 - INFO - train -  # sentences and augmented sentences: 14986
05/03/2022 13:05:31 - INFO - train -  epoch 13/100 - batch 1/937 - loss 0.1871473342180252 - samples/second: 84.44585043104479
05/03/2022 13:05:50 - INFO - train -  epoch 13/100 - batch 94/937 - loss 0.5284727772182607 - samples/second: 78.85386440339276
05/03/2022 13:06:08 - INFO - train -  epoch 13/100 - batch 187/937 - loss 0.5489753458429786 - samples/second: 79.53912990905069
05/03/2022 13:06:29 - INFO - train -  epoch 13/100 - batch 280/937 - loss 0.5278225673362613 - samples/second: 77.01019452759839
05/03/2022 13:06:49 - INFO - train -  epoch 13/100 - batch 373/937 - loss 0.549233826831103 - samples/second: 75.92162635732173
05/03/2022 13:07:13 - INFO - train -  epoch 13/100 - batch 466/937 - loss 0.5446844855763114 - samples/second: 72.54198114003124
05/03/2022 13:07:37 - INFO - train -  epoch 13/100 - batch 559/937 - loss 0.5613250795198681 - samples/second: 70.81711226377752
05/03/2022 13:07:58 - INFO - train -  epoch 13/100 - batch 652/937 - loss 0.5733656829188755 - samples/second: 70.59782644913038
05/03/2022 13:08:07 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=[], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=16, log_filepath='development.log', lr=3e-05, max_epochs=100, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='development.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=16, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 13:08:08 - INFO - data -  Load 14986 sentences from data/train.txt
05/03/2022 13:08:08 - INFO - data -  Load 3465 sentences from data/dev.txt
05/03/2022 13:08:08 - INFO - data -  Load 3683 sentences from data/test.txt
05/03/2022 13:08:14 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:08:14 - INFO - train -  Testing using best model ...
05/03/2022 13:08:28 - INFO - train -  Finish evaluation: 14.350854635238647 s
05/03/2022 13:08:29 - INFO - train -  micro-avg: acc 0.9019169329073482 - micro-avg-f1-score 0.9484293633462121
05/03/2022 13:08:29 - INFO - train -  Class	TP	TP	FN	TN	Precision	Recall	F1
05/03/2022 13:08:29 - INFO - train -  LOC	1779	94	58	1779	0.9498	0.9684	0.9590
05/03/2022 13:08:29 - INFO - train -  MISC	826	81	96	826	0.9107	0.8959	0.9032
05/03/2022 13:08:29 - INFO - train -  ORG	1231	117	110	1231	0.9132	0.9180	0.9156
05/03/2022 13:08:29 - INFO - train -  PER	1810	26	32	1810	0.9858	0.9826	0.9842
05/03/2022 13:08:29 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:08:29 - INFO - train -  Testing using best model ...
05/03/2022 13:08:41 - INFO - train -  Finish evaluation: 12.33305549621582 s
05/03/2022 13:08:41 - INFO - train -  micro-avg: acc 0.8320672377565864 - micro-avg-f1-score 0.9083370092633436
05/03/2022 13:08:41 - INFO - train -  Class	TP	TP	FN	TN	Precision	Recall	F1
05/03/2022 13:08:41 - INFO - train -  LOC	1573	181	95	1573	0.8968	0.9430	0.9193
05/03/2022 13:08:41 - INFO - train -  MISC	567	138	135	567	0.8043	0.8077	0.8060
05/03/2022 13:08:41 - INFO - train -  ORG	1451	178	210	1451	0.8907	0.8736	0.8821
05/03/2022 13:08:41 - INFO - train -  PER	1557	42	60	1557	0.9737	0.9629	0.9683
05/03/2022 13:17:31 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=[], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=16, log_filepath='development.log', lr=3e-05, max_epochs=100, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='development.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=16, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 13:17:32 - INFO - data -  Load 100 sentences from data/train.txt
05/03/2022 13:17:32 - INFO - data -  Load 100 sentences from data/dev.txt
05/03/2022 13:17:32 - INFO - data -  Load 100 sentences from data/test.txt
05/03/2022 13:18:00 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=[], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=16, log_filepath='development.log', lr=3e-05, max_epochs=100, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='development.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=16, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 13:18:01 - INFO - data -  Load 100 sentences from data/train.txt
05/03/2022 13:18:01 - INFO - data -  Load 100 sentences from data/dev.txt
05/03/2022 13:18:01 - INFO - data -  Load 100 sentences from data/test.txt
05/03/2022 13:18:07 - INFO - train -  # sentences in training set: 100
05/03/2022 13:18:07 - INFO - train -  # sentences in development set: 100
05/03/2022 13:18:07 - INFO - train -  No data augmentation used
05/03/2022 13:18:07 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:18:07 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:19:24 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=[], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=16, log_filepath='development.log', lr=3e-05, max_epochs=100, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='development.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=16, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 13:19:25 - INFO - data -  Load 100 sentences from data/train.txt
05/03/2022 13:19:25 - INFO - data -  Load 3465 sentences from data/dev.txt
05/03/2022 13:19:25 - INFO - data -  Load 3683 sentences from data/test.txt
05/03/2022 13:19:30 - INFO - train -  # sentences in training set: 100
05/03/2022 13:19:30 - INFO - train -  # sentences in development set: 3465
05/03/2022 13:19:30 - INFO - train -  No data augmentation used
05/03/2022 13:19:30 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:19:30 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:19:31 - INFO - train -  epoch 1/100 - batch 1/7 - loss 39.067535400390625 - samples/second: 15.367346480792897
05/03/2022 13:19:31 - INFO - train -  epoch 1/100 - batch 2/7 - loss 35.9000186920166 - samples/second: 24.857979672488444
05/03/2022 13:19:32 - INFO - train -  epoch 1/100 - batch 3/7 - loss 31.38364092508952 - samples/second: 31.458322056918135
05/03/2022 13:19:32 - INFO - train -  epoch 1/100 - batch 4/7 - loss 29.968468189239502 - samples/second: 35.47505596428858
05/03/2022 13:19:32 - INFO - train -  epoch 1/100 - batch 5/7 - loss 27.93265266418457 - samples/second: 38.30880352462942
05/03/2022 13:19:32 - INFO - train -  epoch 1/100 - batch 6/7 - loss 26.305109977722168 - samples/second: 41.12565896031806
05/03/2022 13:19:33 - INFO - train -  epoch 1/100 - batch 7/7 - loss 25.8306759425572 - samples/second: 44.51689561204968
05/03/2022 13:19:43 - INFO - train -  Finish evaluation: 10.502809762954712 s
05/03/2022 13:19:43 - INFO - train -  micro-avg: acc 0.03648003251702063 - micro-avg-f1-score 0.0703921568627451
05/03/2022 13:19:43 - INFO - train -  New best model found
05/03/2022 13:19:44 - INFO - train -  No data augmentation used
05/03/2022 13:19:44 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:19:44 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:19:44 - INFO - train -  epoch 2/100 - batch 1/7 - loss 15.518563270568848 - samples/second: 91.12394070529577
05/03/2022 13:19:44 - INFO - train -  epoch 2/100 - batch 2/7 - loss 14.297197818756104 - samples/second: 77.77451036634373
05/03/2022 13:19:45 - INFO - train -  epoch 2/100 - batch 3/7 - loss 15.082444190979004 - samples/second: 71.70963464261227
05/03/2022 13:19:45 - INFO - train -  epoch 2/100 - batch 4/7 - loss 14.840105295181274 - samples/second: 72.3872324062124
05/03/2022 13:19:45 - INFO - train -  epoch 2/100 - batch 5/7 - loss 14.929101753234864 - samples/second: 71.41386305843372
05/03/2022 13:19:45 - INFO - train -  epoch 2/100 - batch 6/7 - loss 14.279055118560791 - samples/second: 72.6662058704951
05/03/2022 13:19:45 - INFO - train -  epoch 2/100 - batch 7/7 - loss 13.131657668522426 - samples/second: 72.2689162402051
05/03/2022 13:19:53 - INFO - train -  Finish evaluation: 7.042713642120361 s
05/03/2022 13:19:53 - INFO - train -  micro-avg: acc 0.0003365303718660609 - micro-avg-f1-score 0.0006728343145500421
05/03/2022 13:19:53 - INFO - train -  No improvement since last 1 epochs, best score is 0.0703921568627451
05/03/2022 13:19:53 - INFO - train -  No data augmentation used
05/03/2022 13:19:53 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:19:53 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:19:53 - INFO - train -  epoch 3/100 - batch 1/7 - loss 14.782855987548828 - samples/second: 72.98201899674397
05/03/2022 13:19:53 - INFO - train -  epoch 3/100 - batch 2/7 - loss 13.966482162475586 - samples/second: 84.22492741109075
05/03/2022 13:19:53 - INFO - train -  epoch 3/100 - batch 3/7 - loss 12.057168006896973 - samples/second: 87.69416246584495
05/03/2022 13:19:53 - INFO - train -  epoch 3/100 - batch 4/7 - loss 11.737711191177368 - samples/second: 88.83208386970809
05/03/2022 13:19:53 - INFO - train -  epoch 3/100 - batch 5/7 - loss 11.462787055969239 - samples/second: 88.89606204046078
05/03/2022 13:19:54 - INFO - train -  epoch 3/100 - batch 6/7 - loss 11.041009744008383 - samples/second: 88.08455700588816
05/03/2022 13:19:54 - INFO - train -  epoch 3/100 - batch 7/7 - loss 10.98723942892892 - samples/second: 92.98950329339688
05/03/2022 13:20:01 - INFO - train -  Finish evaluation: 6.909785509109497 s
05/03/2022 13:20:01 - INFO - train -  micro-avg: acc 0.04754024371897096 - micro-avg-f1-score 0.09076547465173057
05/03/2022 13:20:01 - INFO - train -  New best model found
05/03/2022 13:20:01 - INFO - train -  No data augmentation used
05/03/2022 13:20:01 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:20:01 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:20:02 - INFO - train -  epoch 4/100 - batch 1/7 - loss 12.600591659545898 - samples/second: 81.66579129905689
05/03/2022 13:20:02 - INFO - train -  epoch 4/100 - batch 2/7 - loss 9.831504821777344 - samples/second: 81.35689745050735
05/03/2022 13:20:02 - INFO - train -  epoch 4/100 - batch 3/7 - loss 8.512868245442709 - samples/second: 79.06375121103149
05/03/2022 13:20:02 - INFO - train -  epoch 4/100 - batch 4/7 - loss 9.27151346206665 - samples/second: 73.60393262894205
05/03/2022 13:20:03 - INFO - train -  epoch 4/100 - batch 5/7 - loss 8.568011569976807 - samples/second: 70.24646448405919
05/03/2022 13:20:03 - INFO - train -  epoch 4/100 - batch 6/7 - loss 8.651811520258585 - samples/second: 69.67028024136023
05/03/2022 13:20:03 - INFO - train -  epoch 4/100 - batch 7/7 - loss 8.45574460710798 - samples/second: 73.98482322372469
05/03/2022 13:20:10 - INFO - train -  Finish evaluation: 6.845303297042847 s
05/03/2022 13:20:10 - INFO - train -  micro-avg: acc 0.06621573513705944 - micro-avg-f1-score 0.12420701168614358
05/03/2022 13:20:10 - INFO - train -  New best model found
05/03/2022 13:20:11 - INFO - train -  No data augmentation used
05/03/2022 13:20:11 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:20:11 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:20:11 - INFO - train -  epoch 5/100 - batch 1/7 - loss 6.087653160095215 - samples/second: 84.6662797680627
05/03/2022 13:20:11 - INFO - train -  epoch 5/100 - batch 2/7 - loss 6.635073661804199 - samples/second: 86.48238943378914
05/03/2022 13:20:11 - INFO - train -  epoch 5/100 - batch 3/7 - loss 7.552247683207194 - samples/second: 78.6780826655568
05/03/2022 13:20:11 - INFO - train -  epoch 5/100 - batch 4/7 - loss 7.348390817642212 - samples/second: 82.65987245455693
05/03/2022 13:20:12 - INFO - train -  epoch 5/100 - batch 5/7 - loss 7.112913131713867 - samples/second: 80.3560969289825
05/03/2022 13:20:12 - INFO - train -  epoch 5/100 - batch 6/7 - loss 6.802299976348877 - samples/second: 74.891264658224
05/03/2022 13:20:12 - INFO - train -  epoch 5/100 - batch 7/7 - loss 7.586594581604004 - samples/second: 73.28065498043742
05/03/2022 13:20:19 - INFO - train -  Finish evaluation: 6.8968894481658936 s
05/03/2022 13:20:19 - INFO - train -  micro-avg: acc 0.1703080229226361 - micro-avg-f1-score 0.29104820198928844
05/03/2022 13:20:19 - INFO - train -  New best model found
05/03/2022 13:20:20 - INFO - train -  No data augmentation used
05/03/2022 13:20:20 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:20:20 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:20:20 - INFO - train -  epoch 6/100 - batch 1/7 - loss 3.519402503967285 - samples/second: 97.07014742299059
05/03/2022 13:20:20 - INFO - train -  epoch 6/100 - batch 2/7 - loss 4.375417232513428 - samples/second: 102.41805005612409
05/03/2022 13:20:20 - INFO - train -  epoch 6/100 - batch 3/7 - loss 5.332200368245442 - samples/second: 97.05812063796317
05/03/2022 13:20:21 - INFO - train -  epoch 6/100 - batch 4/7 - loss 5.5517802238464355 - samples/second: 86.24709420382985
05/03/2022 13:20:21 - INFO - train -  epoch 6/100 - batch 5/7 - loss 5.739666366577149 - samples/second: 84.88633816577642
05/03/2022 13:20:21 - INFO - train -  epoch 6/100 - batch 6/7 - loss 5.671813885370891 - samples/second: 82.39335276189993
05/03/2022 13:20:21 - INFO - train -  epoch 6/100 - batch 7/7 - loss 6.073672362736294 - samples/second: 82.61988598660211
05/03/2022 13:20:28 - INFO - train -  Finish evaluation: 6.897879362106323 s
05/03/2022 13:20:28 - INFO - train -  micro-avg: acc 0.18204859290333858 - micro-avg-f1-score 0.30802218114602586
05/03/2022 13:20:28 - INFO - train -  New best model found
05/03/2022 13:20:29 - INFO - train -  No data augmentation used
05/03/2022 13:20:29 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:20:29 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:20:29 - INFO - train -  epoch 7/100 - batch 1/7 - loss 2.596554756164551 - samples/second: 66.51046930763917
05/03/2022 13:20:29 - INFO - train -  epoch 7/100 - batch 2/7 - loss 2.9719783067703247 - samples/second: 69.06285948336279
05/03/2022 13:20:30 - INFO - train -  epoch 7/100 - batch 3/7 - loss 4.1308402220408125 - samples/second: 66.77924166315069
05/03/2022 13:20:30 - INFO - train -  epoch 7/100 - batch 4/7 - loss 4.651441514492035 - samples/second: 67.02396139690048
05/03/2022 13:20:30 - INFO - train -  epoch 7/100 - batch 5/7 - loss 4.616905164718628 - samples/second: 64.61509605965448
05/03/2022 13:20:30 - INFO - train -  epoch 7/100 - batch 6/7 - loss 4.73035713036855 - samples/second: 65.56144987922558
05/03/2022 13:20:31 - INFO - train -  epoch 7/100 - batch 7/7 - loss 5.134585755211966 - samples/second: 67.62348840727773
05/03/2022 13:20:38 - INFO - train -  Finish evaluation: 6.977720260620117 s
05/03/2022 13:20:38 - INFO - train -  micro-avg: acc 0.31173917645813487 - micro-avg-f1-score 0.4753066494512589
05/03/2022 13:20:38 - INFO - train -  New best model found
05/03/2022 13:20:38 - INFO - train -  No data augmentation used
05/03/2022 13:20:38 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:20:38 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:20:39 - INFO - train -  epoch 8/100 - batch 1/7 - loss 4.0270795822143555 - samples/second: 71.21036753915257
05/03/2022 13:20:39 - INFO - train -  epoch 8/100 - batch 2/7 - loss 4.5588250160217285 - samples/second: 80.14874406428251
05/03/2022 13:20:39 - INFO - train -  epoch 8/100 - batch 3/7 - loss 4.275863806406657 - samples/second: 80.85041636681402
05/03/2022 13:20:39 - INFO - train -  epoch 8/100 - batch 4/7 - loss 4.18343186378479 - samples/second: 79.43169924100076
05/03/2022 13:20:39 - INFO - train -  epoch 8/100 - batch 5/7 - loss 4.0931250095367435 - samples/second: 80.54675259425906
05/03/2022 13:20:40 - INFO - train -  epoch 8/100 - batch 6/7 - loss 4.08298138777415 - samples/second: 82.65534195824178
05/03/2022 13:20:40 - INFO - train -  epoch 8/100 - batch 7/7 - loss 4.380132641111102 - samples/second: 86.69418195917736
05/03/2022 13:20:47 - INFO - train -  Finish evaluation: 7.552104473114014 s
05/03/2022 13:20:47 - INFO - train -  micro-avg: acc 0.4202981651376147 - micro-avg-f1-score 0.5918449737585789
05/03/2022 13:20:47 - INFO - train -  New best model found
05/03/2022 13:20:48 - INFO - train -  No data augmentation used
05/03/2022 13:20:48 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:20:48 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:20:48 - INFO - train -  epoch 9/100 - batch 1/7 - loss 4.565343856811523 - samples/second: 73.20421277686573
05/03/2022 13:20:48 - INFO - train -  epoch 9/100 - batch 2/7 - loss 4.236956596374512 - samples/second: 82.22190857053242
05/03/2022 13:20:49 - INFO - train -  epoch 9/100 - batch 3/7 - loss 3.7761313915252686 - samples/second: 79.60634346727022
05/03/2022 13:20:49 - INFO - train -  epoch 9/100 - batch 4/7 - loss 3.6838948726654053 - samples/second: 77.7931052070736
05/03/2022 13:20:49 - INFO - train -  epoch 9/100 - batch 5/7 - loss 3.5180304527282713 - samples/second: 74.64861276480629
05/03/2022 13:20:49 - INFO - train -  epoch 9/100 - batch 6/7 - loss 3.468175530433655 - samples/second: 75.76273628040175
05/03/2022 13:20:50 - INFO - train -  epoch 9/100 - batch 7/7 - loss 3.4158854825156078 - samples/second: 78.5506399936325
05/03/2022 13:20:57 - INFO - train -  Finish evaluation: 7.30757474899292 s
05/03/2022 13:20:57 - INFO - train -  micro-avg: acc 0.4382616693492757 - micro-avg-f1-score 0.6094324540367705
05/03/2022 13:20:57 - INFO - train -  New best model found
05/03/2022 13:20:58 - INFO - train -  No data augmentation used
05/03/2022 13:20:58 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:20:58 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:20:58 - INFO - train -  epoch 10/100 - batch 1/7 - loss 3.442634105682373 - samples/second: 91.9101837002179
05/03/2022 13:20:58 - INFO - train -  epoch 10/100 - batch 2/7 - loss 4.886664152145386 - samples/second: 86.13976545096426
05/03/2022 13:20:58 - INFO - train -  epoch 10/100 - batch 3/7 - loss 3.856475750605265 - samples/second: 93.43714733644161
05/03/2022 13:20:58 - INFO - train -  epoch 10/100 - batch 4/7 - loss 3.758473515510559 - samples/second: 80.71222315966462
05/03/2022 13:20:59 - INFO - train -  epoch 10/100 - batch 5/7 - loss 3.486173915863037 - samples/second: 78.96042969508356
05/03/2022 13:20:59 - INFO - train -  epoch 10/100 - batch 6/7 - loss 3.2143376072247825 - samples/second: 76.51129931747482
05/03/2022 13:20:59 - INFO - train -  epoch 10/100 - batch 7/7 - loss 3.2937159027372087 - samples/second: 77.31312518546034
05/03/2022 13:21:06 - INFO - train -  Finish evaluation: 6.854727745056152 s
05/03/2022 13:21:06 - INFO - train -  micro-avg: acc 0.4758054784602389 - micro-avg-f1-score 0.6448078495502861
05/03/2022 13:21:06 - INFO - train -  New best model found
05/03/2022 13:21:07 - INFO - train -  No data augmentation used
05/03/2022 13:21:07 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:21:07 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:21:07 - INFO - train -  epoch 11/100 - batch 1/7 - loss 4.52807092666626 - samples/second: 90.61283723844231
05/03/2022 13:21:07 - INFO - train -  epoch 11/100 - batch 2/7 - loss 3.638707399368286 - samples/second: 94.60647144030253
05/03/2022 13:21:07 - INFO - train -  epoch 11/100 - batch 3/7 - loss 3.0947967370351157 - samples/second: 87.58299469916626
05/03/2022 13:21:08 - INFO - train -  epoch 11/100 - batch 4/7 - loss 2.9230597615242004 - samples/second: 79.06660009926202
05/03/2022 13:21:08 - INFO - train -  epoch 11/100 - batch 5/7 - loss 2.495924401283264 - samples/second: 73.55068287885162
05/03/2022 13:21:08 - INFO - train -  epoch 11/100 - batch 6/7 - loss 2.4320504864056907 - samples/second: 72.76478591708477
05/03/2022 13:21:08 - INFO - train -  epoch 11/100 - batch 7/7 - loss 2.4225200414657593 - samples/second: 76.84153612391952
05/03/2022 13:21:15 - INFO - train -  Finish evaluation: 7.159271955490112 s
05/03/2022 13:21:15 - INFO - train -  micro-avg: acc 0.48161852470756744 - micro-avg-f1-score 0.6501248690888585
05/03/2022 13:21:15 - INFO - train -  New best model found
05/03/2022 13:21:16 - INFO - train -  No data augmentation used
05/03/2022 13:21:16 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:21:16 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:21:16 - INFO - train -  epoch 12/100 - batch 1/7 - loss 2.2178797721862793 - samples/second: 50.08968975364502
05/03/2022 13:21:17 - INFO - train -  epoch 12/100 - batch 2/7 - loss 2.3711400032043457 - samples/second: 65.63143477185086
05/03/2022 13:21:17 - INFO - train -  epoch 12/100 - batch 3/7 - loss 2.6123655637105307 - samples/second: 64.3869692614418
05/03/2022 13:21:17 - INFO - train -  epoch 12/100 - batch 4/7 - loss 2.446594625711441 - samples/second: 66.37434886190692
05/03/2022 13:21:17 - INFO - train -  epoch 12/100 - batch 5/7 - loss 2.3242446184158325 - samples/second: 65.2994425662658
05/03/2022 13:21:18 - INFO - train -  epoch 12/100 - batch 6/7 - loss 2.2935707767804465 - samples/second: 68.39140807564253
05/03/2022 13:21:18 - INFO - train -  epoch 12/100 - batch 7/7 - loss 2.2924149547304427 - samples/second: 73.40891113663146
05/03/2022 13:21:25 - INFO - train -  Finish evaluation: 6.972813367843628 s
05/03/2022 13:21:25 - INFO - train -  micro-avg: acc 0.4739190116678106 - micro-avg-f1-score 0.6430733410942957
05/03/2022 13:21:25 - INFO - train -  No improvement since last 1 epochs, best score is 0.6501248690888585
05/03/2022 13:21:25 - INFO - train -  No data augmentation used
05/03/2022 13:21:25 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:21:25 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:21:25 - INFO - train -  epoch 13/100 - batch 1/7 - loss 1.761896014213562 - samples/second: 64.13112748845602
05/03/2022 13:21:25 - INFO - train -  epoch 13/100 - batch 2/7 - loss 2.4520244002342224 - samples/second: 66.97120468876226
05/03/2022 13:21:25 - INFO - train -  epoch 13/100 - batch 3/7 - loss 2.319211761156718 - samples/second: 68.6907665600332
05/03/2022 13:21:26 - INFO - train -  epoch 13/100 - batch 4/7 - loss 2.083043158054352 - samples/second: 69.4527915351231
05/03/2022 13:21:26 - INFO - train -  epoch 13/100 - batch 5/7 - loss 1.9032952785491943 - samples/second: 71.68964598538665
05/03/2022 13:21:26 - INFO - train -  epoch 13/100 - batch 6/7 - loss 2.032294273376465 - samples/second: 68.20271043710876
05/03/2022 13:21:26 - INFO - train -  epoch 13/100 - batch 7/7 - loss 2.066286393574306 - samples/second: 70.23876350650427
05/03/2022 13:21:33 - INFO - train -  Finish evaluation: 7.079171419143677 s
05/03/2022 13:21:33 - INFO - train -  micro-avg: acc 0.49994009823888824 - micro-avg-f1-score 0.6666134185303515
05/03/2022 13:21:33 - INFO - train -  New best model found
05/03/2022 13:21:34 - INFO - train -  No data augmentation used
05/03/2022 13:21:34 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:21:34 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:21:34 - INFO - train -  epoch 14/100 - batch 1/7 - loss 1.6404211521148682 - samples/second: 86.25241500568086
05/03/2022 13:21:35 - INFO - train -  epoch 14/100 - batch 2/7 - loss 1.9532661437988281 - samples/second: 89.74988899766227
05/03/2022 13:21:35 - INFO - train -  epoch 14/100 - batch 3/7 - loss 2.226548751195272 - samples/second: 80.58846708397947
05/03/2022 13:21:35 - INFO - train -  epoch 14/100 - batch 4/7 - loss 2.4771928191184998 - samples/second: 75.46431015220749
05/03/2022 13:21:35 - INFO - train -  epoch 14/100 - batch 5/7 - loss 2.433169794082642 - samples/second: 74.95441787320638
05/03/2022 13:21:36 - INFO - train -  epoch 14/100 - batch 6/7 - loss 2.30112357934316 - samples/second: 69.57552509105311
05/03/2022 13:21:36 - INFO - train -  epoch 14/100 - batch 7/7 - loss 2.1163551807403564 - samples/second: 72.68025176195773
05/03/2022 13:21:43 - INFO - train -  Finish evaluation: 6.843321323394775 s
05/03/2022 13:21:43 - INFO - train -  micro-avg: acc 0.49730853927085883 - micro-avg-f1-score 0.6642699566958085
05/03/2022 13:21:43 - INFO - train -  No improvement since last 1 epochs, best score is 0.6666134185303515
05/03/2022 13:21:43 - INFO - train -  No data augmentation used
05/03/2022 13:21:43 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:21:43 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:21:43 - INFO - train -  epoch 15/100 - batch 1/7 - loss 1.773756742477417 - samples/second: 83.78762953529603
05/03/2022 13:21:43 - INFO - train -  epoch 15/100 - batch 2/7 - loss 1.9980005025863647 - samples/second: 92.45122361148613
05/03/2022 13:21:43 - INFO - train -  epoch 15/100 - batch 3/7 - loss 1.9264845848083496 - samples/second: 82.79508230093045
05/03/2022 13:21:43 - INFO - train -  epoch 15/100 - batch 4/7 - loss 1.8646219968795776 - samples/second: 76.22215653520081
05/03/2022 13:21:44 - INFO - train -  epoch 15/100 - batch 5/7 - loss 1.8469377517700196 - samples/second: 80.01133125561853
05/03/2022 13:21:44 - INFO - train -  epoch 15/100 - batch 6/7 - loss 1.9660158157348633 - samples/second: 78.8755439362591
05/03/2022 13:21:44 - INFO - train -  epoch 15/100 - batch 7/7 - loss 2.0195763451712474 - samples/second: 83.3860318355178
05/03/2022 13:21:51 - INFO - train -  Finish evaluation: 6.769416570663452 s
05/03/2022 13:21:51 - INFO - train -  micro-avg: acc 0.4993217412751264 - micro-avg-f1-score 0.6660634972857378
05/03/2022 13:21:51 - INFO - train -  No improvement since last 2 epochs, best score is 0.6666134185303515
05/03/2022 13:21:51 - INFO - train -  No data augmentation used
05/03/2022 13:21:51 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:21:51 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:21:51 - INFO - train -  epoch 16/100 - batch 1/7 - loss 2.1527881622314453 - samples/second: 93.5021965237382
05/03/2022 13:21:51 - INFO - train -  epoch 16/100 - batch 2/7 - loss 1.5496935844421387 - samples/second: 72.40660161722683
05/03/2022 13:21:52 - INFO - train -  epoch 16/100 - batch 3/7 - loss 1.7112619082132976 - samples/second: 71.79187172312324
05/03/2022 13:21:52 - INFO - train -  epoch 16/100 - batch 4/7 - loss 1.8712692260742188 - samples/second: 69.7105669234329
05/03/2022 13:21:52 - INFO - train -  epoch 16/100 - batch 5/7 - loss 2.0630102157592773 - samples/second: 69.91366022073547
05/03/2022 13:21:52 - INFO - train -  epoch 16/100 - batch 6/7 - loss 2.02545028924942 - samples/second: 68.9031125342438
05/03/2022 13:21:52 - INFO - train -  epoch 16/100 - batch 7/7 - loss 1.9031280619757516 - samples/second: 72.07374639007628
05/03/2022 13:22:00 - INFO - train -  Finish evaluation: 7.435048341751099 s
05/03/2022 13:22:00 - INFO - train -  micro-avg: acc 0.5187395559799475 - micro-avg-f1-score 0.6831185161898775
05/03/2022 13:22:00 - INFO - train -  New best model found
05/03/2022 13:22:01 - INFO - train -  No data augmentation used
05/03/2022 13:22:01 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:22:01 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:22:01 - INFO - train -  epoch 17/100 - batch 1/7 - loss 1.8858025074005127 - samples/second: 65.33355530178461
05/03/2022 13:22:01 - INFO - train -  epoch 17/100 - batch 2/7 - loss 1.8539909720420837 - samples/second: 80.05729006675132
05/03/2022 13:22:01 - INFO - train -  epoch 17/100 - batch 3/7 - loss 1.8643738428751628 - samples/second: 82.79266487258276
05/03/2022 13:22:01 - INFO - train -  epoch 17/100 - batch 4/7 - loss 2.0152827501296997 - samples/second: 80.80296703981429
05/03/2022 13:22:02 - INFO - train -  epoch 17/100 - batch 5/7 - loss 2.076734209060669 - samples/second: 76.5905959627593
05/03/2022 13:22:02 - INFO - train -  epoch 17/100 - batch 6/7 - loss 2.1288400888442993 - samples/second: 74.35940136215225
05/03/2022 13:22:02 - INFO - train -  epoch 17/100 - batch 7/7 - loss 2.051711474146162 - samples/second: 80.13352709313725
05/03/2022 13:22:09 - INFO - train -  Finish evaluation: 7.130007982254028 s
05/03/2022 13:22:09 - INFO - train -  micro-avg: acc 0.5530208072198546 - micro-avg-f1-score 0.712187247780468
05/03/2022 13:22:09 - INFO - train -  New best model found
05/03/2022 13:22:10 - INFO - train -  No data augmentation used
05/03/2022 13:22:10 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:22:10 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:22:10 - INFO - train -  epoch 18/100 - batch 1/7 - loss 1.192293643951416 - samples/second: 72.84734039204278
05/03/2022 13:22:10 - INFO - train -  epoch 18/100 - batch 2/7 - loss 1.6714558601379395 - samples/second: 71.22809136582256
05/03/2022 13:22:11 - INFO - train -  epoch 18/100 - batch 3/7 - loss 1.6692839463551838 - samples/second: 74.9531063270234
05/03/2022 13:22:11 - INFO - train -  epoch 18/100 - batch 4/7 - loss 1.4689548015594482 - samples/second: 74.60380468057586
05/03/2022 13:22:11 - INFO - train -  epoch 18/100 - batch 5/7 - loss 1.4987051486968994 - samples/second: 72.85792236651228
05/03/2022 13:22:11 - INFO - train -  epoch 18/100 - batch 6/7 - loss 1.5081517100334167 - samples/second: 72.71418216018195
05/03/2022 13:22:11 - INFO - train -  epoch 18/100 - batch 7/7 - loss 1.4578285387584142 - samples/second: 76.99426806921849
05/03/2022 13:22:18 - INFO - train -  Finish evaluation: 6.89936637878418 s
05/03/2022 13:22:18 - INFO - train -  micro-avg: acc 0.555152300712897 - micro-avg-f1-score 0.7139523253875646
05/03/2022 13:22:18 - INFO - train -  New best model found
05/03/2022 13:22:19 - INFO - train -  No data augmentation used
05/03/2022 13:22:19 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:22:19 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:22:19 - INFO - train -  epoch 19/100 - batch 1/7 - loss 1.1390684843063354 - samples/second: 91.64184379246069
05/03/2022 13:22:20 - INFO - train -  epoch 19/100 - batch 2/7 - loss 1.7718750834465027 - samples/second: 68.83609940630295
05/03/2022 13:22:20 - INFO - train -  epoch 19/100 - batch 3/7 - loss 1.8031315803527832 - samples/second: 77.34236783904463
05/03/2022 13:22:20 - INFO - train -  epoch 19/100 - batch 4/7 - loss 1.7107064723968506 - samples/second: 80.58247550649332
05/03/2022 13:22:20 - INFO - train -  epoch 19/100 - batch 5/7 - loss 1.7177048683166505 - samples/second: 76.28743217453896
05/03/2022 13:22:20 - INFO - train -  epoch 19/100 - batch 6/7 - loss 1.6006818413734436 - samples/second: 79.97271515002735
05/03/2022 13:22:20 - INFO - train -  epoch 19/100 - batch 7/7 - loss 1.45466182913099 - samples/second: 81.22006052057655
05/03/2022 13:22:28 - INFO - train -  Finish evaluation: 7.114631652832031 s
05/03/2022 13:22:28 - INFO - train -  micro-avg: acc 0.5398373983739837 - micro-avg-f1-score 0.7011615628299894
05/03/2022 13:22:28 - INFO - train -  No improvement since last 1 epochs, best score is 0.7139523253875646
05/03/2022 13:22:28 - INFO - train -  No data augmentation used
05/03/2022 13:22:28 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:22:28 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:22:28 - INFO - train -  epoch 20/100 - batch 1/7 - loss 1.5810881853103638 - samples/second: 75.10305889831315
05/03/2022 13:22:28 - INFO - train -  epoch 20/100 - batch 2/7 - loss 1.8464214205741882 - samples/second: 79.8977348828986
05/03/2022 13:22:28 - INFO - train -  epoch 20/100 - batch 3/7 - loss 1.5071329673131306 - samples/second: 76.18605105267042
05/03/2022 13:22:29 - INFO - train -  epoch 20/100 - batch 4/7 - loss 1.5181544125080109 - samples/second: 70.92661307006935
05/03/2022 13:22:29 - INFO - train -  epoch 20/100 - batch 5/7 - loss 1.536419939994812 - samples/second: 70.21058510229827
05/03/2022 13:22:29 - INFO - train -  epoch 20/100 - batch 6/7 - loss 1.535229245821635 - samples/second: 68.24120163221698
05/03/2022 13:22:29 - INFO - train -  epoch 20/100 - batch 7/7 - loss 1.9946324825286865 - samples/second: 72.9057682775001
05/03/2022 13:22:36 - INFO - train -  Finish evaluation: 7.257976055145264 s
05/03/2022 13:22:36 - INFO - train -  micro-avg: acc 0.5275449101796407 - micro-avg-f1-score 0.6907095256762055
05/03/2022 13:22:36 - INFO - train -  No improvement since last 2 epochs, best score is 0.7139523253875646
05/03/2022 13:22:36 - INFO - train -  No data augmentation used
05/03/2022 13:22:36 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:22:36 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:22:37 - INFO - train -  epoch 21/100 - batch 1/7 - loss 2.1491289138793945 - samples/second: 61.79715162889036
05/03/2022 13:22:37 - INFO - train -  epoch 21/100 - batch 2/7 - loss 2.1565810441970825 - samples/second: 76.05265639165911
05/03/2022 13:22:37 - INFO - train -  epoch 21/100 - batch 3/7 - loss 1.9192624886830647 - samples/second: 83.11724547931632
05/03/2022 13:22:37 - INFO - train -  epoch 21/100 - batch 4/7 - loss 1.8169268071651459 - samples/second: 75.39963861266136
05/03/2022 13:22:38 - INFO - train -  epoch 21/100 - batch 5/7 - loss 1.845822286605835 - samples/second: 70.63885722898998
05/03/2022 13:22:38 - INFO - train -  epoch 21/100 - batch 6/7 - loss 1.8248368700345357 - samples/second: 72.10361349688748
05/03/2022 13:22:38 - INFO - train -  epoch 21/100 - batch 7/7 - loss 1.7240349565233504 - samples/second: 75.36147280214443
05/03/2022 13:22:45 - INFO - train -  Finish evaluation: 7.1731603145599365 s
05/03/2022 13:22:45 - INFO - train -  micro-avg: acc 0.5544441630792606 - micro-avg-f1-score 0.7133664576036491
05/03/2022 13:22:45 - INFO - train -  No improvement since last 3 epochs, best score is 0.7139523253875646
05/03/2022 13:22:45 - INFO - train -  No data augmentation used
05/03/2022 13:22:45 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:22:45 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:22:45 - INFO - train -  epoch 22/100 - batch 1/7 - loss 1.3082572221755981 - samples/second: 86.24975452269445
05/03/2022 13:22:46 - INFO - train -  epoch 22/100 - batch 2/7 - loss 1.7209449410438538 - samples/second: 83.56919605471005
05/03/2022 13:22:46 - INFO - train -  epoch 22/100 - batch 3/7 - loss 1.7176342805226643 - samples/second: 80.24346149998385
05/03/2022 13:22:46 - INFO - train -  epoch 22/100 - batch 4/7 - loss 1.6466836333274841 - samples/second: 81.87290209336975
05/03/2022 13:22:46 - INFO - train -  epoch 22/100 - batch 5/7 - loss 1.5537006378173828 - samples/second: 88.04012105164006
05/03/2022 13:22:46 - INFO - train -  epoch 22/100 - batch 6/7 - loss 1.34359110891819 - samples/second: 87.14431516883442
05/03/2022 13:22:47 - INFO - train -  epoch 22/100 - batch 7/7 - loss 1.238145193883351 - samples/second: 86.25114808855099
05/03/2022 13:22:54 - INFO - train -  Finish evaluation: 6.995591402053833 s
05/03/2022 13:22:54 - INFO - train -  micro-avg: acc 0.5596258768511302 - micro-avg-f1-score 0.7176411794102949
05/03/2022 13:22:54 - INFO - train -  New best model found
05/03/2022 13:22:54 - INFO - train -  No data augmentation used
05/03/2022 13:22:54 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:22:54 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:22:55 - INFO - train -  epoch 23/100 - batch 1/7 - loss 2.004465341567993 - samples/second: 82.71983374400176
05/03/2022 13:22:55 - INFO - train -  epoch 23/100 - batch 2/7 - loss 1.6211406588554382 - samples/second: 76.17307960794774
05/03/2022 13:22:55 - INFO - train -  epoch 23/100 - batch 3/7 - loss 1.7952684958775837 - samples/second: 75.25949207861092
05/03/2022 13:22:55 - INFO - train -  epoch 23/100 - batch 4/7 - loss 1.812717616558075 - samples/second: 71.72742901819616
05/03/2022 13:22:55 - INFO - train -  epoch 23/100 - batch 5/7 - loss 1.708919596672058 - samples/second: 76.91489820150646
05/03/2022 13:22:56 - INFO - train -  epoch 23/100 - batch 6/7 - loss 1.7722143928209941 - samples/second: 76.32040632120923
05/03/2022 13:22:56 - INFO - train -  epoch 23/100 - batch 7/7 - loss 1.5221998010362898 - samples/second: 79.06382218123034
05/03/2022 13:23:03 - INFO - train -  Finish evaluation: 6.830918550491333 s
05/03/2022 13:23:03 - INFO - train -  micro-avg: acc 0.5584716325742957 - micro-avg-f1-score 0.716691431401684
05/03/2022 13:23:03 - INFO - train -  No improvement since last 1 epochs, best score is 0.7176411794102949
05/03/2022 13:23:03 - INFO - train -  No data augmentation used
05/03/2022 13:23:03 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:23:03 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:23:03 - INFO - train -  epoch 24/100 - batch 1/7 - loss 2.0760903358459473 - samples/second: 56.19886578703192
05/03/2022 13:23:03 - INFO - train -  epoch 24/100 - batch 2/7 - loss 1.5772980451583862 - samples/second: 68.79379604974847
05/03/2022 13:23:03 - INFO - train -  epoch 24/100 - batch 3/7 - loss 1.6768761078516643 - samples/second: 72.22926911697121
05/03/2022 13:23:04 - INFO - train -  epoch 24/100 - batch 4/7 - loss 1.6324715912342072 - samples/second: 67.84671397616934
05/03/2022 13:23:04 - INFO - train -  epoch 24/100 - batch 5/7 - loss 1.6799294710159303 - samples/second: 72.60434495296596
05/03/2022 13:23:04 - INFO - train -  epoch 24/100 - batch 6/7 - loss 1.8920928835868835 - samples/second: 69.6169540018237
05/03/2022 13:23:04 - INFO - train -  epoch 24/100 - batch 7/7 - loss 1.820128185408456 - samples/second: 69.04991633378528
05/03/2022 13:23:11 - INFO - train -  Finish evaluation: 6.933096647262573 s
05/03/2022 13:23:11 - INFO - train -  micro-avg: acc 0.5470728343988969 - micro-avg-f1-score 0.7072360424600924
05/03/2022 13:23:11 - INFO - train -  No improvement since last 2 epochs, best score is 0.7176411794102949
05/03/2022 13:23:11 - INFO - train -  No data augmentation used
05/03/2022 13:23:11 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:23:11 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:23:12 - INFO - train -  epoch 25/100 - batch 1/7 - loss 0.9060755968093872 - samples/second: 66.94605120347315
05/03/2022 13:23:12 - INFO - train -  epoch 25/100 - batch 2/7 - loss 1.258122980594635 - samples/second: 77.83779169368205
05/03/2022 13:23:12 - INFO - train -  epoch 25/100 - batch 3/7 - loss 1.1503597100575764 - samples/second: 84.75181983966215
05/03/2022 13:23:12 - INFO - train -  epoch 25/100 - batch 4/7 - loss 1.1931910514831543 - samples/second: 81.10878835426806
05/03/2022 13:23:12 - INFO - train -  epoch 25/100 - batch 5/7 - loss 1.275637435913086 - samples/second: 81.01559615860542
05/03/2022 13:23:12 - INFO - train -  epoch 25/100 - batch 6/7 - loss 1.2738263209660847 - samples/second: 79.71988556381599
05/03/2022 13:23:13 - INFO - train -  epoch 25/100 - batch 7/7 - loss 1.3011138779776437 - samples/second: 84.9262291569984
05/03/2022 13:23:20 - INFO - train -  Finish evaluation: 7.0253517627716064 s
05/03/2022 13:23:20 - INFO - train -  micro-avg: acc 0.5381255459877698 - micro-avg-f1-score 0.6997160243407708
05/03/2022 13:23:20 - INFO - train -  No improvement since last 3 epochs, best score is 0.7176411794102949
05/03/2022 13:23:20 - INFO - train -  No data augmentation used
05/03/2022 13:23:20 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:23:20 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:23:20 - INFO - train -  epoch 26/100 - batch 1/7 - loss 1.4310457706451416 - samples/second: 64.07571202010432
05/03/2022 13:23:20 - INFO - train -  epoch 26/100 - batch 2/7 - loss 1.2169407606124878 - samples/second: 68.331241580636
05/03/2022 13:23:20 - INFO - train -  epoch 26/100 - batch 3/7 - loss 1.2729713122049968 - samples/second: 69.05430800121557
05/03/2022 13:23:21 - INFO - train -  epoch 26/100 - batch 4/7 - loss 1.3253599405288696 - samples/second: 70.37782604762985
05/03/2022 13:23:21 - INFO - train -  epoch 26/100 - batch 5/7 - loss 1.4321720600128174 - samples/second: 69.47920257935682
05/03/2022 13:23:21 - INFO - train -  epoch 26/100 - batch 6/7 - loss 1.2743043303489685 - samples/second: 73.8448428776098
05/03/2022 13:23:21 - INFO - train -  epoch 26/100 - batch 7/7 - loss 1.4768328836985998 - samples/second: 75.19325619826245
05/03/2022 13:23:28 - INFO - train -  Finish evaluation: 7.027881383895874 s
05/03/2022 13:23:28 - INFO - train -  micro-avg: acc 0.5359860296869153 - micro-avg-f1-score 0.6979048237778139
05/03/2022 13:23:28 - INFO - train -  change lr from 3e-05 to 1.5e-05
05/03/2022 13:23:28 - INFO - train -  No improvement since last 4 epochs, best score is 0.7176411794102949
05/03/2022 13:23:28 - INFO - train -  No data augmentation used
05/03/2022 13:23:28 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:23:28 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:23:28 - INFO - train -  epoch 27/100 - batch 1/7 - loss 1.6069685220718384 - samples/second: 101.94577383484231
05/03/2022 13:23:29 - INFO - train -  epoch 27/100 - batch 2/7 - loss 1.9035152792930603 - samples/second: 92.44893112293396
05/03/2022 13:23:29 - INFO - train -  epoch 27/100 - batch 3/7 - loss 1.9305777152379353 - samples/second: 77.05829744707773
05/03/2022 13:23:29 - INFO - train -  epoch 27/100 - batch 4/7 - loss 1.8015678524971008 - samples/second: 74.5913042028482
05/03/2022 13:23:29 - INFO - train -  epoch 27/100 - batch 5/7 - loss 1.72334885597229 - samples/second: 77.9234370402573
05/03/2022 13:23:30 - INFO - train -  epoch 27/100 - batch 6/7 - loss 1.7154152790705364 - samples/second: 77.64059005996201
05/03/2022 13:23:30 - INFO - train -  epoch 27/100 - batch 7/7 - loss 1.7731634889330183 - samples/second: 80.3045267855525
05/03/2022 13:23:38 - INFO - train -  Finish evaluation: 8.618507146835327 s
05/03/2022 13:23:38 - INFO - train -  micro-avg: acc 0.5369856096945216 - micro-avg-f1-score 0.6987516425755584
05/03/2022 13:23:38 - INFO - train -  No improvement since last 5 epochs, best score is 0.7176411794102949
05/03/2022 13:23:38 - INFO - train -  No data augmentation used
05/03/2022 13:23:38 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:23:38 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:23:39 - INFO - train -  epoch 28/100 - batch 1/7 - loss 1.959338903427124 - samples/second: 64.38672216049845
05/03/2022 13:23:39 - INFO - train -  epoch 28/100 - batch 2/7 - loss 1.5913978219032288 - samples/second: 56.89226486082311
05/03/2022 13:23:39 - INFO - train -  epoch 28/100 - batch 3/7 - loss 1.5564053455988567 - samples/second: 64.13120920258453
05/03/2022 13:23:39 - INFO - train -  epoch 28/100 - batch 4/7 - loss 1.6536156237125397 - samples/second: 63.37526849480009
05/03/2022 13:23:40 - INFO - train -  epoch 28/100 - batch 5/7 - loss 1.5741616487503052 - samples/second: 65.24682403690518
05/03/2022 13:23:40 - INFO - train -  epoch 28/100 - batch 6/7 - loss 1.5424016118049622 - samples/second: 68.12675723429717
05/03/2022 13:23:40 - INFO - train -  epoch 28/100 - batch 7/7 - loss 1.6189803906849451 - samples/second: 67.97293596194828
05/03/2022 13:23:49 - INFO - train -  Finish evaluation: 9.243961572647095 s
05/03/2022 13:23:49 - INFO - train -  micro-avg: acc 0.5363036303630363 - micro-avg-f1-score 0.6981740064446832
05/03/2022 13:23:49 - INFO - train -  No improvement since last 6 epochs, best score is 0.7176411794102949
05/03/2022 13:23:49 - INFO - train -  No data augmentation used
05/03/2022 13:23:49 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:23:49 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:23:50 - INFO - train -  epoch 29/100 - batch 1/7 - loss 1.3888990879058838 - samples/second: 83.57008063260795
05/03/2022 13:23:50 - INFO - train -  epoch 29/100 - batch 2/7 - loss 1.234344244003296 - samples/second: 88.34664698986386
05/03/2022 13:23:50 - INFO - train -  epoch 29/100 - batch 3/7 - loss 1.2165414492289226 - samples/second: 79.96115346502211
05/03/2022 13:23:50 - INFO - train -  epoch 29/100 - batch 4/7 - loss 1.4384442567825317 - samples/second: 76.97603734737301
05/03/2022 13:23:50 - INFO - train -  epoch 29/100 - batch 5/7 - loss 1.3729475736618042 - samples/second: 80.91777332125635
05/03/2022 13:23:51 - INFO - train -  epoch 29/100 - batch 6/7 - loss 1.4307635029157002 - samples/second: 80.17407063824348
05/03/2022 13:23:51 - INFO - train -  epoch 29/100 - batch 7/7 - loss 1.3001941783087594 - samples/second: 82.16819253328492
05/03/2022 13:24:00 - INFO - train -  Finish evaluation: 9.594139099121094 s
05/03/2022 13:24:00 - INFO - train -  micro-avg: acc 0.5424486148346738 - micro-avg-f1-score 0.7033603707995365
05/03/2022 13:24:00 - INFO - train -  No improvement since last 7 epochs, best score is 0.7176411794102949
05/03/2022 13:24:00 - INFO - train -  No data augmentation used
05/03/2022 13:24:00 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:24:00 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:24:01 - INFO - train -  epoch 30/100 - batch 1/7 - loss 2.1299989223480225 - samples/second: 49.09900519970998
05/03/2022 13:24:01 - INFO - train -  epoch 30/100 - batch 2/7 - loss 1.7225631475448608 - samples/second: 59.46278263242677
05/03/2022 13:24:01 - INFO - train -  epoch 30/100 - batch 3/7 - loss 1.3887265125910442 - samples/second: 65.21254830775868
05/03/2022 13:24:01 - INFO - train -  epoch 30/100 - batch 4/7 - loss 1.655929297208786 - samples/second: 66.001750634851
05/03/2022 13:24:02 - INFO - train -  epoch 30/100 - batch 5/7 - loss 1.55503511428833 - samples/second: 67.74107793212494
05/03/2022 13:24:02 - INFO - train -  epoch 30/100 - batch 6/7 - loss 1.5937264362970989 - samples/second: 70.4328976492933
05/03/2022 13:24:02 - INFO - train -  epoch 30/100 - batch 7/7 - loss 1.6062829153878349 - samples/second: 73.91408060558429
05/03/2022 13:24:11 - INFO - train -  Finish evaluation: 9.46815299987793 s
05/03/2022 13:24:12 - INFO - train -  micro-avg: acc 0.5503657128191967 - micro-avg-f1-score 0.7099817910941898
05/03/2022 13:24:12 - INFO - train -  change lr from 1.5e-05 to 7.5e-06
05/03/2022 13:24:12 - INFO - train -  No improvement since last 8 epochs, best score is 0.7176411794102949
05/03/2022 13:24:12 - INFO - train -  No data augmentation used
05/03/2022 13:24:12 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:24:12 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:24:12 - INFO - train -  epoch 31/100 - batch 1/7 - loss 1.7101582288742065 - samples/second: 50.80021649691341
05/03/2022 13:24:12 - INFO - train -  epoch 31/100 - batch 2/7 - loss 1.6903846263885498 - samples/second: 43.680798673737115
05/03/2022 13:24:13 - INFO - train -  epoch 31/100 - batch 3/7 - loss 1.8199160893758137 - samples/second: 44.29048166411658
05/03/2022 13:24:13 - INFO - train -  epoch 31/100 - batch 4/7 - loss 1.7754773199558258 - samples/second: 45.11634765857083
05/03/2022 13:24:13 - INFO - train -  epoch 31/100 - batch 5/7 - loss 1.5511660695075988 - samples/second: 49.23403428642529
05/03/2022 13:24:14 - INFO - train -  epoch 31/100 - batch 6/7 - loss 1.5100508431593578 - samples/second: 49.615235015892395
05/03/2022 13:24:14 - INFO - train -  epoch 31/100 - batch 7/7 - loss 1.5600728733198983 - samples/second: 52.50103580015003
05/03/2022 13:24:22 - INFO - train -  Finish evaluation: 8.711257934570312 s
05/03/2022 13:24:23 - INFO - train -  micro-avg: acc 0.549878656277941 - micro-avg-f1-score 0.7095763969012692
05/03/2022 13:24:23 - INFO - train -  No improvement since last 9 epochs, best score is 0.7176411794102949
05/03/2022 13:24:23 - INFO - train -  No data augmentation used
05/03/2022 13:24:23 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:24:23 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:24:23 - INFO - train -  epoch 32/100 - batch 1/7 - loss 1.3278145790100098 - samples/second: 79.70827063025355
05/03/2022 13:24:23 - INFO - train -  epoch 32/100 - batch 2/7 - loss 1.741879940032959 - samples/second: 62.71806625835215
05/03/2022 13:24:23 - INFO - train -  epoch 32/100 - batch 3/7 - loss 1.5240892966588337 - samples/second: 57.78694388489374
05/03/2022 13:24:24 - INFO - train -  epoch 32/100 - batch 4/7 - loss 1.4277932345867157 - samples/second: 56.0118285363021
05/03/2022 13:24:24 - INFO - train -  epoch 32/100 - batch 5/7 - loss 1.4873149633407592 - samples/second: 54.20201905332968
05/03/2022 13:24:24 - INFO - train -  epoch 32/100 - batch 6/7 - loss 1.4004270533720653 - samples/second: 55.382946561277826
05/03/2022 13:24:25 - INFO - train -  epoch 32/100 - batch 7/7 - loss 1.2995604361806596 - samples/second: 56.76767504901411
05/03/2022 13:24:33 - INFO - train -  Finish evaluation: 8.360116004943848 s
05/03/2022 13:24:33 - INFO - train -  micro-avg: acc 0.5512232415902141 - micro-avg-f1-score 0.7106949236076885
05/03/2022 13:24:33 - INFO - train -  No improvement since last 10 epochs, best score is 0.7176411794102949
05/03/2022 13:24:33 - INFO - train -  Early stop since no improvement since last 10 epochs
05/03/2022 13:24:33 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:24:33 - INFO - train -  Testing using best model ...
05/03/2022 13:24:41 - INFO - train -  Finish evaluation: 7.7827441692352295 s
05/03/2022 13:24:41 - INFO - train -  micro-avg: acc 0.5596258768511302 - micro-avg-f1-score 0.7176411794102949
05/03/2022 13:24:41 - INFO - train -  Class	TP	TP	FN	TN	Precision	Recall	F1
05/03/2022 13:24:41 - INFO - train -  LOC	1526	740	311	1526	0.6734	0.8307	0.7438
05/03/2022 13:24:41 - INFO - train -  MISC	323	495	599	323	0.3949	0.3503	0.3713
05/03/2022 13:24:41 - INFO - train -  ORG	806	386	535	806	0.6762	0.6010	0.6364
05/03/2022 13:24:41 - INFO - train -  PER	1653	135	189	1653	0.9245	0.8974	0.9107
05/03/2022 13:24:41 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:24:41 - INFO - train -  Testing using best model ...
05/03/2022 13:24:53 - INFO - train -  Finish evaluation: 11.70362901687622 s
05/03/2022 13:24:53 - INFO - train -  micro-avg: acc 0.5640744797371303 - micro-avg-f1-score 0.7212885154061625
05/03/2022 13:24:53 - INFO - train -  Class	TP	TP	FN	TN	Precision	Recall	F1
05/03/2022 13:24:53 - INFO - train -  LOC	1368	626	300	1368	0.6861	0.8201	0.7471
05/03/2022 13:24:53 - INFO - train -  MISC	247	418	455	247	0.3714	0.3519	0.3614
05/03/2022 13:24:53 - INFO - train -  ORG	1118	514	543	1118	0.6850	0.6731	0.6790
05/03/2022 13:24:53 - INFO - train -  PER	1387	98	230	1387	0.9340	0.8578	0.8943
05/03/2022 13:30:38 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=[], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=8, log_filepath='development.log', lr=3e-05, max_epochs=1000, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='development.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=8, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 13:30:39 - INFO - data -  Load 100 sentences from data/train.txt
05/03/2022 13:30:39 - INFO - data -  Load 3465 sentences from data/dev.txt
05/03/2022 13:30:39 - INFO - data -  Load 3683 sentences from data/test.txt
05/03/2022 13:30:45 - INFO - train -  # sentences in training set: 100
05/03/2022 13:30:45 - INFO - train -  # sentences in development set: 3465
05/03/2022 13:30:45 - INFO - train -  No data augmentation used
05/03/2022 13:30:45 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:30:45 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:30:46 - INFO - train -  epoch 1/1000 - batch 1/13 - loss 30.50493621826172 - samples/second: 8.29565723460061
05/03/2022 13:30:46 - INFO - train -  epoch 1/1000 - batch 2/13 - loss 36.951276779174805 - samples/second: 13.269130035721078
05/03/2022 13:30:46 - INFO - train -  epoch 1/1000 - batch 3/13 - loss 34.701164881388344 - samples/second: 16.34666128832676
05/03/2022 13:30:46 - INFO - train -  epoch 1/1000 - batch 4/13 - loss 33.29490518569946 - samples/second: 19.711154878519984
05/03/2022 13:30:46 - INFO - train -  epoch 1/1000 - batch 5/13 - loss 30.931960678100587 - samples/second: 22.457093208520067
05/03/2022 13:30:47 - INFO - train -  epoch 1/1000 - batch 6/13 - loss 28.56615416208903 - samples/second: 25.044586288351375
05/03/2022 13:30:47 - INFO - train -  epoch 1/1000 - batch 7/13 - loss 27.252140862601145 - samples/second: 26.34195267396346
05/03/2022 13:30:47 - INFO - train -  epoch 1/1000 - batch 8/13 - loss 26.191776990890503 - samples/second: 27.742545563231058
05/03/2022 13:30:47 - INFO - train -  epoch 1/1000 - batch 9/13 - loss 24.45109748840332 - samples/second: 29.59418139312316
05/03/2022 13:30:47 - INFO - train -  epoch 1/1000 - batch 10/13 - loss 23.454286766052245 - samples/second: 29.256038307007977
05/03/2022 13:30:48 - INFO - train -  epoch 1/1000 - batch 11/13 - loss 22.42582199790261 - samples/second: 30.343327318631417
05/03/2022 13:30:48 - INFO - train -  epoch 1/1000 - batch 12/13 - loss 21.52707799275716 - samples/second: 30.638986864641733
05/03/2022 13:30:48 - INFO - train -  epoch 1/1000 - batch 13/13 - loss 20.728811264038086 - samples/second: 31.515921584380745
05/03/2022 13:31:01 - INFO - train -  Finish evaluation: 13.336771965026855 s
05/03/2022 13:31:01 - INFO - train -  micro-avg: acc 0.0005046257359125315 - micro-avg-f1-score 0.0010087424344317419
05/03/2022 13:31:01 - INFO - train -  New best model found
05/03/2022 13:31:02 - INFO - train -  No data augmentation used
05/03/2022 13:31:02 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:31:02 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:31:02 - INFO - train -  epoch 2/1000 - batch 1/13 - loss 11.49045467376709 - samples/second: 58.438872827336375
05/03/2022 13:31:02 - INFO - train -  epoch 2/1000 - batch 2/13 - loss 9.897474765777588 - samples/second: 56.435025459682876
05/03/2022 13:31:03 - INFO - train -  epoch 2/1000 - batch 3/13 - loss 9.56356143951416 - samples/second: 54.33106646459151
05/03/2022 13:31:03 - INFO - train -  epoch 2/1000 - batch 4/13 - loss 10.537905931472778 - samples/second: 55.01984798162859
05/03/2022 13:31:03 - INFO - train -  epoch 2/1000 - batch 5/13 - loss 11.805525016784667 - samples/second: 47.730384976146496
05/03/2022 13:31:03 - INFO - train -  epoch 2/1000 - batch 6/13 - loss 12.284477869669596 - samples/second: 46.44569893043663
05/03/2022 13:31:03 - INFO - train -  epoch 2/1000 - batch 7/13 - loss 11.87278802054269 - samples/second: 48.216338673962035
05/03/2022 13:31:03 - INFO - train -  epoch 2/1000 - batch 8/13 - loss 12.092284202575684 - samples/second: 48.47925564192215
05/03/2022 13:31:04 - INFO - train -  epoch 2/1000 - batch 9/13 - loss 12.473765585157606 - samples/second: 48.86564604165305
05/03/2022 13:31:04 - INFO - train -  epoch 2/1000 - batch 10/13 - loss 12.29373836517334 - samples/second: 49.209520835902865
05/03/2022 13:31:04 - INFO - train -  epoch 2/1000 - batch 11/13 - loss 12.046683051369406 - samples/second: 47.99495264594689
05/03/2022 13:31:04 - INFO - train -  epoch 2/1000 - batch 12/13 - loss 11.813687165578207 - samples/second: 47.92436520207997
05/03/2022 13:31:04 - INFO - train -  epoch 2/1000 - batch 13/13 - loss 11.40772665463961 - samples/second: 47.76657554455355
05/03/2022 13:31:14 - INFO - train -  Finish evaluation: 9.723595142364502 s
05/03/2022 13:31:14 - INFO - train -  micro-avg: acc 0.05170185264971995 - micro-avg-f1-score 0.09832036050798854
05/03/2022 13:31:14 - INFO - train -  New best model found
05/03/2022 13:31:15 - INFO - train -  No data augmentation used
05/03/2022 13:31:15 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:31:15 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:31:15 - INFO - train -  epoch 3/1000 - batch 1/13 - loss 14.48747444152832 - samples/second: 31.137420844376145
05/03/2022 13:31:15 - INFO - train -  epoch 3/1000 - batch 2/13 - loss 12.388644218444824 - samples/second: 33.848968802030875
05/03/2022 13:31:15 - INFO - train -  epoch 3/1000 - batch 3/13 - loss 11.908610661824545 - samples/second: 38.86514706575045
05/03/2022 13:31:16 - INFO - train -  epoch 3/1000 - batch 4/13 - loss 11.140504360198975 - samples/second: 40.52390549334358
05/03/2022 13:31:16 - INFO - train -  epoch 3/1000 - batch 5/13 - loss 10.69439239501953 - samples/second: 39.88284194574035
05/03/2022 13:31:16 - INFO - train -  epoch 3/1000 - batch 6/13 - loss 9.841399272282919 - samples/second: 40.98775212383384
05/03/2022 13:31:16 - INFO - train -  epoch 3/1000 - batch 7/13 - loss 9.900983878544398 - samples/second: 40.6265440933936
05/03/2022 13:31:16 - INFO - train -  epoch 3/1000 - batch 8/13 - loss 9.337254345417023 - samples/second: 41.93374250302941
05/03/2022 13:31:16 - INFO - train -  epoch 3/1000 - batch 9/13 - loss 8.79313490125868 - samples/second: 42.83240734699667
05/03/2022 13:31:17 - INFO - train -  epoch 3/1000 - batch 10/13 - loss 8.88175106048584 - samples/second: 42.377333508124636
05/03/2022 13:31:17 - INFO - train -  epoch 3/1000 - batch 11/13 - loss 8.582177378914572 - samples/second: 42.60739581931263
05/03/2022 13:31:17 - INFO - train -  epoch 3/1000 - batch 12/13 - loss 8.413479328155518 - samples/second: 42.22213269525445
05/03/2022 13:31:17 - INFO - train -  epoch 3/1000 - batch 13/13 - loss 8.42951620542086 - samples/second: 43.294459914516274
05/03/2022 13:31:27 - INFO - train -  Finish evaluation: 9.86445927619934 s
05/03/2022 13:31:27 - INFO - train -  micro-avg: acc 0.1371721435031655 - micro-avg-f1-score 0.24125132555673387
05/03/2022 13:31:27 - INFO - train -  New best model found
05/03/2022 13:31:28 - INFO - train -  No data augmentation used
05/03/2022 13:31:28 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:31:28 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:31:28 - INFO - train -  epoch 4/1000 - batch 1/13 - loss 7.3387322425842285 - samples/second: 37.596465614702254
05/03/2022 13:31:28 - INFO - train -  epoch 4/1000 - batch 2/13 - loss 8.597439527511597 - samples/second: 42.83915479489394
05/03/2022 13:31:28 - INFO - train -  epoch 4/1000 - batch 3/13 - loss 6.861536423365275 - samples/second: 45.13703029947031
05/03/2022 13:31:29 - INFO - train -  epoch 4/1000 - batch 4/13 - loss 6.755730330944061 - samples/second: 47.543029437008315
05/03/2022 13:31:29 - INFO - train -  epoch 4/1000 - batch 5/13 - loss 6.009569406509399 - samples/second: 48.75749756390021
05/03/2022 13:31:29 - INFO - train -  epoch 4/1000 - batch 6/13 - loss 5.708648959795634 - samples/second: 50.90684443527416
05/03/2022 13:31:29 - INFO - train -  epoch 4/1000 - batch 7/13 - loss 6.190411942345755 - samples/second: 50.134540473091434
05/03/2022 13:31:29 - INFO - train -  epoch 4/1000 - batch 8/13 - loss 6.341425865888596 - samples/second: 50.403107004956276
05/03/2022 13:31:29 - INFO - train -  epoch 4/1000 - batch 9/13 - loss 6.153768989774916 - samples/second: 48.71172340105672
05/03/2022 13:31:29 - INFO - train -  epoch 4/1000 - batch 10/13 - loss 5.966156697273254 - samples/second: 49.82701987352885
05/03/2022 13:31:30 - INFO - train -  epoch 4/1000 - batch 11/13 - loss 6.162914297797463 - samples/second: 50.48439081916843
05/03/2022 13:31:30 - INFO - train -  epoch 4/1000 - batch 12/13 - loss 6.002370297908783 - samples/second: 47.04236361210528
05/03/2022 13:31:30 - INFO - train -  epoch 4/1000 - batch 13/13 - loss 5.95599077298091 - samples/second: 47.60696411586778
05/03/2022 13:31:40 - INFO - train -  Finish evaluation: 9.996394872665405 s
05/03/2022 13:31:40 - INFO - train -  micro-avg: acc 0.17130089374379345 - micro-avg-f1-score 0.29249682068673166
05/03/2022 13:31:40 - INFO - train -  New best model found
05/03/2022 13:31:41 - INFO - train -  No data augmentation used
05/03/2022 13:31:41 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:31:41 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:31:41 - INFO - train -  epoch 5/1000 - batch 1/13 - loss 4.567459583282471 - samples/second: 60.63422065049847
05/03/2022 13:31:41 - INFO - train -  epoch 5/1000 - batch 2/13 - loss 3.6763471364974976 - samples/second: 55.16026749607107
05/03/2022 13:31:41 - INFO - train -  epoch 5/1000 - batch 3/13 - loss 3.3701156775156655 - samples/second: 51.48614763141299
05/03/2022 13:31:42 - INFO - train -  epoch 5/1000 - batch 4/13 - loss 4.474339425563812 - samples/second: 47.37677065823834
05/03/2022 13:31:42 - INFO - train -  epoch 5/1000 - batch 5/13 - loss 4.605493021011353 - samples/second: 47.02978112665949
05/03/2022 13:31:42 - INFO - train -  epoch 5/1000 - batch 6/13 - loss 4.848805864651998 - samples/second: 45.10002280464928
05/03/2022 13:31:42 - INFO - train -  epoch 5/1000 - batch 7/13 - loss 4.733097451073783 - samples/second: 44.66517504496353
05/03/2022 13:31:42 - INFO - train -  epoch 5/1000 - batch 8/13 - loss 4.734832257032394 - samples/second: 44.68233226946612
05/03/2022 13:31:42 - INFO - train -  epoch 5/1000 - batch 9/13 - loss 4.635341379377577 - samples/second: 46.17427059028596
05/03/2022 13:31:43 - INFO - train -  epoch 5/1000 - batch 10/13 - loss 4.833022546768189 - samples/second: 45.39847083509841
05/03/2022 13:31:43 - INFO - train -  epoch 5/1000 - batch 11/13 - loss 4.873471953652122 - samples/second: 44.29093784668036
05/03/2022 13:31:43 - INFO - train -  epoch 5/1000 - batch 12/13 - loss 4.795680046081543 - samples/second: 42.89853790281984
05/03/2022 13:31:43 - INFO - train -  epoch 5/1000 - batch 13/13 - loss 5.068605789771447 - samples/second: 42.63667307606594
05/03/2022 13:31:53 - INFO - train -  Finish evaluation: 10.054425716400146 s
05/03/2022 13:31:53 - INFO - train -  micro-avg: acc 0.37165982924936247 - micro-avg-f1-score 0.5419125373858216
05/03/2022 13:31:53 - INFO - train -  New best model found
05/03/2022 13:31:54 - INFO - train -  No data augmentation used
05/03/2022 13:31:54 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:31:54 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:31:54 - INFO - train -  epoch 6/1000 - batch 1/13 - loss 2.5588040351867676 - samples/second: 47.86037741231511
05/03/2022 13:31:54 - INFO - train -  epoch 6/1000 - batch 2/13 - loss 1.910244107246399 - samples/second: 51.121916140660396
05/03/2022 13:31:55 - INFO - train -  epoch 6/1000 - batch 3/13 - loss 2.78269632657369 - samples/second: 54.1848403682683
05/03/2022 13:31:55 - INFO - train -  epoch 6/1000 - batch 4/13 - loss 2.6360982060432434 - samples/second: 56.10088800740668
05/03/2022 13:31:55 - INFO - train -  epoch 6/1000 - batch 5/13 - loss 3.143994188308716 - samples/second: 48.994499907426494
05/03/2022 13:31:55 - INFO - train -  epoch 6/1000 - batch 6/13 - loss 3.247148633003235 - samples/second: 44.57579807372966
05/03/2022 13:31:55 - INFO - train -  epoch 6/1000 - batch 7/13 - loss 3.4668483393532887 - samples/second: 43.65951378443506
05/03/2022 13:31:56 - INFO - train -  epoch 6/1000 - batch 8/13 - loss 3.519477754831314 - samples/second: 44.586230155810284
05/03/2022 13:31:56 - INFO - train -  epoch 6/1000 - batch 9/13 - loss 3.773156828350491 - samples/second: 45.26397620773803
05/03/2022 13:31:56 - INFO - train -  epoch 6/1000 - batch 10/13 - loss 3.696924829483032 - samples/second: 45.71729407351869
05/03/2022 13:31:56 - INFO - train -  epoch 6/1000 - batch 11/13 - loss 3.7097920070994985 - samples/second: 45.36426881302287
05/03/2022 13:31:56 - INFO - train -  epoch 6/1000 - batch 12/13 - loss 3.6154807011286416 - samples/second: 45.94081445979266
05/03/2022 13:31:56 - INFO - train -  epoch 6/1000 - batch 13/13 - loss 3.9061005665705752 - samples/second: 46.8446678554108
05/03/2022 13:32:06 - INFO - train -  Finish evaluation: 10.109977722167969 s
05/03/2022 13:32:07 - INFO - train -  micro-avg: acc 0.41786840919333035 - micro-avg-f1-score 0.5894318633293604
05/03/2022 13:32:07 - INFO - train -  New best model found
05/03/2022 13:32:07 - INFO - train -  No data augmentation used
05/03/2022 13:32:07 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:32:07 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:32:08 - INFO - train -  epoch 7/1000 - batch 1/13 - loss 2.7210140228271484 - samples/second: 33.393608382032134
05/03/2022 13:32:08 - INFO - train -  epoch 7/1000 - batch 2/13 - loss 1.8257267475128174 - samples/second: 45.370037420266435
05/03/2022 13:32:08 - INFO - train -  epoch 7/1000 - batch 3/13 - loss 2.0083768367767334 - samples/second: 42.74480792430349
05/03/2022 13:32:08 - INFO - train -  epoch 7/1000 - batch 4/13 - loss 2.0437851548194885 - samples/second: 43.328481743912135
05/03/2022 13:32:08 - INFO - train -  epoch 7/1000 - batch 5/13 - loss 2.7407088756561278 - samples/second: 44.140741298121526
05/03/2022 13:32:08 - INFO - train -  epoch 7/1000 - batch 6/13 - loss 2.764365871747335 - samples/second: 42.95345744595737
05/03/2022 13:32:09 - INFO - train -  epoch 7/1000 - batch 7/13 - loss 3.2267728873661587 - samples/second: 44.085600168173215
05/03/2022 13:32:09 - INFO - train -  epoch 7/1000 - batch 8/13 - loss 3.219056576490402 - samples/second: 44.74069673931069
05/03/2022 13:32:09 - INFO - train -  epoch 7/1000 - batch 9/13 - loss 3.1836028893788657 - samples/second: 45.32038427570123
05/03/2022 13:32:09 - INFO - train -  epoch 7/1000 - batch 10/13 - loss 3.1529234409332276 - samples/second: 45.0405640400949
05/03/2022 13:32:09 - INFO - train -  epoch 7/1000 - batch 11/13 - loss 3.157705870541659 - samples/second: 45.28312872021299
05/03/2022 13:32:09 - INFO - train -  epoch 7/1000 - batch 12/13 - loss 3.058485597372055 - samples/second: 45.465873200391634
05/03/2022 13:32:10 - INFO - train -  epoch 7/1000 - batch 13/13 - loss 3.4330469369888306 - samples/second: 46.06474994046641
05/03/2022 13:32:20 - INFO - train -  Finish evaluation: 10.30639386177063 s
05/03/2022 13:32:20 - INFO - train -  micro-avg: acc 0.4798367738838214 - micro-avg-f1-score 0.648499594484996
05/03/2022 13:32:20 - INFO - train -  New best model found
05/03/2022 13:32:21 - INFO - train -  No data augmentation used
05/03/2022 13:32:21 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:32:21 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:32:21 - INFO - train -  epoch 8/1000 - batch 1/13 - loss 1.7181817293167114 - samples/second: 59.736751497672266
05/03/2022 13:32:21 - INFO - train -  epoch 8/1000 - batch 2/13 - loss 2.0996267199516296 - samples/second: 47.22969602450271
05/03/2022 13:32:21 - INFO - train -  epoch 8/1000 - batch 3/13 - loss 2.0312777757644653 - samples/second: 47.34542971178837
05/03/2022 13:32:21 - INFO - train -  epoch 8/1000 - batch 4/13 - loss 2.411260098218918 - samples/second: 49.43748457584778
05/03/2022 13:32:22 - INFO - train -  epoch 8/1000 - batch 5/13 - loss 2.238315200805664 - samples/second: 51.30083883757104
05/03/2022 13:32:22 - INFO - train -  epoch 8/1000 - batch 6/13 - loss 2.3825406233469644 - samples/second: 50.16792497683809
05/03/2022 13:32:22 - INFO - train -  epoch 8/1000 - batch 7/13 - loss 2.7409533773149763 - samples/second: 47.45816141240756
05/03/2022 13:32:22 - INFO - train -  epoch 8/1000 - batch 8/13 - loss 2.5294004380702972 - samples/second: 48.25599479968318
05/03/2022 13:32:22 - INFO - train -  epoch 8/1000 - batch 9/13 - loss 2.603955348332723 - samples/second: 48.0520965815835
05/03/2022 13:32:22 - INFO - train -  epoch 8/1000 - batch 10/13 - loss 2.436859357357025 - samples/second: 49.4465109520976
05/03/2022 13:32:23 - INFO - train -  epoch 8/1000 - batch 11/13 - loss 2.351704629984769 - samples/second: 47.43940139010383
05/03/2022 13:32:23 - INFO - train -  epoch 8/1000 - batch 12/13 - loss 2.398619920015335 - samples/second: 48.039812657546435
05/03/2022 13:32:23 - INFO - train -  epoch 8/1000 - batch 13/13 - loss 2.3998235097298255 - samples/second: 48.99101453992434
05/03/2022 13:32:33 - INFO - train -  Finish evaluation: 9.845114469528198 s
05/03/2022 13:32:33 - INFO - train -  micro-avg: acc 0.4972624406862149 - micro-avg-f1-score 0.6642288314643263
05/03/2022 13:32:33 - INFO - train -  New best model found
05/03/2022 13:32:34 - INFO - train -  No data augmentation used
05/03/2022 13:32:34 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:32:34 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:32:34 - INFO - train -  epoch 9/1000 - batch 1/13 - loss 4.010191917419434 - samples/second: 53.033129078704675
05/03/2022 13:32:34 - INFO - train -  epoch 9/1000 - batch 2/13 - loss 3.0828226804733276 - samples/second: 50.709969729164435
05/03/2022 13:32:34 - INFO - train -  epoch 9/1000 - batch 3/13 - loss 2.883248249689738 - samples/second: 50.98032161219355
05/03/2022 13:32:34 - INFO - train -  epoch 9/1000 - batch 4/13 - loss 3.144745886325836 - samples/second: 51.52503874424499
05/03/2022 13:32:34 - INFO - train -  epoch 9/1000 - batch 5/13 - loss 2.796711254119873 - samples/second: 49.86931951266201
05/03/2022 13:32:35 - INFO - train -  epoch 9/1000 - batch 6/13 - loss 2.632070561250051 - samples/second: 51.199661460571804
05/03/2022 13:32:35 - INFO - train -  epoch 9/1000 - batch 7/13 - loss 2.5445199523653304 - samples/second: 49.82196573185132
05/03/2022 13:32:35 - INFO - train -  epoch 9/1000 - batch 8/13 - loss 2.570429250597954 - samples/second: 48.81794982963258
05/03/2022 13:32:35 - INFO - train -  epoch 9/1000 - batch 9/13 - loss 2.527894245253669 - samples/second: 48.77416691498717
05/03/2022 13:32:35 - INFO - train -  epoch 9/1000 - batch 10/13 - loss 2.688585865497589 - samples/second: 48.70998306626223
05/03/2022 13:32:35 - INFO - train -  epoch 9/1000 - batch 11/13 - loss 2.661419142376293 - samples/second: 47.74160515812859
05/03/2022 13:32:36 - INFO - train -  epoch 9/1000 - batch 12/13 - loss 2.500425696372986 - samples/second: 49.095808313141596
05/03/2022 13:32:36 - INFO - train -  epoch 9/1000 - batch 13/13 - loss 2.474968616779034 - samples/second: 47.945561524281715
05/03/2022 13:32:45 - INFO - train -  Finish evaluation: 9.639275074005127 s
05/03/2022 13:32:46 - INFO - train -  micro-avg: acc 0.4652529676155353 - micro-avg-f1-score 0.6350479786062608
05/03/2022 13:32:46 - INFO - train -  No improvement since last 1 epochs, best score is 0.6642288314643263
05/03/2022 13:32:46 - INFO - train -  No data augmentation used
05/03/2022 13:32:46 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:32:46 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:32:46 - INFO - train -  epoch 10/1000 - batch 1/13 - loss 2.115006923675537 - samples/second: 46.48149297397934
05/03/2022 13:32:46 - INFO - train -  epoch 10/1000 - batch 2/13 - loss 1.8319932222366333 - samples/second: 50.4035234244032
05/03/2022 13:32:46 - INFO - train -  epoch 10/1000 - batch 3/13 - loss 2.745521148045858 - samples/second: 49.22415376445356
05/03/2022 13:32:46 - INFO - train -  epoch 10/1000 - batch 4/13 - loss 2.561441659927368 - samples/second: 50.40340985478075
05/03/2022 13:32:46 - INFO - train -  epoch 10/1000 - batch 5/13 - loss 2.417136383056641 - samples/second: 50.09230695735774
05/03/2022 13:32:46 - INFO - train -  epoch 10/1000 - batch 6/13 - loss 2.4377125898996987 - samples/second: 51.92622446395125
05/03/2022 13:32:47 - INFO - train -  epoch 10/1000 - batch 7/13 - loss 2.415337187903268 - samples/second: 48.81902536965369
05/03/2022 13:32:47 - INFO - train -  epoch 10/1000 - batch 8/13 - loss 2.44850555062294 - samples/second: 48.098066960365365
05/03/2022 13:32:47 - INFO - train -  epoch 10/1000 - batch 9/13 - loss 2.4241948392656116 - samples/second: 49.565237258024915
05/03/2022 13:32:47 - INFO - train -  epoch 10/1000 - batch 10/13 - loss 2.313336420059204 - samples/second: 50.00183589046648
05/03/2022 13:32:47 - INFO - train -  epoch 10/1000 - batch 11/13 - loss 2.2078990286046807 - samples/second: 49.7992980312548
05/03/2022 13:32:48 - INFO - train -  epoch 10/1000 - batch 12/13 - loss 2.1786111990610757 - samples/second: 48.210015606918766
05/03/2022 13:32:48 - INFO - train -  epoch 10/1000 - batch 13/13 - loss 2.21338519683251 - samples/second: 49.016514186617066
05/03/2022 13:32:58 - INFO - train -  Finish evaluation: 10.250345945358276 s
05/03/2022 13:32:58 - INFO - train -  micro-avg: acc 0.5174099689959456 - micro-avg-f1-score 0.6819646365422397
05/03/2022 13:32:58 - INFO - train -  New best model found
05/03/2022 13:32:59 - INFO - train -  No data augmentation used
05/03/2022 13:32:59 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:32:59 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:32:59 - INFO - train -  epoch 11/1000 - batch 1/13 - loss 3.5308117866516113 - samples/second: 41.465615272160164
05/03/2022 13:32:59 - INFO - train -  epoch 11/1000 - batch 2/13 - loss 2.9676809310913086 - samples/second: 51.12425285412391
05/03/2022 13:32:59 - INFO - train -  epoch 11/1000 - batch 3/13 - loss 2.7780922253926597 - samples/second: 48.778586581821386
05/03/2022 13:32:59 - INFO - train -  epoch 11/1000 - batch 4/13 - loss 2.48232963681221 - samples/second: 48.58234941732409
05/03/2022 13:33:00 - INFO - train -  epoch 11/1000 - batch 5/13 - loss 2.3930408716201783 - samples/second: 49.65912440994105
05/03/2022 13:33:00 - INFO - train -  epoch 11/1000 - batch 6/13 - loss 2.334618071715037 - samples/second: 49.29938059457533
05/03/2022 13:33:00 - INFO - train -  epoch 11/1000 - batch 7/13 - loss 2.384775757789612 - samples/second: 48.8760663761056
05/03/2022 13:33:00 - INFO - train -  epoch 11/1000 - batch 8/13 - loss 2.206737771630287 - samples/second: 47.68392363408666
05/03/2022 13:33:00 - INFO - train -  epoch 11/1000 - batch 9/13 - loss 2.164127680990431 - samples/second: 47.407483317737004
05/03/2022 13:33:01 - INFO - train -  epoch 11/1000 - batch 10/13 - loss 2.161571705341339 - samples/second: 45.35744038852742
05/03/2022 13:33:01 - INFO - train -  epoch 11/1000 - batch 11/13 - loss 2.133903232487765 - samples/second: 45.46334983864213
05/03/2022 13:33:01 - INFO - train -  epoch 11/1000 - batch 12/13 - loss 2.1062375406424203 - samples/second: 44.64295772750571
05/03/2022 13:33:01 - INFO - train -  epoch 11/1000 - batch 13/13 - loss 2.07530231659229 - samples/second: 45.577385067742675
05/03/2022 13:33:11 - INFO - train -  Finish evaluation: 9.654154300689697 s
05/03/2022 13:33:11 - INFO - train -  micro-avg: acc 0.5156794425087108 - micro-avg-f1-score 0.6804597701149425
05/03/2022 13:33:11 - INFO - train -  No improvement since last 1 epochs, best score is 0.6819646365422397
05/03/2022 13:33:11 - INFO - train -  No data augmentation used
05/03/2022 13:33:11 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:33:11 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:33:11 - INFO - train -  epoch 12/1000 - batch 1/13 - loss 2.065126419067383 - samples/second: 32.84922484111103
05/03/2022 13:33:11 - INFO - train -  epoch 12/1000 - batch 2/13 - loss 1.9686833620071411 - samples/second: 34.83585137490001
05/03/2022 13:33:11 - INFO - train -  epoch 12/1000 - batch 3/13 - loss 2.143073479334513 - samples/second: 36.05580335795836
05/03/2022 13:33:12 - INFO - train -  epoch 12/1000 - batch 4/13 - loss 1.9046499729156494 - samples/second: 40.19688721919804
05/03/2022 13:33:12 - INFO - train -  epoch 12/1000 - batch 5/13 - loss 2.0257588386535645 - samples/second: 38.07598577110765
05/03/2022 13:33:12 - INFO - train -  epoch 12/1000 - batch 6/13 - loss 1.9717153310775757 - samples/second: 37.935680663328846
05/03/2022 13:33:12 - INFO - train -  epoch 12/1000 - batch 7/13 - loss 1.908129266330174 - samples/second: 40.33693836278906
05/03/2022 13:33:12 - INFO - train -  epoch 12/1000 - batch 8/13 - loss 2.0650407820940018 - samples/second: 40.2093871424848
05/03/2022 13:33:13 - INFO - train -  epoch 12/1000 - batch 9/13 - loss 2.1276784075631037 - samples/second: 40.79850591409006
05/03/2022 13:33:13 - INFO - train -  epoch 12/1000 - batch 10/13 - loss 2.0733448266983032 - samples/second: 40.750412945722395
05/03/2022 13:33:13 - INFO - train -  epoch 12/1000 - batch 11/13 - loss 2.2188624251972544 - samples/second: 41.482140422746134
05/03/2022 13:33:13 - INFO - train -  epoch 12/1000 - batch 12/13 - loss 2.115536923209826 - samples/second: 42.6035999413405
05/03/2022 13:33:13 - INFO - train -  epoch 12/1000 - batch 13/13 - loss 2.080785233240861 - samples/second: 43.789957236771436
05/03/2022 13:33:25 - INFO - train -  Finish evaluation: 11.730413436889648 s
05/03/2022 13:33:25 - INFO - train -  micro-avg: acc 0.5259076923076923 - micro-avg-f1-score 0.6893047265688014
05/03/2022 13:33:25 - INFO - train -  New best model found
05/03/2022 13:33:26 - INFO - train -  No data augmentation used
05/03/2022 13:33:26 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:33:26 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:33:26 - INFO - train -  epoch 13/1000 - batch 1/13 - loss 1.313715934753418 - samples/second: 36.3261931930133
05/03/2022 13:33:26 - INFO - train -  epoch 13/1000 - batch 2/13 - loss 1.4933708906173706 - samples/second: 33.91998770752399
05/03/2022 13:33:27 - INFO - train -  epoch 13/1000 - batch 3/13 - loss 1.5303295453389485 - samples/second: 36.19072093970556
05/03/2022 13:33:27 - INFO - train -  epoch 13/1000 - batch 4/13 - loss 1.6382640600204468 - samples/second: 36.9507306991658
05/03/2022 13:33:27 - INFO - train -  epoch 13/1000 - batch 5/13 - loss 2.042158031463623 - samples/second: 35.231545151215236
05/03/2022 13:33:27 - INFO - train -  epoch 13/1000 - batch 6/13 - loss 1.910688618818919 - samples/second: 34.29590372249642
05/03/2022 13:33:28 - INFO - train -  epoch 13/1000 - batch 7/13 - loss 1.641745184149061 - samples/second: 35.61906029964586
05/03/2022 13:33:28 - INFO - train -  epoch 13/1000 - batch 8/13 - loss 1.6150420531630516 - samples/second: 34.46668767264772
05/03/2022 13:33:28 - INFO - train -  epoch 13/1000 - batch 9/13 - loss 1.5167863302760654 - samples/second: 35.28743725169432
05/03/2022 13:33:28 - INFO - train -  epoch 13/1000 - batch 10/13 - loss 1.458058911561966 - samples/second: 35.61527800819393
05/03/2022 13:33:28 - INFO - train -  epoch 13/1000 - batch 11/13 - loss 1.4827350107106296 - samples/second: 36.232551135581666
05/03/2022 13:33:29 - INFO - train -  epoch 13/1000 - batch 12/13 - loss 1.6797486195961635 - samples/second: 36.27424790200652
05/03/2022 13:33:29 - INFO - train -  epoch 13/1000 - batch 13/13 - loss 1.7355721959700952 - samples/second: 36.22197722207197
05/03/2022 13:33:41 - INFO - train -  Finish evaluation: 12.077106237411499 s
05/03/2022 13:33:41 - INFO - train -  micro-avg: acc 0.5455210237659963 - micro-avg-f1-score 0.7059380175065059
05/03/2022 13:33:41 - INFO - train -  New best model found
05/03/2022 13:33:42 - INFO - train -  No data augmentation used
05/03/2022 13:33:42 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:33:42 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:33:42 - INFO - train -  epoch 14/1000 - batch 1/13 - loss 1.322998046875 - samples/second: 45.05299170087154
05/03/2022 13:33:42 - INFO - train -  epoch 14/1000 - batch 2/13 - loss 1.376397728919983 - samples/second: 36.26120396151309
05/03/2022 13:33:43 - INFO - train -  epoch 14/1000 - batch 3/13 - loss 1.45466144879659 - samples/second: 33.634774264125575
05/03/2022 13:33:43 - INFO - train -  epoch 14/1000 - batch 4/13 - loss 1.4215511083602905 - samples/second: 29.985457856783167
05/03/2022 13:33:43 - INFO - train -  epoch 14/1000 - batch 5/13 - loss 1.3500637054443358 - samples/second: 30.861154369270288
05/03/2022 13:33:43 - INFO - train -  epoch 14/1000 - batch 6/13 - loss 1.22372109691302 - samples/second: 31.215854629306033
05/03/2022 13:33:44 - INFO - train -  epoch 14/1000 - batch 7/13 - loss 1.3938096506255013 - samples/second: 30.770844280529627
05/03/2022 13:33:44 - INFO - train -  epoch 14/1000 - batch 8/13 - loss 1.5832819864153862 - samples/second: 29.66831972388676
05/03/2022 13:33:44 - INFO - train -  epoch 14/1000 - batch 9/13 - loss 1.5337845418188307 - samples/second: 31.33094449360962
05/03/2022 13:33:44 - INFO - train -  epoch 14/1000 - batch 10/13 - loss 1.470854538679123 - samples/second: 32.888466856920836
05/03/2022 13:33:45 - INFO - train -  epoch 14/1000 - batch 11/13 - loss 1.4452730146321384 - samples/second: 32.91032899205602
05/03/2022 13:33:45 - INFO - train -  epoch 14/1000 - batch 12/13 - loss 1.4344864040613174 - samples/second: 33.68971022392833
05/03/2022 13:33:45 - INFO - train -  epoch 14/1000 - batch 13/13 - loss 1.486768296131721 - samples/second: 34.668711041100224
05/03/2022 13:33:58 - INFO - train -  Finish evaluation: 13.1281418800354 s
05/03/2022 13:33:58 - INFO - train -  micro-avg: acc 0.5720777581418833 - micro-avg-f1-score 0.7277982977356672
05/03/2022 13:33:58 - INFO - train -  New best model found
05/03/2022 13:33:59 - INFO - train -  No data augmentation used
05/03/2022 13:33:59 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:33:59 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:33:59 - INFO - train -  epoch 15/1000 - batch 1/13 - loss 1.3238399028778076 - samples/second: 46.88717543129106
05/03/2022 13:33:59 - INFO - train -  epoch 15/1000 - batch 2/13 - loss 1.5691619515419006 - samples/second: 49.704157859107696
05/03/2022 13:34:00 - INFO - train -  epoch 15/1000 - batch 3/13 - loss 1.3337674935658772 - samples/second: 45.011210402409226
05/03/2022 13:34:00 - INFO - train -  epoch 15/1000 - batch 4/13 - loss 1.0712277293205261 - samples/second: 49.029933898698246
05/03/2022 13:34:00 - INFO - train -  epoch 15/1000 - batch 5/13 - loss 1.0496483325958252 - samples/second: 49.98735509306103
05/03/2022 13:34:00 - INFO - train -  epoch 15/1000 - batch 6/13 - loss 1.2364401817321777 - samples/second: 50.42130969396329
05/03/2022 13:34:00 - INFO - train -  epoch 15/1000 - batch 7/13 - loss 1.1865983179637365 - samples/second: 51.35906406560497
05/03/2022 13:34:00 - INFO - train -  epoch 15/1000 - batch 8/13 - loss 1.3088450878858566 - samples/second: 48.05272642617103
05/03/2022 13:34:00 - INFO - train -  epoch 15/1000 - batch 9/13 - loss 1.3737601041793823 - samples/second: 49.053860343206594
05/03/2022 13:34:01 - INFO - train -  epoch 15/1000 - batch 10/13 - loss 1.3759678721427917 - samples/second: 48.47597787186927
05/03/2022 13:34:01 - INFO - train -  epoch 15/1000 - batch 11/13 - loss 1.3418698852712458 - samples/second: 48.79872908694374
05/03/2022 13:34:01 - INFO - train -  epoch 15/1000 - batch 12/13 - loss 1.4171418050924938 - samples/second: 48.281628173369306
05/03/2022 13:34:01 - INFO - train -  epoch 15/1000 - batch 13/13 - loss 1.4931146640043993 - samples/second: 47.37681439604414
05/03/2022 13:34:13 - INFO - train -  Finish evaluation: 11.410988330841064 s
05/03/2022 13:34:13 - INFO - train -  micro-avg: acc 0.5544113907958301 - micro-avg-f1-score 0.7133393309887953
05/03/2022 13:34:13 - INFO - train -  No improvement since last 1 epochs, best score is 0.7277982977356672
05/03/2022 13:34:13 - INFO - train -  No data augmentation used
05/03/2022 13:34:13 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:34:13 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:34:13 - INFO - train -  epoch 16/1000 - batch 1/13 - loss 0.2641592025756836 - samples/second: 70.12508411808716
05/03/2022 13:34:13 - INFO - train -  epoch 16/1000 - batch 2/13 - loss 0.7691829204559326 - samples/second: 48.801619621622876
05/03/2022 13:34:13 - INFO - train -  epoch 16/1000 - batch 3/13 - loss 0.960047165552775 - samples/second: 49.780724719528976
05/03/2022 13:34:13 - INFO - train -  epoch 16/1000 - batch 4/13 - loss 0.8928303718566895 - samples/second: 41.975229754317844
05/03/2022 13:34:14 - INFO - train -  epoch 16/1000 - batch 5/13 - loss 0.8889624595642089 - samples/second: 44.189001223432484
05/03/2022 13:34:14 - INFO - train -  epoch 16/1000 - batch 6/13 - loss 1.237748622894287 - samples/second: 45.49784337520932
05/03/2022 13:34:14 - INFO - train -  epoch 16/1000 - batch 7/13 - loss 1.289749026298523 - samples/second: 44.258344144434425
05/03/2022 13:34:14 - INFO - train -  epoch 16/1000 - batch 8/13 - loss 1.5316339284181595 - samples/second: 44.008171585591555
05/03/2022 13:34:14 - INFO - train -  epoch 16/1000 - batch 9/13 - loss 1.5525022877587213 - samples/second: 43.48736700088259
05/03/2022 13:34:15 - INFO - train -  epoch 16/1000 - batch 10/13 - loss 1.6798267126083375 - samples/second: 41.28233684004352
05/03/2022 13:34:15 - INFO - train -  epoch 16/1000 - batch 11/13 - loss 1.8314055096019397 - samples/second: 40.57149301620557
05/03/2022 13:34:15 - INFO - train -  epoch 16/1000 - batch 12/13 - loss 1.80027640859286 - samples/second: 40.73837238007746
05/03/2022 13:34:15 - INFO - train -  epoch 16/1000 - batch 13/13 - loss 1.7406379718046923 - samples/second: 39.71153794857346
05/03/2022 13:34:28 - INFO - train -  Finish evaluation: 12.616804122924805 s
05/03/2022 13:34:28 - INFO - train -  micro-avg: acc 0.5030886196246139 - micro-avg-f1-score 0.6694064648699913
05/03/2022 13:34:28 - INFO - train -  No improvement since last 2 epochs, best score is 0.7277982977356672
05/03/2022 13:34:28 - INFO - train -  No data augmentation used
05/03/2022 13:34:28 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:34:28 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:34:28 - INFO - train -  epoch 17/1000 - batch 1/13 - loss 0.2724253535270691 - samples/second: 63.75060939812554
05/03/2022 13:34:28 - INFO - train -  epoch 17/1000 - batch 2/13 - loss 1.214791625738144 - samples/second: 58.972851466041924
05/03/2022 13:34:28 - INFO - train -  epoch 17/1000 - batch 3/13 - loss 0.9952077666918436 - samples/second: 60.25213129099701
05/03/2022 13:34:29 - INFO - train -  epoch 17/1000 - batch 4/13 - loss 1.2210821360349655 - samples/second: 60.97496540513921
05/03/2022 13:34:29 - INFO - train -  epoch 17/1000 - batch 5/13 - loss 1.3402525782585144 - samples/second: 61.651656639566795
05/03/2022 13:34:29 - INFO - train -  epoch 17/1000 - batch 6/13 - loss 1.5726280113061268 - samples/second: 60.18005358994011
05/03/2022 13:34:29 - INFO - train -  epoch 17/1000 - batch 7/13 - loss 1.5949927142688207 - samples/second: 57.25088345079366
05/03/2022 13:34:29 - INFO - train -  epoch 17/1000 - batch 8/13 - loss 1.578305833041668 - samples/second: 57.60170293120467
05/03/2022 13:34:29 - INFO - train -  epoch 17/1000 - batch 9/13 - loss 1.4911626511149936 - samples/second: 56.63551071656635
05/03/2022 13:34:29 - INFO - train -  epoch 17/1000 - batch 10/13 - loss 1.4816491663455964 - samples/second: 56.211923964610094
05/03/2022 13:34:30 - INFO - train -  epoch 17/1000 - batch 11/13 - loss 1.40089811520143 - samples/second: 55.98450811960127
05/03/2022 13:34:30 - INFO - train -  epoch 17/1000 - batch 12/13 - loss 1.3564629207054775 - samples/second: 54.859437376740956
05/03/2022 13:34:30 - INFO - train -  epoch 17/1000 - batch 13/13 - loss 1.2531661574657147 - samples/second: 55.89789598457132
05/03/2022 13:34:42 - INFO - train -  Finish evaluation: 12.559231758117676 s
05/03/2022 13:34:43 - INFO - train -  micro-avg: acc 0.5156341491977984 - micro-avg-f1-score 0.6804203368876527
05/03/2022 13:34:43 - INFO - train -  No improvement since last 3 epochs, best score is 0.7277982977356672
05/03/2022 13:34:43 - INFO - train -  No data augmentation used
05/03/2022 13:34:43 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:34:43 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:34:43 - INFO - train -  epoch 18/1000 - batch 1/13 - loss 3.230976104736328 - samples/second: 38.59759357673637
05/03/2022 13:34:43 - INFO - train -  epoch 18/1000 - batch 2/13 - loss 2.3404349088668823 - samples/second: 40.12792839874837
05/03/2022 13:34:43 - INFO - train -  epoch 18/1000 - batch 3/13 - loss 2.137655019760132 - samples/second: 44.31552713984027
05/03/2022 13:34:43 - INFO - train -  epoch 18/1000 - batch 4/13 - loss 2.2826414704322815 - samples/second: 46.567546637725975
05/03/2022 13:34:43 - INFO - train -  epoch 18/1000 - batch 5/13 - loss 1.9607348918914795 - samples/second: 46.55027167617388
05/03/2022 13:34:44 - INFO - train -  epoch 18/1000 - batch 6/13 - loss 1.7623613774776459 - samples/second: 46.99079074144615
05/03/2022 13:34:44 - INFO - train -  epoch 18/1000 - batch 7/13 - loss 1.555075236729213 - samples/second: 47.99430805680909
05/03/2022 13:34:44 - INFO - train -  epoch 18/1000 - batch 8/13 - loss 1.4949921816587448 - samples/second: 47.69381064433574
05/03/2022 13:34:44 - INFO - train -  epoch 18/1000 - batch 9/13 - loss 1.4468179146448772 - samples/second: 48.55818180502594
05/03/2022 13:34:44 - INFO - train -  epoch 18/1000 - batch 10/13 - loss 1.5275906920433044 - samples/second: 47.415761234744
05/03/2022 13:34:44 - INFO - train -  epoch 18/1000 - batch 11/13 - loss 1.4799497235905041 - samples/second: 47.3166402841213
05/03/2022 13:34:45 - INFO - train -  epoch 18/1000 - batch 12/13 - loss 1.483614315589269 - samples/second: 45.52345499318765
05/03/2022 13:34:45 - INFO - train -  epoch 18/1000 - batch 13/13 - loss 1.5981127207095807 - samples/second: 44.63478353940491
05/03/2022 13:34:58 - INFO - train -  Finish evaluation: 12.952557563781738 s
05/03/2022 13:34:58 - INFO - train -  micro-avg: acc 0.5619876403077311 - micro-avg-f1-score 0.7195801372628179
05/03/2022 13:34:58 - INFO - train -  change lr from 3e-05 to 1.5e-05
05/03/2022 13:34:58 - INFO - train -  No improvement since last 4 epochs, best score is 0.7277982977356672
05/03/2022 13:34:58 - INFO - train -  No data augmentation used
05/03/2022 13:34:58 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:34:58 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:34:58 - INFO - train -  epoch 19/1000 - batch 1/13 - loss 0.8303186893463135 - samples/second: 37.1636546484982
05/03/2022 13:34:58 - INFO - train -  epoch 19/1000 - batch 2/13 - loss 0.974432647228241 - samples/second: 37.59673943186561
05/03/2022 13:34:59 - INFO - train -  epoch 19/1000 - batch 3/13 - loss 1.4086521069208782 - samples/second: 31.097069044292255
05/03/2022 13:34:59 - INFO - train -  epoch 19/1000 - batch 4/13 - loss 1.6403212249279022 - samples/second: 30.51835884758616
05/03/2022 13:34:59 - INFO - train -  epoch 19/1000 - batch 5/13 - loss 1.7547793626785277 - samples/second: 31.551291015492037
05/03/2022 13:34:59 - INFO - train -  epoch 19/1000 - batch 6/13 - loss 1.8365979393323262 - samples/second: 32.344203545246906
05/03/2022 13:35:00 - INFO - train -  epoch 19/1000 - batch 7/13 - loss 1.7922199964523315 - samples/second: 32.16609728942103
05/03/2022 13:35:00 - INFO - train -  epoch 19/1000 - batch 8/13 - loss 1.6405005604028702 - samples/second: 32.33887045270607
05/03/2022 13:35:00 - INFO - train -  epoch 19/1000 - batch 9/13 - loss 1.6319893068737454 - samples/second: 32.76775466850346
05/03/2022 13:35:00 - INFO - train -  epoch 19/1000 - batch 10/13 - loss 1.5943662405014039 - samples/second: 33.0987025838633
05/03/2022 13:35:01 - INFO - train -  epoch 19/1000 - batch 11/13 - loss 1.5999193625016646 - samples/second: 34.22048394473489
05/03/2022 13:35:01 - INFO - train -  epoch 19/1000 - batch 12/13 - loss 1.5092190752426784 - samples/second: 34.86009960048642
05/03/2022 13:35:01 - INFO - train -  epoch 19/1000 - batch 13/13 - loss 1.5066497371746943 - samples/second: 34.62796552346893
05/03/2022 13:35:14 - INFO - train -  Finish evaluation: 12.803756713867188 s
05/03/2022 13:35:14 - INFO - train -  micro-avg: acc 0.567814923096479 - micro-avg-f1-score 0.7243392249067617
05/03/2022 13:35:14 - INFO - train -  No improvement since last 5 epochs, best score is 0.7277982977356672
05/03/2022 13:35:14 - INFO - train -  No data augmentation used
05/03/2022 13:35:14 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:35:14 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:35:14 - INFO - train -  epoch 20/1000 - batch 1/13 - loss 3.2278366088867188 - samples/second: 32.00189220172549
05/03/2022 13:35:14 - INFO - train -  epoch 20/1000 - batch 2/13 - loss 2.016732931137085 - samples/second: 34.798279086818795
05/03/2022 13:35:15 - INFO - train -  epoch 20/1000 - batch 3/13 - loss 1.6586848298708599 - samples/second: 34.83589356885955
05/03/2022 13:35:15 - INFO - train -  epoch 20/1000 - batch 4/13 - loss 1.6791513711214066 - samples/second: 34.72346696221696
05/03/2022 13:35:15 - INFO - train -  epoch 20/1000 - batch 5/13 - loss 1.6205445885658265 - samples/second: 37.33572725174798
05/03/2022 13:35:15 - INFO - train -  epoch 20/1000 - batch 6/13 - loss 1.3943071365356445 - samples/second: 39.95632019341623
05/03/2022 13:35:15 - INFO - train -  epoch 20/1000 - batch 7/13 - loss 1.3394545486995153 - samples/second: 42.47672208738325
05/03/2022 13:35:15 - INFO - train -  epoch 20/1000 - batch 8/13 - loss 1.6615884602069855 - samples/second: 43.343040526041385
05/03/2022 13:35:16 - INFO - train -  epoch 20/1000 - batch 9/13 - loss 1.739768425623576 - samples/second: 42.23484169445705
05/03/2022 13:35:16 - INFO - train -  epoch 20/1000 - batch 10/13 - loss 1.7723713397979737 - samples/second: 43.16035071674664
05/03/2022 13:35:16 - INFO - train -  epoch 20/1000 - batch 11/13 - loss 1.7062995650551536 - samples/second: 43.97005975469127
05/03/2022 13:35:16 - INFO - train -  epoch 20/1000 - batch 12/13 - loss 1.7487184802691143 - samples/second: 45.021698800116646
05/03/2022 13:35:16 - INFO - train -  epoch 20/1000 - batch 13/13 - loss 1.7787597179412842 - samples/second: 45.610310719783385
05/03/2022 13:35:30 - INFO - train -  Finish evaluation: 13.817091226577759 s
05/03/2022 13:35:30 - INFO - train -  micro-avg: acc 0.5680668016194332 - micro-avg-f1-score 0.7245441342585123
05/03/2022 13:35:30 - INFO - train -  No improvement since last 6 epochs, best score is 0.7277982977356672
05/03/2022 13:35:30 - INFO - train -  No data augmentation used
05/03/2022 13:35:30 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:35:30 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:35:30 - INFO - train -  epoch 21/1000 - batch 1/13 - loss 1.1862215995788574 - samples/second: 37.33567740004428
05/03/2022 13:35:31 - INFO - train -  epoch 21/1000 - batch 2/13 - loss 1.9763984680175781 - samples/second: 36.28586892636672
05/03/2022 13:35:31 - INFO - train -  epoch 21/1000 - batch 3/13 - loss 1.9061644872029622 - samples/second: 33.141860031751406
05/03/2022 13:35:31 - INFO - train -  epoch 21/1000 - batch 4/13 - loss 1.657882571220398 - samples/second: 35.02258762905698
05/03/2022 13:35:31 - INFO - train -  epoch 21/1000 - batch 5/13 - loss 1.4423265337944031 - samples/second: 36.60485354428908
05/03/2022 13:35:31 - INFO - train -  epoch 21/1000 - batch 6/13 - loss 1.6114969551563263 - samples/second: 38.20342601326753
05/03/2022 13:35:32 - INFO - train -  epoch 21/1000 - batch 7/13 - loss 1.7423059514590673 - samples/second: 39.851078958847594
05/03/2022 13:35:32 - INFO - train -  epoch 21/1000 - batch 8/13 - loss 1.7858892008662224 - samples/second: 39.56674768622584
05/03/2022 13:35:32 - INFO - train -  epoch 21/1000 - batch 9/13 - loss 1.941250052716997 - samples/second: 39.157348180775564
05/03/2022 13:35:32 - INFO - train -  epoch 21/1000 - batch 10/13 - loss 1.9415771901607513 - samples/second: 40.41219571708985
05/03/2022 13:35:32 - INFO - train -  epoch 21/1000 - batch 11/13 - loss 1.9078749038956382 - samples/second: 40.95369188073393
05/03/2022 13:35:32 - INFO - train -  epoch 21/1000 - batch 12/13 - loss 1.80805807809035 - samples/second: 41.71126008652959
05/03/2022 13:35:33 - INFO - train -  epoch 21/1000 - batch 13/13 - loss 1.7341669385249798 - samples/second: 42.56372137427485
05/03/2022 13:35:47 - INFO - train -  Finish evaluation: 14.149904012680054 s
05/03/2022 13:35:47 - INFO - train -  micro-avg: acc 0.56755392960767 - micro-avg-f1-score 0.7241268308385643
05/03/2022 13:35:47 - INFO - train -  No improvement since last 7 epochs, best score is 0.7277982977356672
05/03/2022 13:35:47 - INFO - train -  No data augmentation used
05/03/2022 13:35:47 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:35:47 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:35:47 - INFO - train -  epoch 22/1000 - batch 1/13 - loss 1.5454883575439453 - samples/second: 24.92907259754115
05/03/2022 13:35:47 - INFO - train -  epoch 22/1000 - batch 2/13 - loss 1.959363579750061 - samples/second: 30.432195277238772
05/03/2022 13:35:48 - INFO - train -  epoch 22/1000 - batch 3/13 - loss 2.512873888015747 - samples/second: 28.257942268213718
05/03/2022 13:35:48 - INFO - train -  epoch 22/1000 - batch 4/13 - loss 2.8180022835731506 - samples/second: 30.585051673250774
05/03/2022 13:35:48 - INFO - train -  epoch 22/1000 - batch 5/13 - loss 2.496195936203003 - samples/second: 31.289334497086887
05/03/2022 13:35:49 - INFO - train -  epoch 22/1000 - batch 6/13 - loss 2.404215673605601 - samples/second: 27.933825142366686
05/03/2022 13:35:49 - INFO - train -  epoch 22/1000 - batch 7/13 - loss 2.1838342121669223 - samples/second: 29.930494731539746
05/03/2022 13:35:49 - INFO - train -  epoch 22/1000 - batch 8/13 - loss 2.1867528557777405 - samples/second: 31.861646611752548
05/03/2022 13:35:49 - INFO - train -  epoch 22/1000 - batch 9/13 - loss 2.0161193344328137 - samples/second: 33.43368068990828
05/03/2022 13:35:49 - INFO - train -  epoch 22/1000 - batch 10/13 - loss 1.8408474385738374 - samples/second: 34.75519982532511
05/03/2022 13:35:49 - INFO - train -  epoch 22/1000 - batch 11/13 - loss 1.728233976797624 - samples/second: 35.78623050560074
05/03/2022 13:35:50 - INFO - train -  epoch 22/1000 - batch 12/13 - loss 1.692878673473994 - samples/second: 36.56073933375083
05/03/2022 13:35:50 - INFO - train -  epoch 22/1000 - batch 13/13 - loss 1.6531161803465624 - samples/second: 37.23701526887311
05/03/2022 13:36:02 - INFO - train -  Finish evaluation: 11.82465147972107 s
05/03/2022 13:36:02 - INFO - train -  micro-avg: acc 0.5618904726181545 - micro-avg-f1-score 0.7195004803073969
05/03/2022 13:36:02 - INFO - train -  change lr from 1.5e-05 to 7.5e-06
05/03/2022 13:36:02 - INFO - train -  No improvement since last 8 epochs, best score is 0.7277982977356672
05/03/2022 13:36:02 - INFO - train -  No data augmentation used
05/03/2022 13:36:02 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:36:02 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:36:02 - INFO - train -  epoch 23/1000 - batch 1/13 - loss 2.395111560821533 - samples/second: 51.20531305128095
05/03/2022 13:36:02 - INFO - train -  epoch 23/1000 - batch 2/13 - loss 1.6150286197662354 - samples/second: 52.882807162428065
05/03/2022 13:36:02 - INFO - train -  epoch 23/1000 - batch 3/13 - loss 1.974729299545288 - samples/second: 54.24610088603734
05/03/2022 13:36:02 - INFO - train -  epoch 23/1000 - batch 4/13 - loss 1.8025732636451721 - samples/second: 50.521932543684215
05/03/2022 13:36:02 - INFO - train -  epoch 23/1000 - batch 5/13 - loss 1.4946677803993225 - samples/second: 50.30533328016115
05/03/2022 13:36:03 - INFO - train -  epoch 23/1000 - batch 6/13 - loss 1.3780380686124165 - samples/second: 48.40855754098735
05/03/2022 13:36:03 - INFO - train -  epoch 23/1000 - batch 7/13 - loss 1.4064874819346838 - samples/second: 46.13731763581849
05/03/2022 13:36:03 - INFO - train -  epoch 23/1000 - batch 8/13 - loss 1.4793184250593185 - samples/second: 44.97287676144236
05/03/2022 13:36:03 - INFO - train -  epoch 23/1000 - batch 9/13 - loss 1.5072559648089938 - samples/second: 46.47920370762555
05/03/2022 13:36:03 - INFO - train -  epoch 23/1000 - batch 10/13 - loss 1.5854231715202332 - samples/second: 45.36811736229587
05/03/2022 13:36:04 - INFO - train -  epoch 23/1000 - batch 11/13 - loss 1.5473010431636463 - samples/second: 45.31615856166444
05/03/2022 13:36:04 - INFO - train -  epoch 23/1000 - batch 12/13 - loss 1.5062287151813507 - samples/second: 44.46170774672188
05/03/2022 13:36:04 - INFO - train -  epoch 23/1000 - batch 13/13 - loss 1.5071185460457435 - samples/second: 45.31893458935861
05/03/2022 13:36:14 - INFO - train -  Finish evaluation: 10.508763551712036 s
05/03/2022 13:36:14 - INFO - train -  micro-avg: acc 0.5612040969273046 - micro-avg-f1-score 0.7189375150012002
05/03/2022 13:36:14 - INFO - train -  No improvement since last 9 epochs, best score is 0.7277982977356672
05/03/2022 13:36:14 - INFO - train -  No data augmentation used
05/03/2022 13:36:14 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:36:14 - INFO - train -  # sentences and augmented sentences: 100
05/03/2022 13:36:15 - INFO - train -  epoch 24/1000 - batch 1/13 - loss 1.840498924255371 - samples/second: 44.06770953036987
05/03/2022 13:36:15 - INFO - train -  epoch 24/1000 - batch 2/13 - loss 1.5639322996139526 - samples/second: 38.82127564555709
05/03/2022 13:36:15 - INFO - train -  epoch 24/1000 - batch 3/13 - loss 1.6114041010538738 - samples/second: 42.63412134274873
05/03/2022 13:36:15 - INFO - train -  epoch 24/1000 - batch 4/13 - loss 1.503385603427887 - samples/second: 46.44996386933157
05/03/2022 13:36:15 - INFO - train -  epoch 24/1000 - batch 5/13 - loss 1.33607656955719 - samples/second: 50.09054218425033
05/03/2022 13:36:15 - INFO - train -  epoch 24/1000 - batch 6/13 - loss 1.4721196293830872 - samples/second: 49.1491921604088
05/03/2022 13:36:16 - INFO - train -  epoch 24/1000 - batch 7/13 - loss 1.441392949649266 - samples/second: 45.85854045210139
05/03/2022 13:36:16 - INFO - train -  epoch 24/1000 - batch 8/13 - loss 1.3986544162034988 - samples/second: 45.30643391282128
05/03/2022 13:36:16 - INFO - train -  epoch 24/1000 - batch 9/13 - loss 1.4037632015016344 - samples/second: 45.490989695644544
05/03/2022 13:36:16 - INFO - train -  epoch 24/1000 - batch 10/13 - loss 1.4696210741996765 - samples/second: 45.395663967638725
05/03/2022 13:36:16 - INFO - train -  epoch 24/1000 - batch 11/13 - loss 1.4165259166197344 - samples/second: 44.32170534071751
05/03/2022 13:36:17 - INFO - train -  epoch 24/1000 - batch 12/13 - loss 1.3627190043528874 - samples/second: 44.668507603293094
05/03/2022 13:36:17 - INFO - train -  epoch 24/1000 - batch 13/13 - loss 1.3761772971886854 - samples/second: 42.773860548078325
05/03/2022 13:36:27 - INFO - train -  Finish evaluation: 10.273698806762695 s
05/03/2022 13:36:27 - INFO - train -  micro-avg: acc 0.5621405351337835 - micro-avg-f1-score 0.7197054586201377
05/03/2022 13:36:27 - INFO - train -  No improvement since last 10 epochs, best score is 0.7277982977356672
05/03/2022 13:36:27 - INFO - train -  Early stop since no improvement since last 10 epochs
05/03/2022 13:36:27 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:36:27 - INFO - train -  Testing using best model ...
05/03/2022 13:36:38 - INFO - train -  Finish evaluation: 10.368395566940308 s
05/03/2022 13:36:38 - INFO - train -  micro-avg: acc 0.5720777581418833 - micro-avg-f1-score 0.7277982977356672
05/03/2022 13:36:38 - INFO - train -  Class	TP	TP	FN	TN	Precision	Recall	F1
05/03/2022 13:36:38 - INFO - train -  LOC	1526	640	311	1526	0.7045	0.8307	0.7624
05/03/2022 13:36:38 - INFO - train -  MISC	434	670	488	434	0.3931	0.4707	0.4284
05/03/2022 13:36:38 - INFO - train -  ORG	977	601	364	977	0.6191	0.7286	0.6694
05/03/2022 13:36:38 - INFO - train -  PER	1595	69	247	1595	0.9585	0.8659	0.9099
05/03/2022 13:36:38 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 13:36:38 - INFO - train -  Testing using best model ...
05/03/2022 13:36:55 - INFO - train -  Finish evaluation: 16.42605209350586 s
05/03/2022 13:36:55 - INFO - train -  micro-avg: acc 0.550077841203944 - micro-avg-f1-score 0.7097422162705056
05/03/2022 13:36:55 - INFO - train -  Class	TP	TP	FN	TN	Precision	Recall	F1
05/03/2022 13:36:55 - INFO - train -  LOC	1355	584	313	1355	0.6988	0.8124	0.7513
05/03/2022 13:36:55 - INFO - train -  MISC	315	632	387	315	0.3326	0.4487	0.3820
05/03/2022 13:36:55 - INFO - train -  ORG	1260	799	401	1260	0.6119	0.7586	0.6774
05/03/2022 13:36:55 - INFO - train -  PER	1310	45	307	1310	0.9668	0.8101	0.8816
05/03/2022 14:07:17 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=['MR', 'LwTR', 'SiS', 'SR'], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=8, log_filepath='development.log', lr=3e-05, max_epochs=1000, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='all.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=8, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 14:07:17 - INFO - data -  Load 100 sentences from data/train.txt
05/03/2022 14:07:18 - INFO - data -  Load 3465 sentences from data/dev.txt
05/03/2022 14:07:18 - INFO - data -  Load 3683 sentences from data/test.txt
05/03/2022 14:07:23 - INFO - train -  # sentences in training set: 100
05/03/2022 14:07:23 - INFO - train -  # sentences in development set: 3465
05/03/2022 14:07:53 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=['MR', 'LwTR', 'SiS', 'SR'], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=8, log_filepath='development.log', lr=3e-05, max_epochs=1000, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='all.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=8, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 14:07:54 - INFO - data -  Load 100 sentences from data/train.txt
05/03/2022 14:07:54 - INFO - data -  Load 3465 sentences from data/dev.txt
05/03/2022 14:07:54 - INFO - data -  Load 3683 sentences from data/test.txt
05/03/2022 14:07:59 - INFO - train -  # sentences in training set: 100
05/03/2022 14:07:59 - INFO - train -  # sentences in development set: 3465
05/03/2022 14:08:36 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=['MR', 'LwTR', 'SiS', 'SR'], data_folder='data/', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=8, log_filepath='development.log', lr=3e-05, max_epochs=1000, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='all.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=8, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/03/2022 14:08:37 - INFO - data -  Load 100 sentences from data/train.txt
05/03/2022 14:08:37 - INFO - data -  Load 3465 sentences from data/dev.txt
05/03/2022 14:08:37 - INFO - data -  Load 3683 sentences from data/test.txt
05/03/2022 14:08:43 - INFO - train -  # sentences in training set: 100
05/03/2022 14:08:43 - INFO - train -  # sentences in development set: 3465
05/03/2022 14:08:44 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:08:44 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:08:45 - INFO - train -  epoch 1/1000 - batch 1/63 - loss 30.347274780273438 - samples/second: 8.384673491963897
05/03/2022 14:08:46 - INFO - train -  epoch 1/1000 - batch 7/63 - loss 27.286945751735143 - samples/second: 27.985604538490346
05/03/2022 14:08:47 - INFO - train -  epoch 1/1000 - batch 13/63 - loss 21.735146595881535 - samples/second: 33.8788296117237
05/03/2022 14:08:48 - INFO - train -  epoch 1/1000 - batch 19/63 - loss 18.471759043241804 - samples/second: 36.6163615294629
05/03/2022 14:08:50 - INFO - train -  epoch 1/1000 - batch 25/63 - loss 16.989695301055907 - samples/second: 38.12557220572718
05/03/2022 14:08:50 - INFO - train -  epoch 1/1000 - batch 31/63 - loss 15.581765497884442 - samples/second: 39.82788539431099
05/03/2022 14:08:52 - INFO - train -  epoch 1/1000 - batch 37/63 - loss 14.146694776174185 - samples/second: 40.66503414415954
05/03/2022 14:08:53 - INFO - train -  epoch 1/1000 - batch 43/63 - loss 13.148353138635326 - samples/second: 41.38589561415639
05/03/2022 14:08:54 - INFO - train -  epoch 1/1000 - batch 49/63 - loss 12.272363244270792 - samples/second: 42.312824945990364
05/03/2022 14:08:55 - INFO - train -  epoch 1/1000 - batch 55/63 - loss 11.663667479428378 - samples/second: 42.656881584882214
05/03/2022 14:08:56 - INFO - train -  epoch 1/1000 - batch 61/63 - loss 11.104333936190995 - samples/second: 43.15080085175815
05/03/2022 14:09:10 - INFO - train -  Finish evaluation: 13.93166470527649 s
05/03/2022 14:09:10 - INFO - train -  micro-avg: acc 0.2675202814974098 - micro-avg-f1-score 0.4221159777914868
05/03/2022 14:09:10 - INFO - train -  New best model found
05/03/2022 14:09:11 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:09:11 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:09:11 - INFO - train -  epoch 2/1000 - batch 1/63 - loss 11.973698616027832 - samples/second: 47.86024088136792
05/03/2022 14:09:12 - INFO - train -  epoch 2/1000 - batch 7/63 - loss 6.960614476885114 - samples/second: 46.02207513823413
05/03/2022 14:09:13 - INFO - train -  epoch 2/1000 - batch 13/63 - loss 5.764655168239887 - samples/second: 46.121023809642125
05/03/2022 14:09:14 - INFO - train -  epoch 2/1000 - batch 19/63 - loss 5.386478863264385 - samples/second: 46.85628526251561
05/03/2022 14:09:15 - INFO - train -  epoch 2/1000 - batch 25/63 - loss 4.784304428100586 - samples/second: 47.77424761725555
05/03/2022 14:09:16 - INFO - train -  epoch 2/1000 - batch 31/63 - loss 4.693125663265105 - samples/second: 46.282430274397804
05/03/2022 14:09:17 - INFO - train -  epoch 2/1000 - batch 37/63 - loss 4.656611622990789 - samples/second: 45.545701946560655
05/03/2022 14:09:18 - INFO - train -  epoch 2/1000 - batch 43/63 - loss 4.444164564443189 - samples/second: 46.618685450784646
05/03/2022 14:09:19 - INFO - train -  epoch 2/1000 - batch 49/63 - loss 4.312891232724092 - samples/second: 46.499494638084336
05/03/2022 14:09:20 - INFO - train -  epoch 2/1000 - batch 55/63 - loss 4.213375327803872 - samples/second: 47.16499374981855
05/03/2022 14:09:21 - INFO - train -  epoch 2/1000 - batch 61/63 - loss 4.115374074607599 - samples/second: 47.02050705925444
05/03/2022 14:09:32 - INFO - train -  Finish evaluation: 10.069804668426514 s
05/03/2022 14:09:32 - INFO - train -  micro-avg: acc 0.5295393645527625 - micro-avg-f1-score 0.6924167848502545
05/03/2022 14:09:32 - INFO - train -  New best model found
05/03/2022 14:09:33 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:09:33 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:09:33 - INFO - train -  epoch 3/1000 - batch 1/63 - loss 1.6823614835739136 - samples/second: 60.1822483126983
05/03/2022 14:09:34 - INFO - train -  epoch 3/1000 - batch 7/63 - loss 2.317413789885385 - samples/second: 54.411050435867956
05/03/2022 14:09:35 - INFO - train -  epoch 3/1000 - batch 13/63 - loss 2.414790529471177 - samples/second: 48.7904241795841
05/03/2022 14:09:36 - INFO - train -  epoch 3/1000 - batch 19/63 - loss 2.2725440075522974 - samples/second: 48.06694601048414
05/03/2022 14:09:37 - INFO - train -  epoch 3/1000 - batch 25/63 - loss 2.420737180709839 - samples/second: 48.29331375488821
05/03/2022 14:09:38 - INFO - train -  epoch 3/1000 - batch 31/63 - loss 2.470171751514558 - samples/second: 47.411071690538776
05/03/2022 14:09:39 - INFO - train -  epoch 3/1000 - batch 37/63 - loss 2.3868074320458077 - samples/second: 46.79036711953001
05/03/2022 14:09:40 - INFO - train -  epoch 3/1000 - batch 43/63 - loss 2.483696837757909 - samples/second: 47.33713238023719
05/03/2022 14:09:41 - INFO - train -  epoch 3/1000 - batch 49/63 - loss 2.4253419637680054 - samples/second: 47.043680222595846
05/03/2022 14:09:42 - INFO - train -  epoch 3/1000 - batch 55/63 - loss 2.3785995461724023 - samples/second: 47.06642103123018
05/03/2022 14:09:43 - INFO - train -  epoch 3/1000 - batch 61/63 - loss 2.2919774680841165 - samples/second: 46.45563468585416
05/03/2022 14:09:53 - INFO - train -  Finish evaluation: 9.541067123413086 s
05/03/2022 14:09:53 - INFO - train -  micro-avg: acc 0.5676720804331014 - micro-avg-f1-score 0.7242229896398618
05/03/2022 14:09:53 - INFO - train -  New best model found
05/03/2022 14:09:54 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:09:54 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:09:54 - INFO - train -  epoch 4/1000 - batch 1/63 - loss 2.631427764892578 - samples/second: 52.88193205529884
05/03/2022 14:09:55 - INFO - train -  epoch 4/1000 - batch 7/63 - loss 1.7840883391244071 - samples/second: 49.72058204664671
05/03/2022 14:09:56 - INFO - train -  epoch 4/1000 - batch 13/63 - loss 2.247082288448627 - samples/second: 47.776029184707866
05/03/2022 14:09:57 - INFO - train -  epoch 4/1000 - batch 19/63 - loss 2.3113105046121696 - samples/second: 46.12786957836686
05/03/2022 14:09:58 - INFO - train -  epoch 4/1000 - batch 25/63 - loss 2.142767210006714 - samples/second: 46.81409060035278
05/03/2022 14:09:59 - INFO - train -  epoch 4/1000 - batch 31/63 - loss 2.0632923264657297 - samples/second: 46.53182675510475
05/03/2022 14:10:01 - INFO - train -  epoch 4/1000 - batch 37/63 - loss 2.0635186449901477 - samples/second: 45.29127393086984
05/03/2022 14:10:02 - INFO - train -  epoch 4/1000 - batch 43/63 - loss 2.273685182249823 - samples/second: 45.525264233470516
05/03/2022 14:10:03 - INFO - train -  epoch 4/1000 - batch 49/63 - loss 2.244671124584821 - samples/second: 45.00861709672307
05/03/2022 14:10:04 - INFO - train -  epoch 4/1000 - batch 55/63 - loss 2.287745208090002 - samples/second: 45.40323163360494
05/03/2022 14:10:05 - INFO - train -  epoch 4/1000 - batch 61/63 - loss 2.2040629298960575 - samples/second: 45.392608494418795
05/03/2022 14:10:15 - INFO - train -  Finish evaluation: 9.523211240768433 s
05/03/2022 14:10:15 - INFO - train -  micro-avg: acc 0.5897908169977635 - micro-avg-f1-score 0.7419728566699767
05/03/2022 14:10:15 - INFO - train -  New best model found
05/03/2022 14:10:15 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:10:15 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:10:16 - INFO - train -  epoch 5/1000 - batch 1/63 - loss 1.2671678066253662 - samples/second: 48.58173394336017
05/03/2022 14:10:17 - INFO - train -  epoch 5/1000 - batch 7/63 - loss 2.3346377526010786 - samples/second: 47.08639638481976
05/03/2022 14:10:17 - INFO - train -  epoch 5/1000 - batch 13/63 - loss 2.075734711610354 - samples/second: 50.90753359990271
05/03/2022 14:10:18 - INFO - train -  epoch 5/1000 - batch 19/63 - loss 2.042226807067269 - samples/second: 51.24787778852876
05/03/2022 14:10:19 - INFO - train -  epoch 5/1000 - batch 25/63 - loss 1.979234321117401 - samples/second: 49.408545185781335
05/03/2022 14:10:20 - INFO - train -  epoch 5/1000 - batch 31/63 - loss 2.0004230487731194 - samples/second: 49.21549456162666
05/03/2022 14:10:21 - INFO - train -  epoch 5/1000 - batch 37/63 - loss 1.9848273042086009 - samples/second: 50.1347498673655
05/03/2022 14:10:22 - INFO - train -  epoch 5/1000 - batch 43/63 - loss 2.033343968003295 - samples/second: 50.47877484587578
05/03/2022 14:10:23 - INFO - train -  epoch 5/1000 - batch 49/63 - loss 1.9043908581441762 - samples/second: 51.25034761128619
05/03/2022 14:10:24 - INFO - train -  epoch 5/1000 - batch 55/63 - loss 2.0077918204394254 - samples/second: 49.84122080858965
05/03/2022 14:10:25 - INFO - train -  epoch 5/1000 - batch 61/63 - loss 2.0394555467074036 - samples/second: 49.03060482535117
05/03/2022 14:10:36 - INFO - train -  Finish evaluation: 9.620425939559937 s
05/03/2022 14:10:36 - INFO - train -  micro-avg: acc 0.6027270320360074 - micro-avg-f1-score 0.7521268687536136
05/03/2022 14:10:36 - INFO - train -  New best model found
05/03/2022 14:10:37 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:10:37 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:10:37 - INFO - train -  epoch 6/1000 - batch 1/63 - loss 1.133152961730957 - samples/second: 55.425684057516165
05/03/2022 14:10:38 - INFO - train -  epoch 6/1000 - batch 7/63 - loss 1.6948199101856776 - samples/second: 45.30617392302344
05/03/2022 14:10:39 - INFO - train -  epoch 6/1000 - batch 13/63 - loss 1.822115026987516 - samples/second: 47.51578750378393
05/03/2022 14:10:40 - INFO - train -  epoch 6/1000 - batch 19/63 - loss 1.7004398546720807 - samples/second: 46.3843001170204
05/03/2022 14:10:41 - INFO - train -  epoch 6/1000 - batch 25/63 - loss 1.8100619196891785 - samples/second: 46.12572792730742
05/03/2022 14:10:42 - INFO - train -  epoch 6/1000 - batch 31/63 - loss 1.751644374862794 - samples/second: 44.98121257015697
05/03/2022 14:10:43 - INFO - train -  epoch 6/1000 - batch 37/63 - loss 1.6862215480288945 - samples/second: 44.09346957322051
05/03/2022 14:10:44 - INFO - train -  epoch 6/1000 - batch 43/63 - loss 1.7049222796462302 - samples/second: 44.596726739294525
05/03/2022 14:10:45 - INFO - train -  epoch 6/1000 - batch 49/63 - loss 1.7448725992319536 - samples/second: 44.304179243166466
05/03/2022 14:10:46 - INFO - train -  epoch 6/1000 - batch 55/63 - loss 1.7483703775839372 - samples/second: 44.781250193363206
05/03/2022 14:10:47 - INFO - train -  epoch 6/1000 - batch 61/63 - loss 1.699954267408027 - samples/second: 44.99168881992928
05/03/2022 14:10:57 - INFO - train -  Finish evaluation: 9.672011137008667 s
05/03/2022 14:10:57 - INFO - train -  micro-avg: acc 0.6141710866313069 - micro-avg-f1-score 0.7609739657932427
05/03/2022 14:10:57 - INFO - train -  New best model found
05/03/2022 14:10:58 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:10:58 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:10:58 - INFO - train -  epoch 7/1000 - batch 1/63 - loss 2.3270533084869385 - samples/second: 35.68352521550853
05/03/2022 14:10:59 - INFO - train -  epoch 7/1000 - batch 7/63 - loss 1.81905232157026 - samples/second: 44.9765561106325
05/03/2022 14:11:01 - INFO - train -  epoch 7/1000 - batch 13/63 - loss 1.920744070639977 - samples/second: 44.92508044559299
05/03/2022 14:11:01 - INFO - train -  epoch 7/1000 - batch 19/63 - loss 1.7420882990485744 - samples/second: 47.34837750087209
05/03/2022 14:11:02 - INFO - train -  epoch 7/1000 - batch 25/63 - loss 1.6548036646842956 - samples/second: 49.040620322391234
05/03/2022 14:11:03 - INFO - train -  epoch 7/1000 - batch 31/63 - loss 1.7576458511813995 - samples/second: 49.32773393695809
05/03/2022 14:11:04 - INFO - train -  epoch 7/1000 - batch 37/63 - loss 1.8740648176219012 - samples/second: 48.786809075651085
05/03/2022 14:11:05 - INFO - train -  epoch 7/1000 - batch 43/63 - loss 1.8279045834097751 - samples/second: 47.52189965790003
05/03/2022 14:11:07 - INFO - train -  epoch 7/1000 - batch 49/63 - loss 1.8307729740532077 - samples/second: 47.357905458748476
05/03/2022 14:11:08 - INFO - train -  epoch 7/1000 - batch 55/63 - loss 1.8239316550168123 - samples/second: 47.107582365608096
05/03/2022 14:11:09 - INFO - train -  epoch 7/1000 - batch 61/63 - loss 1.821137013982554 - samples/second: 46.2418104089714
05/03/2022 14:11:19 - INFO - train -  Finish evaluation: 9.615962266921997 s
05/03/2022 14:11:19 - INFO - train -  micro-avg: acc 0.6001328903654485 - micro-avg-f1-score 0.7501038119757494
05/03/2022 14:11:19 - INFO - train -  No improvement since last 1 epochs, best score is 0.7609739657932427
05/03/2022 14:11:19 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:11:19 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:11:19 - INFO - train -  epoch 8/1000 - batch 1/63 - loss 1.3679165840148926 - samples/second: 56.397036479272835
05/03/2022 14:11:20 - INFO - train -  epoch 8/1000 - batch 7/63 - loss 1.8372855867658342 - samples/second: 42.82876173669434
05/03/2022 14:11:21 - INFO - train -  epoch 8/1000 - batch 13/63 - loss 1.9344966870087843 - samples/second: 42.3985801291958
05/03/2022 14:11:22 - INFO - train -  epoch 8/1000 - batch 19/63 - loss 1.7165337581383555 - samples/second: 43.85204652538467
05/03/2022 14:11:23 - INFO - train -  epoch 8/1000 - batch 25/63 - loss 1.642218873500824 - samples/second: 44.85806510193882
05/03/2022 14:11:24 - INFO - train -  epoch 8/1000 - batch 31/63 - loss 1.7537007927894592 - samples/second: 45.7543717904032
05/03/2022 14:11:26 - INFO - train -  epoch 8/1000 - batch 37/63 - loss 1.6546472343238625 - samples/second: 44.9820435806057
05/03/2022 14:11:27 - INFO - train -  epoch 8/1000 - batch 43/63 - loss 1.645030912964843 - samples/second: 45.24436478437988
05/03/2022 14:11:28 - INFO - train -  epoch 8/1000 - batch 49/63 - loss 1.6293234010131992 - samples/second: 45.65696378960033
05/03/2022 14:11:28 - INFO - train -  epoch 8/1000 - batch 55/63 - loss 1.5849730816754428 - samples/second: 46.4842536608583
05/03/2022 14:11:29 - INFO - train -  epoch 8/1000 - batch 61/63 - loss 1.5593807140334708 - samples/second: 46.52440175835396
05/03/2022 14:11:39 - INFO - train -  Finish evaluation: 9.604553937911987 s
05/03/2022 14:11:39 - INFO - train -  micro-avg: acc 0.6040899795501022 - micro-avg-f1-score 0.7531871494135646
05/03/2022 14:11:39 - INFO - train -  No improvement since last 2 epochs, best score is 0.7609739657932427
05/03/2022 14:11:40 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:11:40 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:11:40 - INFO - train -  epoch 9/1000 - batch 1/63 - loss 1.6666605472564697 - samples/second: 35.14075600769957
05/03/2022 14:11:41 - INFO - train -  epoch 9/1000 - batch 7/63 - loss 1.5470945239067078 - samples/second: 50.33684348134504
05/03/2022 14:11:42 - INFO - train -  epoch 9/1000 - batch 13/63 - loss 1.5055293991015508 - samples/second: 48.99057986672818
05/03/2022 14:11:43 - INFO - train -  epoch 9/1000 - batch 19/63 - loss 1.4100741963637502 - samples/second: 50.30510543778875
05/03/2022 14:11:43 - INFO - train -  epoch 9/1000 - batch 25/63 - loss 1.519801881313324 - samples/second: 50.15040144017114
05/03/2022 14:11:45 - INFO - train -  epoch 9/1000 - batch 31/63 - loss 1.6053256777025038 - samples/second: 49.32263262955978
05/03/2022 14:11:46 - INFO - train -  epoch 9/1000 - batch 37/63 - loss 1.5825500987671517 - samples/second: 48.59551098396875
05/03/2022 14:11:47 - INFO - train -  epoch 9/1000 - batch 43/63 - loss 1.580810735392016 - samples/second: 48.943317308364215
05/03/2022 14:11:48 - INFO - train -  epoch 9/1000 - batch 49/63 - loss 1.6016176038858843 - samples/second: 48.336463310695216
05/03/2022 14:11:49 - INFO - train -  epoch 9/1000 - batch 55/63 - loss 1.6473943677815523 - samples/second: 48.05044608305134
05/03/2022 14:11:50 - INFO - train -  epoch 9/1000 - batch 61/63 - loss 1.594639091218104 - samples/second: 47.668668320940256
05/03/2022 14:12:00 - INFO - train -  Finish evaluation: 9.61546778678894 s
05/03/2022 14:12:00 - INFO - train -  micro-avg: acc 0.6145704467353952 - micro-avg-f1-score 0.7612804358930699
05/03/2022 14:12:00 - INFO - train -  New best model found
05/03/2022 14:12:01 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:12:01 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:12:01 - INFO - train -  epoch 10/1000 - batch 1/63 - loss 2.789658546447754 - samples/second: 30.89886034638987
05/03/2022 14:12:02 - INFO - train -  epoch 10/1000 - batch 7/63 - loss 1.6339386020387923 - samples/second: 43.60677877490883
05/03/2022 14:12:03 - INFO - train -  epoch 10/1000 - batch 13/63 - loss 1.5340086313394399 - samples/second: 46.46866333551185
05/03/2022 14:12:04 - INFO - train -  epoch 10/1000 - batch 19/63 - loss 1.6340462220342535 - samples/second: 47.00066741052751
05/03/2022 14:12:05 - INFO - train -  epoch 10/1000 - batch 25/63 - loss 1.770239725112915 - samples/second: 47.37588099734024
05/03/2022 14:12:06 - INFO - train -  epoch 10/1000 - batch 31/63 - loss 1.7170089175624232 - samples/second: 47.71352966971673
05/03/2022 14:12:07 - INFO - train -  epoch 10/1000 - batch 37/63 - loss 1.713339235331561 - samples/second: 47.152681740112236
05/03/2022 14:12:08 - INFO - train -  epoch 10/1000 - batch 43/63 - loss 1.6618920315143675 - samples/second: 47.06220539856943
05/03/2022 14:12:09 - INFO - train -  epoch 10/1000 - batch 49/63 - loss 1.6007696450973044 - samples/second: 47.7475265288371
05/03/2022 14:12:10 - INFO - train -  epoch 10/1000 - batch 55/63 - loss 1.6021073438904503 - samples/second: 48.116136973690985
05/03/2022 14:12:11 - INFO - train -  epoch 10/1000 - batch 61/63 - loss 1.6010645403236639 - samples/second: 47.47592297861925
05/03/2022 14:12:21 - INFO - train -  Finish evaluation: 9.610010623931885 s
05/03/2022 14:12:21 - INFO - train -  micro-avg: acc 0.6233196159122085 - micro-avg-f1-score 0.7679567348318403
05/03/2022 14:12:21 - INFO - train -  New best model found
05/03/2022 14:12:22 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:12:22 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:12:22 - INFO - train -  epoch 11/1000 - batch 1/63 - loss 1.2839770317077637 - samples/second: 46.481686141144365
05/03/2022 14:12:23 - INFO - train -  epoch 11/1000 - batch 7/63 - loss 1.3600572347640991 - samples/second: 42.8450194706124
05/03/2022 14:12:24 - INFO - train -  epoch 11/1000 - batch 13/63 - loss 1.622827676626352 - samples/second: 43.81830767649796
05/03/2022 14:12:25 - INFO - train -  epoch 11/1000 - batch 19/63 - loss 1.606807131516306 - samples/second: 44.14137943306262
05/03/2022 14:12:26 - INFO - train -  epoch 11/1000 - batch 25/63 - loss 1.615416784286499 - samples/second: 43.50017893000531
05/03/2022 14:12:27 - INFO - train -  epoch 11/1000 - batch 31/63 - loss 1.5981351752435007 - samples/second: 44.42263443081176
05/03/2022 14:12:28 - INFO - train -  epoch 11/1000 - batch 37/63 - loss 1.5145452231974215 - samples/second: 44.64691445646851
05/03/2022 14:12:29 - INFO - train -  epoch 11/1000 - batch 43/63 - loss 1.4934423316356749 - samples/second: 45.381783997464126
05/03/2022 14:12:30 - INFO - train -  epoch 11/1000 - batch 49/63 - loss 1.5463042332201589 - samples/second: 46.04125425803298
05/03/2022 14:12:31 - INFO - train -  epoch 11/1000 - batch 55/63 - loss 1.5406142581592908 - samples/second: 45.97782508531213
05/03/2022 14:12:32 - INFO - train -  epoch 11/1000 - batch 61/63 - loss 1.478919925259762 - samples/second: 46.3968831251966
05/03/2022 14:12:42 - INFO - train -  Finish evaluation: 9.624394655227661 s
05/03/2022 14:12:42 - INFO - train -  micro-avg: acc 0.5847211208035951 - micro-avg-f1-score 0.7379482902418683
05/03/2022 14:12:42 - INFO - train -  No improvement since last 1 epochs, best score is 0.7679567348318403
05/03/2022 14:12:42 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:12:42 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:12:42 - INFO - train -  epoch 12/1000 - batch 1/63 - loss 2.9974536895751953 - samples/second: 49.02450755505945
05/03/2022 14:12:43 - INFO - train -  epoch 12/1000 - batch 7/63 - loss 1.5647607701165336 - samples/second: 50.222765045381614
05/03/2022 14:12:44 - INFO - train -  epoch 12/1000 - batch 13/63 - loss 1.7071630221146803 - samples/second: 50.49972273103104
05/03/2022 14:12:45 - INFO - train -  epoch 12/1000 - batch 19/63 - loss 1.6902792704732794 - samples/second: 48.75103923991917
05/03/2022 14:12:46 - INFO - train -  epoch 12/1000 - batch 25/63 - loss 1.7014666938781737 - samples/second: 48.66906316000965
05/03/2022 14:12:47 - INFO - train -  epoch 12/1000 - batch 31/63 - loss 1.5922811012114249 - samples/second: 47.90622093905805
05/03/2022 14:12:48 - INFO - train -  epoch 12/1000 - batch 37/63 - loss 1.5309984893412203 - samples/second: 48.02284213733164
05/03/2022 14:12:50 - INFO - train -  epoch 12/1000 - batch 43/63 - loss 1.5328384319017099 - samples/second: 46.45036613081875
05/03/2022 14:12:51 - INFO - train -  epoch 12/1000 - batch 49/63 - loss 1.5335013282542327 - samples/second: 46.973229381441755
05/03/2022 14:12:52 - INFO - train -  epoch 12/1000 - batch 55/63 - loss 1.5338682185519825 - samples/second: 47.5019393366138
05/03/2022 14:12:53 - INFO - train -  epoch 12/1000 - batch 61/63 - loss 1.5278032754288344 - samples/second: 47.86304439842506
05/03/2022 14:13:02 - INFO - train -  Finish evaluation: 9.59215497970581 s
05/03/2022 14:13:02 - INFO - train -  micro-avg: acc 0.6080476900149031 - micro-avg-f1-score 0.7562557924003708
05/03/2022 14:13:02 - INFO - train -  No improvement since last 2 epochs, best score is 0.7679567348318403
05/03/2022 14:13:03 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:13:03 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:13:03 - INFO - train -  epoch 13/1000 - batch 1/63 - loss 1.5493955612182617 - samples/second: 36.656767551411015
05/03/2022 14:13:04 - INFO - train -  epoch 13/1000 - batch 7/63 - loss 1.7019828047071184 - samples/second: 45.548310804587004
05/03/2022 14:13:05 - INFO - train -  epoch 13/1000 - batch 13/63 - loss 1.5892318762265718 - samples/second: 43.99899011875788
05/03/2022 14:13:06 - INFO - train -  epoch 13/1000 - batch 19/63 - loss 1.5344821904834949 - samples/second: 47.01070422385658
05/03/2022 14:13:07 - INFO - train -  epoch 13/1000 - batch 25/63 - loss 1.6020854711532593 - samples/second: 48.4615665469812
05/03/2022 14:13:08 - INFO - train -  epoch 13/1000 - batch 31/63 - loss 1.5381822682196093 - samples/second: 46.20846311018889
05/03/2022 14:13:09 - INFO - train -  epoch 13/1000 - batch 37/63 - loss 1.5620400164578412 - samples/second: 46.71593793634603
05/03/2022 14:13:10 - INFO - train -  epoch 13/1000 - batch 43/63 - loss 1.6092031445614128 - samples/second: 46.06185197213598
05/03/2022 14:13:11 - INFO - train -  epoch 13/1000 - batch 49/63 - loss 1.5434816041771247 - samples/second: 46.32634413885941
05/03/2022 14:13:12 - INFO - train -  epoch 13/1000 - batch 55/63 - loss 1.6784682999957692 - samples/second: 46.40327187043509
05/03/2022 14:13:13 - INFO - train -  epoch 13/1000 - batch 61/63 - loss 1.6585936380214379 - samples/second: 46.72613068498553
05/03/2022 14:13:23 - INFO - train -  Finish evaluation: 10.038617610931396 s
05/03/2022 14:13:23 - INFO - train -  micro-avg: acc 0.5899148657498363 - micro-avg-f1-score 0.7420710107916633
05/03/2022 14:13:23 - INFO - train -  No improvement since last 3 epochs, best score is 0.7679567348318403
05/03/2022 14:13:24 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:13:24 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:13:24 - INFO - train -  epoch 14/1000 - batch 1/63 - loss 2.4452171325683594 - samples/second: 39.053700765956656
05/03/2022 14:13:25 - INFO - train -  epoch 14/1000 - batch 7/63 - loss 1.6363450288772583 - samples/second: 48.98091529349842
05/03/2022 14:13:26 - INFO - train -  epoch 14/1000 - batch 13/63 - loss 1.5187151844684894 - samples/second: 50.86727848602405
05/03/2022 14:13:27 - INFO - train -  epoch 14/1000 - batch 19/63 - loss 1.615959578438809 - samples/second: 49.36078755614343
05/03/2022 14:13:28 - INFO - train -  epoch 14/1000 - batch 25/63 - loss 1.6391704773902893 - samples/second: 48.32582008094161
05/03/2022 14:13:29 - INFO - train -  epoch 14/1000 - batch 31/63 - loss 1.722763982511336 - samples/second: 48.22215132370529
05/03/2022 14:13:30 - INFO - train -  epoch 14/1000 - batch 37/63 - loss 1.7040992653047717 - samples/second: 48.311350872108314
05/03/2022 14:13:31 - INFO - train -  epoch 14/1000 - batch 43/63 - loss 1.6457313798194708 - samples/second: 48.61342678025833
05/03/2022 14:13:32 - INFO - train -  epoch 14/1000 - batch 49/63 - loss 1.60031151406619 - samples/second: 48.740509588320045
05/03/2022 14:13:33 - INFO - train -  epoch 14/1000 - batch 55/63 - loss 1.533488684350794 - samples/second: 48.56041396399618
05/03/2022 14:13:34 - INFO - train -  epoch 14/1000 - batch 61/63 - loss 1.52274359835953 - samples/second: 47.64530753671763
05/03/2022 14:13:44 - INFO - train -  Finish evaluation: 9.60852313041687 s
05/03/2022 14:13:44 - INFO - train -  micro-avg: acc 0.6234072022160665 - micro-avg-f1-score 0.7680232062110741
05/03/2022 14:13:44 - INFO - train -  change lr from 3e-05 to 1.5e-05
05/03/2022 14:13:44 - INFO - train -  No improvement since last 4 epochs, best score is 0.7679567348318403
05/03/2022 14:13:44 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:13:44 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:13:44 - INFO - train -  epoch 15/1000 - batch 1/63 - loss 2.172853469848633 - samples/second: 39.84959152141202
05/03/2022 14:13:45 - INFO - train -  epoch 15/1000 - batch 7/63 - loss 1.6189172608511788 - samples/second: 43.68209438066005
05/03/2022 14:13:46 - INFO - train -  epoch 15/1000 - batch 13/63 - loss 1.6670211095076342 - samples/second: 45.694707279284906
05/03/2022 14:13:47 - INFO - train -  epoch 15/1000 - batch 19/63 - loss 1.602412832410712 - samples/second: 45.59947598105853
05/03/2022 14:13:48 - INFO - train -  epoch 15/1000 - batch 25/63 - loss 1.5869680976867675 - samples/second: 45.714651928156904
05/03/2022 14:13:49 - INFO - train -  epoch 15/1000 - batch 31/63 - loss 1.6328158609328731 - samples/second: 45.81063419430507
05/03/2022 14:13:51 - INFO - train -  epoch 15/1000 - batch 37/63 - loss 1.690403387353227 - samples/second: 45.65112008900232
05/03/2022 14:13:52 - INFO - train -  epoch 15/1000 - batch 43/63 - loss 1.6985118139621824 - samples/second: 45.22797263289332
05/03/2022 14:13:53 - INFO - train -  epoch 15/1000 - batch 49/63 - loss 1.6652910161991508 - samples/second: 45.25567581007199
05/03/2022 14:13:54 - INFO - train -  epoch 15/1000 - batch 55/63 - loss 1.7470227013934743 - samples/second: 45.76786460582365
05/03/2022 14:13:55 - INFO - train -  epoch 15/1000 - batch 61/63 - loss 1.677288143361201 - samples/second: 45.6753425895573
05/03/2022 14:14:05 - INFO - train -  Finish evaluation: 9.799483060836792 s
05/03/2022 14:14:05 - INFO - train -  micro-avg: acc 0.6202886366820793 - micro-avg-f1-score 0.7656520235212729
05/03/2022 14:14:05 - INFO - train -  No improvement since last 5 epochs, best score is 0.7679567348318403
05/03/2022 14:14:05 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:14:05 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:14:05 - INFO - train -  epoch 16/1000 - batch 1/63 - loss 0.8737455606460571 - samples/second: 58.969016797359664
05/03/2022 14:14:06 - INFO - train -  epoch 16/1000 - batch 7/63 - loss 1.5453975711550032 - samples/second: 51.0292765293291
05/03/2022 14:14:07 - INFO - train -  epoch 16/1000 - batch 13/63 - loss 1.6524218962742732 - samples/second: 49.95267816459063
05/03/2022 14:14:08 - INFO - train -  epoch 16/1000 - batch 19/63 - loss 1.6692172351636385 - samples/second: 49.91424667980417
05/03/2022 14:14:09 - INFO - train -  epoch 16/1000 - batch 25/63 - loss 1.4770845127105714 - samples/second: 47.659444882705074
05/03/2022 14:14:10 - INFO - train -  epoch 16/1000 - batch 31/63 - loss 1.4502761767756553 - samples/second: 47.80312264517249
05/03/2022 14:14:11 - INFO - train -  epoch 16/1000 - batch 37/63 - loss 1.3870886854223303 - samples/second: 48.78572783418996
05/03/2022 14:14:12 - INFO - train -  epoch 16/1000 - batch 43/63 - loss 1.4236651090688484 - samples/second: 48.49973300350319
05/03/2022 14:14:13 - INFO - train -  epoch 16/1000 - batch 49/63 - loss 1.366284796169826 - samples/second: 48.56879788554609
05/03/2022 14:14:14 - INFO - train -  epoch 16/1000 - batch 55/63 - loss 1.3318099043586038 - samples/second: 48.37944968248896
05/03/2022 14:14:15 - INFO - train -  epoch 16/1000 - batch 61/63 - loss 1.298781639239827 - samples/second: 48.578463976963576
05/03/2022 14:14:25 - INFO - train -  Finish evaluation: 9.592650890350342 s
05/03/2022 14:14:25 - INFO - train -  micro-avg: acc 0.6309170552493994 - micro-avg-f1-score 0.7736960665395944
05/03/2022 14:14:25 - INFO - train -  New best model found
05/03/2022 14:14:26 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:14:26 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:14:26 - INFO - train -  epoch 17/1000 - batch 1/63 - loss 1.2799072265625 - samples/second: 51.573010359349546
05/03/2022 14:14:27 - INFO - train -  epoch 17/1000 - batch 7/63 - loss 0.9773637226649693 - samples/second: 44.086700713834304
05/03/2022 14:14:28 - INFO - train -  epoch 17/1000 - batch 13/63 - loss 1.3835965486673207 - samples/second: 42.84428603532461
05/03/2022 14:14:29 - INFO - train -  epoch 17/1000 - batch 19/63 - loss 1.4194705737264532 - samples/second: 43.97389932165881
05/03/2022 14:14:30 - INFO - train -  epoch 17/1000 - batch 25/63 - loss 1.4257460594177247 - samples/second: 44.81778493841554
05/03/2022 14:14:31 - INFO - train -  epoch 17/1000 - batch 31/63 - loss 1.418568257362612 - samples/second: 46.00775869527102
05/03/2022 14:14:32 - INFO - train -  epoch 17/1000 - batch 37/63 - loss 1.5172873735427856 - samples/second: 45.63284392736053
05/03/2022 14:14:34 - INFO - train -  epoch 17/1000 - batch 43/63 - loss 1.5015410850214403 - samples/second: 45.40492961946056
05/03/2022 14:14:35 - INFO - train -  epoch 17/1000 - batch 49/63 - loss 1.5323161665274172 - samples/second: 45.896314353545236
05/03/2022 14:14:36 - INFO - train -  epoch 17/1000 - batch 55/63 - loss 1.6101929686286234 - samples/second: 46.10512343448781
05/03/2022 14:14:37 - INFO - train -  epoch 17/1000 - batch 61/63 - loss 1.569600525449534 - samples/second: 46.18217364162177
05/03/2022 14:14:47 - INFO - train -  Finish evaluation: 9.702764749526978 s
05/03/2022 14:14:47 - INFO - train -  micro-avg: acc 0.6255456977890438 - micro-avg-f1-score 0.7696439400502469
05/03/2022 14:14:47 - INFO - train -  No improvement since last 1 epochs, best score is 0.7736960665395944
05/03/2022 14:14:47 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:14:47 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:14:47 - INFO - train -  epoch 18/1000 - batch 1/63 - loss 1.4469707012176514 - samples/second: 50.246455135318065
05/03/2022 14:14:48 - INFO - train -  epoch 18/1000 - batch 7/63 - loss 1.5451826878956385 - samples/second: 50.62142310493231
05/03/2022 14:14:49 - INFO - train -  epoch 18/1000 - batch 13/63 - loss 1.8105070545123174 - samples/second: 49.634276864993595
05/03/2022 14:14:50 - INFO - train -  epoch 18/1000 - batch 19/63 - loss 1.513741091678017 - samples/second: 48.8256142200743
05/03/2022 14:14:51 - INFO - train -  epoch 18/1000 - batch 25/63 - loss 1.5320358514785766 - samples/second: 48.241567610792146
05/03/2022 14:14:52 - INFO - train -  epoch 18/1000 - batch 31/63 - loss 1.536182822719697 - samples/second: 48.96931302358008
05/03/2022 14:14:53 - INFO - train -  epoch 18/1000 - batch 37/63 - loss 1.5269821978904106 - samples/second: 48.41793437807776
05/03/2022 14:14:54 - INFO - train -  epoch 18/1000 - batch 43/63 - loss 1.4711197240408076 - samples/second: 48.467758358672825
05/03/2022 14:14:55 - INFO - train -  epoch 18/1000 - batch 49/63 - loss 1.4136092760124985 - samples/second: 48.76883862293887
05/03/2022 14:14:56 - INFO - train -  epoch 18/1000 - batch 55/63 - loss 1.4034131873737683 - samples/second: 49.464739321282515
05/03/2022 14:14:57 - INFO - train -  epoch 18/1000 - batch 61/63 - loss 1.3773963539326777 - samples/second: 49.3467122959294
05/03/2022 14:15:07 - INFO - train -  Finish evaluation: 9.533626556396484 s
05/03/2022 14:15:07 - INFO - train -  micro-avg: acc 0.6260061060227589 - micro-avg-f1-score 0.7699923188529487
05/03/2022 14:15:07 - INFO - train -  No improvement since last 2 epochs, best score is 0.7736960665395944
05/03/2022 14:15:07 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:15:07 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:15:07 - INFO - train -  epoch 19/1000 - batch 1/63 - loss 0.39052295684814453 - samples/second: 60.63378237967456
05/03/2022 14:15:08 - INFO - train -  epoch 19/1000 - batch 7/63 - loss 1.495262895311628 - samples/second: 50.29354704571665
05/03/2022 14:15:09 - INFO - train -  epoch 19/1000 - batch 13/63 - loss 1.3351761286075299 - samples/second: 50.98057781420557
05/03/2022 14:15:10 - INFO - train -  epoch 19/1000 - batch 19/63 - loss 1.239451461716702 - samples/second: 52.71931551094349
05/03/2022 14:15:11 - INFO - train -  epoch 19/1000 - batch 25/63 - loss 1.4261980175971984 - samples/second: 48.50607996527799
05/03/2022 14:15:12 - INFO - train -  epoch 19/1000 - batch 31/63 - loss 1.4821434655497152 - samples/second: 49.22454044865764
05/03/2022 14:15:13 - INFO - train -  epoch 19/1000 - batch 37/63 - loss 1.471247089875711 - samples/second: 48.89584785784248
05/03/2022 14:15:14 - INFO - train -  epoch 19/1000 - batch 43/63 - loss 1.5027052053185397 - samples/second: 48.69052644594361
05/03/2022 14:15:15 - INFO - train -  epoch 19/1000 - batch 49/63 - loss 1.4732001192715702 - samples/second: 48.58605515138603
05/03/2022 14:15:16 - INFO - train -  epoch 19/1000 - batch 55/63 - loss 1.48260850798 - samples/second: 47.273607707496616
05/03/2022 14:15:17 - INFO - train -  epoch 19/1000 - batch 61/63 - loss 1.4949456121100755 - samples/second: 47.693605604227216
05/03/2022 14:15:27 - INFO - train -  Finish evaluation: 10.089644432067871 s
05/03/2022 14:15:27 - INFO - train -  micro-avg: acc 0.6195135588481968 - micro-avg-f1-score 0.7650612808562058
05/03/2022 14:15:27 - INFO - train -  No improvement since last 3 epochs, best score is 0.7736960665395944
05/03/2022 14:15:27 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:15:27 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:15:28 - INFO - train -  epoch 20/1000 - batch 1/63 - loss 1.7772479057312012 - samples/second: 40.32713182766545
05/03/2022 14:15:29 - INFO - train -  epoch 20/1000 - batch 7/63 - loss 1.3670372452054704 - samples/second: 45.712109549776216
05/03/2022 14:15:30 - INFO - train -  epoch 20/1000 - batch 13/63 - loss 1.2724119837467487 - samples/second: 46.14833351565239
05/03/2022 14:15:31 - INFO - train -  epoch 20/1000 - batch 19/63 - loss 1.3648077500493903 - samples/second: 45.58558300117229
05/03/2022 14:15:32 - INFO - train -  epoch 20/1000 - batch 25/63 - loss 1.4144408416748047 - samples/second: 47.08624724325738
05/03/2022 14:15:33 - INFO - train -  epoch 20/1000 - batch 31/63 - loss 1.5620706831255267 - samples/second: 45.901658234050636
05/03/2022 14:15:34 - INFO - train -  epoch 20/1000 - batch 37/63 - loss 1.521777489700833 - samples/second: 46.70455871611047
05/03/2022 14:15:35 - INFO - train -  epoch 20/1000 - batch 43/63 - loss 1.4797914818275806 - samples/second: 47.05916003066261
05/03/2022 14:15:36 - INFO - train -  epoch 20/1000 - batch 49/63 - loss 1.5428010286117086 - samples/second: 47.015114508767454
05/03/2022 14:15:37 - INFO - train -  epoch 20/1000 - batch 55/63 - loss 1.5449842073700644 - samples/second: 46.855983591540166
05/03/2022 14:15:38 - INFO - train -  epoch 20/1000 - batch 61/63 - loss 1.5381871755005883 - samples/second: 46.24708359093058
05/03/2022 14:15:48 - INFO - train -  Finish evaluation: 9.571817874908447 s
05/03/2022 14:15:48 - INFO - train -  micro-avg: acc 0.6369417945527444 - micro-avg-f1-score 0.7782094594594594
05/03/2022 14:15:48 - INFO - train -  New best model found
05/03/2022 14:15:49 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:15:49 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:15:49 - INFO - train -  epoch 21/1000 - batch 1/63 - loss 0.5800879597663879 - samples/second: 43.59162060162781
05/03/2022 14:15:50 - INFO - train -  epoch 21/1000 - batch 7/63 - loss 1.345515957900456 - samples/second: 51.29571431067317
05/03/2022 14:15:51 - INFO - train -  epoch 21/1000 - batch 13/63 - loss 1.533996467406933 - samples/second: 41.80979539820403
05/03/2022 14:15:53 - INFO - train -  epoch 21/1000 - batch 19/63 - loss 1.4604264246790033 - samples/second: 39.79047975693846
05/03/2022 14:15:54 - INFO - train -  epoch 21/1000 - batch 25/63 - loss 1.437080080509186 - samples/second: 40.08752860712625
05/03/2022 14:15:55 - INFO - train -  epoch 21/1000 - batch 31/63 - loss 1.4068113353944594 - samples/second: 41.536390364063564
05/03/2022 14:15:56 - INFO - train -  epoch 21/1000 - batch 37/63 - loss 1.3099073139396873 - samples/second: 40.32082688364343
05/03/2022 14:15:57 - INFO - train -  epoch 21/1000 - batch 43/63 - loss 1.255506275698196 - samples/second: 40.49894759870421
05/03/2022 14:15:58 - INFO - train -  epoch 21/1000 - batch 49/63 - loss 1.2354455663233388 - samples/second: 41.850549218610816
05/03/2022 14:15:59 - INFO - train -  epoch 21/1000 - batch 55/63 - loss 1.2790273666381835 - samples/second: 42.488724621621145
05/03/2022 14:16:00 - INFO - train -  epoch 21/1000 - batch 61/63 - loss 1.2819130147089723 - samples/second: 42.96866505360134
05/03/2022 14:16:12 - INFO - train -  Finish evaluation: 11.66593313217163 s
05/03/2022 14:16:12 - INFO - train -  micro-avg: acc 0.6400167434072834 - micro-avg-f1-score 0.7805002552322613
05/03/2022 14:16:12 - INFO - train -  New best model found
05/03/2022 14:16:13 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:16:13 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:16:13 - INFO - train -  epoch 22/1000 - batch 1/63 - loss 0.988142728805542 - samples/second: 33.33190818098375
05/03/2022 14:16:14 - INFO - train -  epoch 22/1000 - batch 7/63 - loss 1.0426741072109766 - samples/second: 46.56294008159977
05/03/2022 14:16:15 - INFO - train -  epoch 22/1000 - batch 13/63 - loss 1.1985280559613154 - samples/second: 46.126056865181134
05/03/2022 14:16:17 - INFO - train -  epoch 22/1000 - batch 19/63 - loss 1.1191214166189496 - samples/second: 42.99558319114642
05/03/2022 14:16:18 - INFO - train -  epoch 22/1000 - batch 25/63 - loss 1.2135034060478211 - samples/second: 41.75360182085867
05/03/2022 14:16:19 - INFO - train -  epoch 22/1000 - batch 31/63 - loss 1.2772123871311065 - samples/second: 43.12146263539255
05/03/2022 14:16:20 - INFO - train -  epoch 22/1000 - batch 37/63 - loss 1.3139558321720846 - samples/second: 42.95150060439329
05/03/2022 14:16:21 - INFO - train -  epoch 22/1000 - batch 43/63 - loss 1.285797729048618 - samples/second: 43.77238466143249
05/03/2022 14:16:22 - INFO - train -  epoch 22/1000 - batch 49/63 - loss 1.2995126028450168 - samples/second: 42.352606996433884
05/03/2022 14:16:24 - INFO - train -  epoch 22/1000 - batch 55/63 - loss 1.2699782447381454 - samples/second: 41.63228057260675
05/03/2022 14:16:25 - INFO - train -  epoch 22/1000 - batch 61/63 - loss 1.2869499032614662 - samples/second: 41.648107391307775
05/03/2022 14:16:37 - INFO - train -  Finish evaluation: 11.693707942962646 s
05/03/2022 14:16:37 - INFO - train -  micro-avg: acc 0.6267981915330867 - micro-avg-f1-score 0.7705912076806468
05/03/2022 14:16:37 - INFO - train -  No improvement since last 1 epochs, best score is 0.7805002552322613
05/03/2022 14:16:37 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:16:37 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:16:37 - INFO - train -  epoch 23/1000 - batch 1/63 - loss 0.5530781745910645 - samples/second: 48.29018061452112
05/03/2022 14:16:38 - INFO - train -  epoch 23/1000 - batch 7/63 - loss 1.2575815064566476 - samples/second: 50.49328421610206
05/03/2022 14:16:39 - INFO - train -  epoch 23/1000 - batch 13/63 - loss 1.5462935887850249 - samples/second: 46.12354507710069
05/03/2022 14:16:40 - INFO - train -  epoch 23/1000 - batch 19/63 - loss 1.5180197671840066 - samples/second: 45.44167530012171
05/03/2022 14:16:42 - INFO - train -  epoch 23/1000 - batch 25/63 - loss 1.5104087114334106 - samples/second: 42.423164160385156
05/03/2022 14:16:43 - INFO - train -  epoch 23/1000 - batch 31/63 - loss 1.4614680101794582 - samples/second: 42.14127732642967
05/03/2022 14:16:44 - INFO - train -  epoch 23/1000 - batch 37/63 - loss 1.459968107777673 - samples/second: 42.89372877946069
05/03/2022 14:16:45 - INFO - train -  epoch 23/1000 - batch 43/63 - loss 1.443288767060568 - samples/second: 43.032486197586984
05/03/2022 14:16:46 - INFO - train -  epoch 23/1000 - batch 49/63 - loss 1.392155223963212 - samples/second: 42.78918744932313
05/03/2022 14:16:47 - INFO - train -  epoch 23/1000 - batch 55/63 - loss 1.399701264771548 - samples/second: 43.15903603131034
05/03/2022 14:16:48 - INFO - train -  epoch 23/1000 - batch 61/63 - loss 1.4327712528041152 - samples/second: 43.1275796275161
05/03/2022 14:17:00 - INFO - train -  Finish evaluation: 10.547450065612793 s
05/03/2022 14:17:00 - INFO - train -  micro-avg: acc 0.6039345164396753 - micro-avg-f1-score 0.7530663007118963
05/03/2022 14:17:00 - INFO - train -  No improvement since last 2 epochs, best score is 0.7805002552322613
05/03/2022 14:17:00 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:17:00 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:17:00 - INFO - train -  epoch 24/1000 - batch 1/63 - loss 3.1190409660339355 - samples/second: 38.585831498208954
05/03/2022 14:17:01 - INFO - train -  epoch 24/1000 - batch 7/63 - loss 2.053152961390359 - samples/second: 48.24888493755178
05/03/2022 14:17:02 - INFO - train -  epoch 24/1000 - batch 13/63 - loss 1.6336293449768653 - samples/second: 40.85538327243846
05/03/2022 14:17:04 - INFO - train -  epoch 24/1000 - batch 19/63 - loss 1.5037126227429038 - samples/second: 39.68200133448856
05/03/2022 14:17:04 - INFO - train -  epoch 24/1000 - batch 25/63 - loss 1.4112803077697753 - samples/second: 42.276926252773904
05/03/2022 14:17:06 - INFO - train -  epoch 24/1000 - batch 31/63 - loss 1.3694336837337864 - samples/second: 42.30232490328035
05/03/2022 14:17:07 - INFO - train -  epoch 24/1000 - batch 37/63 - loss 1.4113928031277012 - samples/second: 43.213764091914136
05/03/2022 14:17:08 - INFO - train -  epoch 24/1000 - batch 43/63 - loss 1.3849864796150562 - samples/second: 44.02973186683987
05/03/2022 14:17:09 - INFO - train -  epoch 24/1000 - batch 49/63 - loss 1.5357569370950972 - samples/second: 43.57478913032981
05/03/2022 14:17:10 - INFO - train -  epoch 24/1000 - batch 55/63 - loss 1.5002769296819514 - samples/second: 43.18004424290725
05/03/2022 14:17:11 - INFO - train -  epoch 24/1000 - batch 61/63 - loss 1.473045226003303 - samples/second: 42.6836378526615
05/03/2022 14:17:22 - INFO - train -  Finish evaluation: 10.90612530708313 s
05/03/2022 14:17:23 - INFO - train -  micro-avg: acc 0.6492790500424088 - micro-avg-f1-score 0.7873489328876317
05/03/2022 14:17:23 - INFO - train -  New best model found
05/03/2022 14:17:23 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:17:23 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:17:24 - INFO - train -  epoch 25/1000 - batch 1/63 - loss 1.4113881587982178 - samples/second: 42.505709327219066
05/03/2022 14:17:24 - INFO - train -  epoch 25/1000 - batch 7/63 - loss 1.8763079813548498 - samples/second: 49.96656373304425
05/03/2022 14:17:25 - INFO - train -  epoch 25/1000 - batch 13/63 - loss 1.5672302842140198 - samples/second: 48.638997782069204
05/03/2022 14:17:27 - INFO - train -  epoch 25/1000 - batch 19/63 - loss 1.4298125819156045 - samples/second: 47.86890495412453
05/03/2022 14:17:28 - INFO - train -  epoch 25/1000 - batch 25/63 - loss 1.3680522561073303 - samples/second: 45.85751798593597
05/03/2022 14:17:29 - INFO - train -  epoch 25/1000 - batch 31/63 - loss 1.3503176992939365 - samples/second: 44.59158410886206
05/03/2022 14:17:30 - INFO - train -  epoch 25/1000 - batch 37/63 - loss 1.3591807275205046 - samples/second: 44.87401185665389
05/03/2022 14:17:31 - INFO - train -  epoch 25/1000 - batch 43/63 - loss 1.3328691637793253 - samples/second: 44.23212444585709
05/03/2022 14:17:32 - INFO - train -  epoch 25/1000 - batch 49/63 - loss 1.310631932044516 - samples/second: 45.1908138725211
05/03/2022 14:17:33 - INFO - train -  epoch 25/1000 - batch 55/63 - loss 1.2791564334522594 - samples/second: 44.677139817696805
05/03/2022 14:17:35 - INFO - train -  epoch 25/1000 - batch 61/63 - loss 1.3188771537092865 - samples/second: 42.90284252400774
05/03/2022 14:17:46 - INFO - train -  Finish evaluation: 11.34155011177063 s
05/03/2022 14:17:47 - INFO - train -  micro-avg: acc 0.6295054484492875 - micro-avg-f1-score 0.7726337448559671
05/03/2022 14:17:47 - INFO - train -  No improvement since last 1 epochs, best score is 0.7873489328876317
05/03/2022 14:17:47 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:17:47 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:17:47 - INFO - train -  epoch 26/1000 - batch 1/63 - loss 1.4167571067810059 - samples/second: 49.58333628873048
05/03/2022 14:17:48 - INFO - train -  epoch 26/1000 - batch 7/63 - loss 1.418986780302865 - samples/second: 47.72849174112527
05/03/2022 14:17:49 - INFO - train -  epoch 26/1000 - batch 13/63 - loss 1.2818959263654857 - samples/second: 49.551163807244116
05/03/2022 14:17:50 - INFO - train -  epoch 26/1000 - batch 19/63 - loss 1.2560012277803922 - samples/second: 50.498479027819805
05/03/2022 14:17:51 - INFO - train -  epoch 26/1000 - batch 25/63 - loss 1.264379961490631 - samples/second: 48.68445710463271
05/03/2022 14:17:52 - INFO - train -  epoch 26/1000 - batch 31/63 - loss 1.2546128207637417 - samples/second: 45.59446740681501
05/03/2022 14:17:53 - INFO - train -  epoch 26/1000 - batch 37/63 - loss 1.2798167225476857 - samples/second: 44.9992165186403
05/03/2022 14:17:54 - INFO - train -  epoch 26/1000 - batch 43/63 - loss 1.244307397409927 - samples/second: 45.67962828187248
05/03/2022 14:17:55 - INFO - train -  epoch 26/1000 - batch 49/63 - loss 1.1677580597449322 - samples/second: 46.689777687815386
05/03/2022 14:17:57 - INFO - train -  epoch 26/1000 - batch 55/63 - loss 1.215202680501071 - samples/second: 43.85721610608772
05/03/2022 14:17:58 - INFO - train -  epoch 26/1000 - batch 61/63 - loss 1.215775728225708 - samples/second: 42.70287286833563
05/03/2022 14:18:09 - INFO - train -  Finish evaluation: 10.221580266952515 s
05/03/2022 14:18:09 - INFO - train -  micro-avg: acc 0.643969422423556 - micro-avg-f1-score 0.7834323602858866
05/03/2022 14:18:09 - INFO - train -  No improvement since last 2 epochs, best score is 0.7873489328876317
05/03/2022 14:18:09 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:18:09 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:18:09 - INFO - train -  epoch 27/1000 - batch 1/63 - loss 1.1291882991790771 - samples/second: 47.38717481227695
05/03/2022 14:18:10 - INFO - train -  epoch 27/1000 - batch 7/63 - loss 0.8065417834690639 - samples/second: 37.94892266599714
05/03/2022 14:18:11 - INFO - train -  epoch 27/1000 - batch 13/63 - loss 1.146828124156365 - samples/second: 37.16103002238483
05/03/2022 14:18:13 - INFO - train -  epoch 27/1000 - batch 19/63 - loss 1.0433627084681862 - samples/second: 37.822259985104466
05/03/2022 14:18:14 - INFO - train -  epoch 27/1000 - batch 25/63 - loss 1.0358470797538757 - samples/second: 37.92775214554556
05/03/2022 14:18:15 - INFO - train -  epoch 27/1000 - batch 31/63 - loss 1.1699208809483437 - samples/second: 39.491318619418095
05/03/2022 14:18:16 - INFO - train -  epoch 27/1000 - batch 37/63 - loss 1.2812975016800132 - samples/second: 40.08582447863104
05/03/2022 14:18:17 - INFO - train -  epoch 27/1000 - batch 43/63 - loss 1.2847577624542768 - samples/second: 39.09193558866253
05/03/2022 14:18:18 - INFO - train -  epoch 27/1000 - batch 49/63 - loss 1.2330492041548904 - samples/second: 40.174037739035654
05/03/2022 14:18:19 - INFO - train -  epoch 27/1000 - batch 55/63 - loss 1.2258111162619156 - samples/second: 41.2174103019128
05/03/2022 14:18:20 - INFO - train -  epoch 27/1000 - batch 61/63 - loss 1.221172151995487 - samples/second: 42.143918816317
05/03/2022 14:18:31 - INFO - train -  Finish evaluation: 10.86542296409607 s
05/03/2022 14:18:32 - INFO - train -  micro-avg: acc 0.62013256006628 - micro-avg-f1-score 0.7655331117361288
05/03/2022 14:18:32 - INFO - train -  No improvement since last 3 epochs, best score is 0.7873489328876317
05/03/2022 14:18:32 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:18:32 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:18:32 - INFO - train -  epoch 28/1000 - batch 1/63 - loss 1.6415563821792603 - samples/second: 60.634001514294546
05/03/2022 14:18:33 - INFO - train -  epoch 28/1000 - batch 7/63 - loss 1.705091186932155 - samples/second: 50.47061884900072
05/03/2022 14:18:34 - INFO - train -  epoch 28/1000 - batch 13/63 - loss 1.275090245100168 - samples/second: 48.78476018436783
05/03/2022 14:18:35 - INFO - train -  epoch 28/1000 - batch 19/63 - loss 1.2474592767263715 - samples/second: 48.38953894795933
05/03/2022 14:18:36 - INFO - train -  epoch 28/1000 - batch 25/63 - loss 1.4237462210655212 - samples/second: 43.80499084825078
05/03/2022 14:18:37 - INFO - train -  epoch 28/1000 - batch 31/63 - loss 1.3693008172896601 - samples/second: 42.947371202567396
05/03/2022 14:18:38 - INFO - train -  epoch 28/1000 - batch 37/63 - loss 1.3280946580139366 - samples/second: 43.43917013680438
05/03/2022 14:18:39 - INFO - train -  epoch 28/1000 - batch 43/63 - loss 1.3005732006804889 - samples/second: 44.02561408252764
05/03/2022 14:18:40 - INFO - train -  epoch 28/1000 - batch 49/63 - loss 1.282316421975895 - samples/second: 43.78960753479668
05/03/2022 14:18:42 - INFO - train -  epoch 28/1000 - batch 55/63 - loss 1.283730323748155 - samples/second: 43.113885755175374
05/03/2022 14:18:43 - INFO - train -  epoch 28/1000 - batch 61/63 - loss 1.2799744049056632 - samples/second: 43.04892633873616
05/03/2022 14:18:55 - INFO - train -  Finish evaluation: 11.384205102920532 s
05/03/2022 14:18:55 - INFO - train -  micro-avg: acc 0.6453374404928591 - micro-avg-f1-score 0.784443877116841
05/03/2022 14:18:55 - INFO - train -  change lr from 1.5e-05 to 7.5e-06
05/03/2022 14:18:55 - INFO - train -  No improvement since last 4 epochs, best score is 0.7873489328876317
05/03/2022 14:18:55 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:18:55 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:18:55 - INFO - train -  epoch 29/1000 - batch 1/63 - loss 0.7882388830184937 - samples/second: 67.48529698659121
05/03/2022 14:18:56 - INFO - train -  epoch 29/1000 - batch 7/63 - loss 1.202208433832441 - samples/second: 50.768675638901584
05/03/2022 14:18:57 - INFO - train -  epoch 29/1000 - batch 13/63 - loss 1.1461204611338103 - samples/second: 38.43991787995129
05/03/2022 14:18:59 - INFO - train -  epoch 29/1000 - batch 19/63 - loss 1.0736272178198163 - samples/second: 40.016282332205826
05/03/2022 14:18:59 - INFO - train -  epoch 29/1000 - batch 25/63 - loss 1.099859447479248 - samples/second: 42.12477470302378
05/03/2022 14:19:01 - INFO - train -  epoch 29/1000 - batch 31/63 - loss 1.136847230695909 - samples/second: 40.897331513100866
05/03/2022 14:19:02 - INFO - train -  epoch 29/1000 - batch 37/63 - loss 1.1862243252831537 - samples/second: 41.69405185553232
05/03/2022 14:19:04 - INFO - train -  epoch 29/1000 - batch 43/63 - loss 1.1881790881933167 - samples/second: 39.25492119431616
05/03/2022 14:19:05 - INFO - train -  epoch 29/1000 - batch 49/63 - loss 1.1941972423572929 - samples/second: 39.50607263615937
05/03/2022 14:19:05 - INFO - train -  epoch 29/1000 - batch 55/63 - loss 1.1671326637268067 - samples/second: 41.029245046666226
05/03/2022 14:19:06 - INFO - train -  epoch 29/1000 - batch 61/63 - loss 1.1524593341545981 - samples/second: 41.77781388271034
05/03/2022 14:19:18 - INFO - train -  Finish evaluation: 11.064284324645996 s
05/03/2022 14:19:18 - INFO - train -  micro-avg: acc 0.6333751218832706 - micro-avg-f1-score 0.7755415316390927
05/03/2022 14:19:18 - INFO - train -  No improvement since last 5 epochs, best score is 0.7873489328876317
05/03/2022 14:19:18 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:19:18 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:19:18 - INFO - train -  epoch 30/1000 - batch 1/63 - loss 1.0908129215240479 - samples/second: 45.8254274995459
05/03/2022 14:19:19 - INFO - train -  epoch 30/1000 - batch 7/63 - loss 1.2624743580818176 - samples/second: 50.80240851853702
05/03/2022 14:19:20 - INFO - train -  epoch 30/1000 - batch 13/63 - loss 1.1548756865354686 - samples/second: 44.19739171042845
05/03/2022 14:19:22 - INFO - train -  epoch 30/1000 - batch 19/63 - loss 1.1354441485906903 - samples/second: 40.28878513301632
05/03/2022 14:19:23 - INFO - train -  epoch 30/1000 - batch 25/63 - loss 1.2812530207633972 - samples/second: 39.553753960570106
05/03/2022 14:19:24 - INFO - train -  epoch 30/1000 - batch 31/63 - loss 1.270003363009422 - samples/second: 38.708730465148605
05/03/2022 14:19:25 - INFO - train -  epoch 30/1000 - batch 37/63 - loss 1.2215001083709098 - samples/second: 40.13820396249973
05/03/2022 14:19:26 - INFO - train -  epoch 30/1000 - batch 43/63 - loss 1.133074512315351 - samples/second: 41.7800964094654
05/03/2022 14:19:27 - INFO - train -  epoch 30/1000 - batch 49/63 - loss 1.1567572999973685 - samples/second: 42.6994210297887
05/03/2022 14:19:29 - INFO - train -  epoch 30/1000 - batch 55/63 - loss 1.1701809417117726 - samples/second: 41.85804913387227
05/03/2022 14:19:30 - INFO - train -  epoch 30/1000 - batch 61/63 - loss 1.218976909019908 - samples/second: 41.53978656336024
05/03/2022 14:19:41 - INFO - train -  Finish evaluation: 10.599531888961792 s
05/03/2022 14:19:41 - INFO - train -  micro-avg: acc 0.6371456776195177 - micro-avg-f1-score 0.7783616159875959
05/03/2022 14:19:41 - INFO - train -  No improvement since last 6 epochs, best score is 0.7873489328876317
05/03/2022 14:19:41 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:19:41 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:19:41 - INFO - train -  epoch 31/1000 - batch 1/63 - loss 0.6692336797714233 - samples/second: 36.135675577879056
05/03/2022 14:19:42 - INFO - train -  epoch 31/1000 - batch 7/63 - loss 0.7005110808781215 - samples/second: 34.65778230409799
05/03/2022 14:19:44 - INFO - train -  epoch 31/1000 - batch 13/63 - loss 0.9311124911675086 - samples/second: 36.30211386630819
05/03/2022 14:19:45 - INFO - train -  epoch 31/1000 - batch 19/63 - loss 0.9528810664227134 - samples/second: 39.874001663297726
05/03/2022 14:19:46 - INFO - train -  epoch 31/1000 - batch 25/63 - loss 0.9914581561088562 - samples/second: 41.873885278462616
05/03/2022 14:19:47 - INFO - train -  epoch 31/1000 - batch 31/63 - loss 1.0714920451564174 - samples/second: 42.59463486185035
05/03/2022 14:19:48 - INFO - train -  epoch 31/1000 - batch 37/63 - loss 1.0294276379250191 - samples/second: 42.400045162455235
05/03/2022 14:19:49 - INFO - train -  epoch 31/1000 - batch 43/63 - loss 1.0783444559851358 - samples/second: 41.55658789339831
05/03/2022 14:19:50 - INFO - train -  epoch 31/1000 - batch 49/63 - loss 1.0745650201427692 - samples/second: 42.41700895656047
05/03/2022 14:19:51 - INFO - train -  epoch 31/1000 - batch 55/63 - loss 1.0803990374911916 - samples/second: 43.21354270878762
05/03/2022 14:19:52 - INFO - train -  epoch 31/1000 - batch 61/63 - loss 1.0769836931932169 - samples/second: 42.72719790399168
05/03/2022 14:20:03 - INFO - train -  Finish evaluation: 10.24191665649414 s
05/03/2022 14:20:03 - INFO - train -  micro-avg: acc 0.650007180812868 - micro-avg-f1-score 0.7878840630167988
05/03/2022 14:20:03 - INFO - train -  New best model found
05/03/2022 14:20:04 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:20:04 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:20:04 - INFO - train -  epoch 32/1000 - batch 1/63 - loss 0.1615837812423706 - samples/second: 28.664791812605717
05/03/2022 14:20:06 - INFO - train -  epoch 32/1000 - batch 7/63 - loss 1.2050523502486092 - samples/second: 37.76244106879075
05/03/2022 14:20:07 - INFO - train -  epoch 32/1000 - batch 13/63 - loss 1.2672897898233855 - samples/second: 42.04848466153585
05/03/2022 14:20:08 - INFO - train -  epoch 32/1000 - batch 19/63 - loss 1.2930108277421248 - samples/second: 42.8907823807527
05/03/2022 14:20:09 - INFO - train -  epoch 32/1000 - batch 25/63 - loss 1.262444598674774 - samples/second: 43.804798700781596
05/03/2022 14:20:10 - INFO - train -  epoch 32/1000 - batch 31/63 - loss 1.2763081346788714 - samples/second: 42.6574298254834
05/03/2022 14:20:11 - INFO - train -  epoch 32/1000 - batch 37/63 - loss 1.193479769938701 - samples/second: 42.63156131913579
05/03/2022 14:20:12 - INFO - train -  epoch 32/1000 - batch 43/63 - loss 1.227677442306696 - samples/second: 43.39977750268496
05/03/2022 14:20:13 - INFO - train -  epoch 32/1000 - batch 49/63 - loss 1.2260314810032746 - samples/second: 43.3023196990721
05/03/2022 14:20:14 - INFO - train -  epoch 32/1000 - batch 55/63 - loss 1.247521838274869 - samples/second: 42.87996130729699
05/03/2022 14:20:16 - INFO - train -  epoch 32/1000 - batch 61/63 - loss 1.2193964309379703 - samples/second: 42.05752091666895
05/03/2022 14:20:28 - INFO - train -  Finish evaluation: 11.394686460494995 s
05/03/2022 14:20:28 - INFO - train -  micro-avg: acc 0.6403927068723703 - micro-avg-f1-score 0.78077975376197
05/03/2022 14:20:28 - INFO - train -  No improvement since last 1 epochs, best score is 0.7878840630167988
05/03/2022 14:20:28 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:20:28 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:20:28 - INFO - train -  epoch 33/1000 - batch 1/63 - loss 1.0178040266036987 - samples/second: 53.943517102900344
05/03/2022 14:20:29 - INFO - train -  epoch 33/1000 - batch 7/63 - loss 1.1001034804752894 - samples/second: 49.56431452438259
05/03/2022 14:20:30 - INFO - train -  epoch 33/1000 - batch 13/63 - loss 1.1715558308821459 - samples/second: 50.80760386228887
05/03/2022 14:20:31 - INFO - train -  epoch 33/1000 - batch 19/63 - loss 1.3426787100340192 - samples/second: 49.04880490440189
05/03/2022 14:20:32 - INFO - train -  epoch 33/1000 - batch 25/63 - loss 1.2579292106628417 - samples/second: 44.356356233982595
05/03/2022 14:20:33 - INFO - train -  epoch 33/1000 - batch 31/63 - loss 1.2458186264960998 - samples/second: 44.19037164162168
05/03/2022 14:20:34 - INFO - train -  epoch 33/1000 - batch 37/63 - loss 1.276917795877199 - samples/second: 45.19422391197815
05/03/2022 14:20:35 - INFO - train -  epoch 33/1000 - batch 43/63 - loss 1.2989535664403162 - samples/second: 45.360619864928
05/03/2022 14:20:36 - INFO - train -  epoch 33/1000 - batch 49/63 - loss 1.2356354180647402 - samples/second: 46.078491774494275
05/03/2022 14:20:37 - INFO - train -  epoch 33/1000 - batch 55/63 - loss 1.2223879131403836 - samples/second: 46.0120394130664
05/03/2022 14:20:39 - INFO - train -  epoch 33/1000 - batch 61/63 - loss 1.2108593934872112 - samples/second: 44.27130991983702
05/03/2022 14:20:50 - INFO - train -  Finish evaluation: 10.582173347473145 s
05/03/2022 14:20:50 - INFO - train -  micro-avg: acc 0.6405633802816901 - micro-avg-f1-score 0.7809065934065934
05/03/2022 14:20:50 - INFO - train -  No improvement since last 2 epochs, best score is 0.7878840630167988
05/03/2022 14:20:50 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:20:50 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:20:50 - INFO - train -  epoch 34/1000 - batch 1/63 - loss 0.47438716888427734 - samples/second: 30.839195070056846
05/03/2022 14:20:52 - INFO - train -  epoch 34/1000 - batch 7/63 - loss 1.1565500072070531 - samples/second: 34.92013866897881
05/03/2022 14:20:53 - INFO - train -  epoch 34/1000 - batch 13/63 - loss 1.0409101935533376 - samples/second: 38.842196492313484
05/03/2022 14:20:54 - INFO - train -  epoch 34/1000 - batch 19/63 - loss 1.2854846998264915 - samples/second: 39.17780842188579
05/03/2022 14:20:55 - INFO - train -  epoch 34/1000 - batch 25/63 - loss 1.2566908383369446 - samples/second: 41.02376711926146
05/03/2022 14:20:56 - INFO - train -  epoch 34/1000 - batch 31/63 - loss 1.2190121431504526 - samples/second: 40.02863039969276
05/03/2022 14:20:57 - INFO - train -  epoch 34/1000 - batch 37/63 - loss 1.1590352702785183 - samples/second: 41.44536379155477
05/03/2022 14:20:58 - INFO - train -  epoch 34/1000 - batch 43/63 - loss 1.2042151135067607 - samples/second: 42.31260245187421
05/03/2022 14:20:59 - INFO - train -  epoch 34/1000 - batch 49/63 - loss 1.1770260236701187 - samples/second: 43.196166293901165
05/03/2022 14:21:00 - INFO - train -  epoch 34/1000 - batch 55/63 - loss 1.191830984028903 - samples/second: 43.129668530725326
05/03/2022 14:21:02 - INFO - train -  epoch 34/1000 - batch 61/63 - loss 1.2188964534978397 - samples/second: 41.97600148313184
05/03/2022 14:21:12 - INFO - train -  Finish evaluation: 10.228028774261475 s
05/03/2022 14:21:12 - INFO - train -  micro-avg: acc 0.6274131274131274 - micro-avg-f1-score 0.7710557532621589
05/03/2022 14:21:12 - INFO - train -  No improvement since last 3 epochs, best score is 0.7878840630167988
05/03/2022 14:21:12 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:21:12 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:21:13 - INFO - train -  epoch 35/1000 - batch 1/63 - loss 1.1433138847351074 - samples/second: 40.122050581782574
05/03/2022 14:21:14 - INFO - train -  epoch 35/1000 - batch 7/63 - loss 0.9088248865944999 - samples/second: 38.11004714897105
05/03/2022 14:21:15 - INFO - train -  epoch 35/1000 - batch 13/63 - loss 0.9962105888586777 - samples/second: 39.51437267182247
05/03/2022 14:21:16 - INFO - train -  epoch 35/1000 - batch 19/63 - loss 0.9811228764684576 - samples/second: 41.16906961668067
05/03/2022 14:21:17 - INFO - train -  epoch 35/1000 - batch 25/63 - loss 0.9019906711578369 - samples/second: 43.187011639363725
05/03/2022 14:21:18 - INFO - train -  epoch 35/1000 - batch 31/63 - loss 0.9841139047376571 - samples/second: 42.30144754282423
05/03/2022 14:21:20 - INFO - train -  epoch 35/1000 - batch 37/63 - loss 1.0725470330264117 - samples/second: 40.68015349564734
05/03/2022 14:21:21 - INFO - train -  epoch 35/1000 - batch 43/63 - loss 1.0644910086032957 - samples/second: 40.67242172202552
05/03/2022 14:21:22 - INFO - train -  epoch 35/1000 - batch 49/63 - loss 1.066279014762567 - samples/second: 40.57166794390269
05/03/2022 14:21:23 - INFO - train -  epoch 35/1000 - batch 55/63 - loss 1.0593952200629495 - samples/second: 40.886802858545515
05/03/2022 14:21:24 - INFO - train -  epoch 35/1000 - batch 61/63 - loss 1.0751624517753475 - samples/second: 41.77722550708981
05/03/2022 14:21:36 - INFO - train -  Finish evaluation: 11.32666802406311 s
05/03/2022 14:21:36 - INFO - train -  micro-avg: acc 0.6319315751960085 - micro-avg-f1-score 0.7744584206848357
05/03/2022 14:21:36 - INFO - train -  change lr from 7.5e-06 to 3.75e-06
05/03/2022 14:21:36 - INFO - train -  No improvement since last 4 epochs, best score is 0.7878840630167988
05/03/2022 14:21:36 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:21:36 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:21:36 - INFO - train -  epoch 36/1000 - batch 1/63 - loss 0.9075303077697754 - samples/second: 48.58053820995313
05/03/2022 14:21:37 - INFO - train -  epoch 36/1000 - batch 7/63 - loss 0.9778638907841274 - samples/second: 55.290607275974914
05/03/2022 14:21:38 - INFO - train -  epoch 36/1000 - batch 13/63 - loss 0.7945667642813462 - samples/second: 49.84582755884493
05/03/2022 14:21:40 - INFO - train -  epoch 36/1000 - batch 19/63 - loss 0.7872995859698245 - samples/second: 42.17656219061844
05/03/2022 14:21:41 - INFO - train -  epoch 36/1000 - batch 25/63 - loss 0.8874148392677307 - samples/second: 43.94240630411536
05/03/2022 14:21:42 - INFO - train -  epoch 36/1000 - batch 31/63 - loss 1.0104436509070858 - samples/second: 44.653874062442945
05/03/2022 14:21:43 - INFO - train -  epoch 36/1000 - batch 37/63 - loss 1.0924647031603634 - samples/second: 44.738246333829395
05/03/2022 14:21:44 - INFO - train -  epoch 36/1000 - batch 43/63 - loss 1.1139186773189278 - samples/second: 43.95238994604256
05/03/2022 14:21:45 - INFO - train -  epoch 36/1000 - batch 49/63 - loss 1.1260895765557581 - samples/second: 43.87000068253073
05/03/2022 14:21:46 - INFO - train -  epoch 36/1000 - batch 55/63 - loss 1.1180747812444514 - samples/second: 44.53598152663924
05/03/2022 14:21:47 - INFO - train -  epoch 36/1000 - batch 61/63 - loss 1.1336666443308845 - samples/second: 44.70560157933177
05/03/2022 14:21:58 - INFO - train -  Finish evaluation: 11.019148588180542 s
05/03/2022 14:21:58 - INFO - train -  micro-avg: acc 0.6341325010639807 - micro-avg-f1-score 0.7761090372428161
05/03/2022 14:21:58 - INFO - train -  No improvement since last 5 epochs, best score is 0.7878840630167988
05/03/2022 14:21:58 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:21:58 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:21:59 - INFO - train -  epoch 37/1000 - batch 1/63 - loss 0.45810365676879883 - samples/second: 51.53047882461526
05/03/2022 14:22:00 - INFO - train -  epoch 37/1000 - batch 7/63 - loss 1.3693659816469466 - samples/second: 37.64978765182754
05/03/2022 14:22:01 - INFO - train -  epoch 37/1000 - batch 13/63 - loss 1.3092678418526282 - samples/second: 37.570336867915096
05/03/2022 14:22:02 - INFO - train -  epoch 37/1000 - batch 19/63 - loss 1.2361719671048617 - samples/second: 41.75986803148715
05/03/2022 14:22:03 - INFO - train -  epoch 37/1000 - batch 25/63 - loss 1.2005549335479737 - samples/second: 43.97982946416129
05/03/2022 14:22:04 - INFO - train -  epoch 37/1000 - batch 31/63 - loss 1.3459957568876204 - samples/second: 44.257861801130446
05/03/2022 14:22:05 - INFO - train -  epoch 37/1000 - batch 37/63 - loss 1.290152221112638 - samples/second: 44.50737607792944
05/03/2022 14:22:06 - INFO - train -  epoch 37/1000 - batch 43/63 - loss 1.2530039715212444 - samples/second: 43.51776840113737
05/03/2022 14:22:08 - INFO - train -  epoch 37/1000 - batch 49/63 - loss 1.305405821119036 - samples/second: 43.28417703755671
05/03/2022 14:22:09 - INFO - train -  epoch 37/1000 - batch 55/63 - loss 1.2886095783927225 - samples/second: 43.447665232759384
05/03/2022 14:22:10 - INFO - train -  epoch 37/1000 - batch 61/63 - loss 1.269232198840282 - samples/second: 43.6585294486843
05/03/2022 14:22:21 - INFO - train -  Finish evaluation: 11.052878141403198 s
05/03/2022 14:22:21 - INFO - train -  micro-avg: acc 0.6399829980164352 - micro-avg-f1-score 0.7804751619870411
05/03/2022 14:22:21 - INFO - train -  No improvement since last 6 epochs, best score is 0.7878840630167988
05/03/2022 14:22:21 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:22:21 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:22:21 - INFO - train -  epoch 38/1000 - batch 1/63 - loss 0.9111915826797485 - samples/second: 37.509090421298325
05/03/2022 14:22:23 - INFO - train -  epoch 38/1000 - batch 7/63 - loss 0.9264953477042062 - samples/second: 41.84448875674772
05/03/2022 14:22:24 - INFO - train -  epoch 38/1000 - batch 13/63 - loss 1.0948112561152532 - samples/second: 42.81599221041308
05/03/2022 14:22:25 - INFO - train -  epoch 38/1000 - batch 19/63 - loss 1.0318212446413542 - samples/second: 45.47314411053454
05/03/2022 14:22:25 - INFO - train -  epoch 38/1000 - batch 25/63 - loss 1.0728758668899536 - samples/second: 46.881711896769346
05/03/2022 14:22:27 - INFO - train -  epoch 38/1000 - batch 31/63 - loss 1.070473382549901 - samples/second: 45.76016674816228
05/03/2022 14:22:28 - INFO - train -  epoch 38/1000 - batch 37/63 - loss 1.032788154241201 - samples/second: 44.37693339077666
05/03/2022 14:22:29 - INFO - train -  epoch 38/1000 - batch 43/63 - loss 1.0820592031922451 - samples/second: 45.34287371519436
05/03/2022 14:22:30 - INFO - train -  epoch 38/1000 - batch 49/63 - loss 1.1482134059983857 - samples/second: 44.775841891553206
05/03/2022 14:22:31 - INFO - train -  epoch 38/1000 - batch 55/63 - loss 1.114794963056391 - samples/second: 45.44867835633776
05/03/2022 14:22:32 - INFO - train -  epoch 38/1000 - batch 61/63 - loss 1.1177175729001154 - samples/second: 45.15090642609599
05/03/2022 14:22:43 - INFO - train -  Finish evaluation: 10.680377721786499 s
05/03/2022 14:22:43 - INFO - train -  micro-avg: acc 0.6470588235294118 - micro-avg-f1-score 0.7857142857142857
05/03/2022 14:22:43 - INFO - train -  No improvement since last 7 epochs, best score is 0.7878840630167988
05/03/2022 14:22:43 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:22:43 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:22:43 - INFO - train -  epoch 39/1000 - batch 1/63 - loss 0.9900474548339844 - samples/second: 53.94256317921677
05/03/2022 14:22:45 - INFO - train -  epoch 39/1000 - batch 7/63 - loss 1.3656366467475891 - samples/second: 40.624991179046674
05/03/2022 14:22:46 - INFO - train -  epoch 39/1000 - batch 13/63 - loss 1.2470913254297697 - samples/second: 40.92739520536712
05/03/2022 14:22:47 - INFO - train -  epoch 39/1000 - batch 19/63 - loss 1.1761090033932735 - samples/second: 43.97230396991697
05/03/2022 14:22:48 - INFO - train -  epoch 39/1000 - batch 25/63 - loss 1.1311303496360778 - samples/second: 43.47355249989013
05/03/2022 14:22:49 - INFO - train -  epoch 39/1000 - batch 31/63 - loss 1.195536865342048 - samples/second: 44.48319167561516
05/03/2022 14:22:50 - INFO - train -  epoch 39/1000 - batch 37/63 - loss 1.2065949311127533 - samples/second: 43.47059677051593
05/03/2022 14:22:51 - INFO - train -  epoch 39/1000 - batch 43/63 - loss 1.2260981604110364 - samples/second: 42.16060958062097
05/03/2022 14:22:53 - INFO - train -  epoch 39/1000 - batch 49/63 - loss 1.224460554366209 - samples/second: 42.064944638797364
05/03/2022 14:22:54 - INFO - train -  epoch 39/1000 - batch 55/63 - loss 1.2181364872238853 - samples/second: 42.12004470148929
05/03/2022 14:22:55 - INFO - train -  epoch 39/1000 - batch 61/63 - loss 1.1588554196670406 - samples/second: 42.581950758212486
05/03/2022 14:23:06 - INFO - train -  Finish evaluation: 10.999309301376343 s
05/03/2022 14:23:06 - INFO - train -  micro-avg: acc 0.6405772966971968 - micro-avg-f1-score 0.7809169345288446
05/03/2022 14:23:06 - INFO - train -  change lr from 3.75e-06 to 1.875e-06
05/03/2022 14:23:06 - INFO - train -  No improvement since last 8 epochs, best score is 0.7878840630167988
05/03/2022 14:23:06 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:23:06 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:23:06 - INFO - train -  epoch 40/1000 - batch 1/63 - loss 0.598031759262085 - samples/second: 42.22425352849981
05/03/2022 14:23:08 - INFO - train -  epoch 40/1000 - batch 7/63 - loss 1.2303236893245153 - samples/second: 37.0537687468725
05/03/2022 14:23:09 - INFO - train -  epoch 40/1000 - batch 13/63 - loss 1.2778786695920503 - samples/second: 37.90008488706198
05/03/2022 14:23:10 - INFO - train -  epoch 40/1000 - batch 19/63 - loss 1.2367585113174038 - samples/second: 40.1280635267119
05/03/2022 14:23:11 - INFO - train -  epoch 40/1000 - batch 25/63 - loss 1.212923948764801 - samples/second: 40.697639329583616
05/03/2022 14:23:12 - INFO - train -  epoch 40/1000 - batch 31/63 - loss 1.2673494123643445 - samples/second: 41.894126917544455
05/03/2022 14:23:13 - INFO - train -  epoch 40/1000 - batch 37/63 - loss 1.31297830633215 - samples/second: 42.557124935410904
05/03/2022 14:23:15 - INFO - train -  epoch 40/1000 - batch 43/63 - loss 1.277496055115101 - samples/second: 41.03928339939975
05/03/2022 14:23:16 - INFO - train -  epoch 40/1000 - batch 49/63 - loss 1.2723259925842285 - samples/second: 41.5983320258853
05/03/2022 14:23:17 - INFO - train -  epoch 40/1000 - batch 55/63 - loss 1.254496437853033 - samples/second: 42.3538259071254
05/03/2022 14:23:18 - INFO - train -  epoch 40/1000 - batch 61/63 - loss 1.2426812472890636 - samples/second: 42.9543256598884
05/03/2022 14:23:29 - INFO - train -  Finish evaluation: 11.019644260406494 s
05/03/2022 14:23:29 - INFO - train -  micro-avg: acc 0.6485343855693348 - micro-avg-f1-score 0.7868011625918961
05/03/2022 14:23:29 - INFO - train -  No improvement since last 9 epochs, best score is 0.7878840630167988
05/03/2022 14:23:29 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:23:29 - INFO - train -  # sentences and augmented sentences: 500
05/03/2022 14:23:29 - INFO - train -  epoch 41/1000 - batch 1/63 - loss 1.4063129425048828 - samples/second: 37.86147801616263
05/03/2022 14:23:30 - INFO - train -  epoch 41/1000 - batch 7/63 - loss 1.4470697130475725 - samples/second: 40.55490358583347
05/03/2022 14:23:32 - INFO - train -  epoch 41/1000 - batch 13/63 - loss 1.3291364174622755 - samples/second: 38.15091598645028
05/03/2022 14:23:33 - INFO - train -  epoch 41/1000 - batch 19/63 - loss 1.2852663052709479 - samples/second: 38.644905771499445
05/03/2022 14:23:34 - INFO - train -  epoch 41/1000 - batch 25/63 - loss 1.1937265396118164 - samples/second: 40.25085771585357
05/03/2022 14:23:35 - INFO - train -  epoch 41/1000 - batch 31/63 - loss 1.210227337575728 - samples/second: 42.20791337769695
05/03/2022 14:23:36 - INFO - train -  epoch 41/1000 - batch 37/63 - loss 1.1333392085255802 - samples/second: 42.05552147039758
05/03/2022 14:23:37 - INFO - train -  epoch 41/1000 - batch 43/63 - loss 1.0791552344033883 - samples/second: 41.25117505219222
05/03/2022 14:23:38 - INFO - train -  epoch 41/1000 - batch 49/63 - loss 1.0552338142784274 - samples/second: 42.19820890922535
05/03/2022 14:23:39 - INFO - train -  epoch 41/1000 - batch 55/63 - loss 1.0616514054211703 - samples/second: 42.80392022611865
05/03/2022 14:23:41 - INFO - train -  epoch 41/1000 - batch 61/63 - loss 1.0998334845558542 - samples/second: 42.59426972509406
05/03/2022 14:23:52 - INFO - train -  Finish evaluation: 11.069740533828735 s
05/03/2022 14:23:52 - INFO - train -  micro-avg: acc 0.6477128782547502 - micro-avg-f1-score 0.7861962928162638
05/03/2022 14:23:52 - INFO - train -  No improvement since last 10 epochs, best score is 0.7878840630167988
05/03/2022 14:23:52 - INFO - train -  Early stop since no improvement since last 10 epochs
05/03/2022 14:23:52 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:23:52 - INFO - train -  Testing using best model ...
05/03/2022 14:24:03 - INFO - train -  Finish evaluation: 10.736923456192017 s
05/03/2022 14:24:04 - INFO - train -  micro-avg: acc 0.650007180812868 - micro-avg-f1-score 0.7878840630167988
05/03/2022 14:24:04 - INFO - train -  Class	TP	TP	FN	TN	Precision	Recall	F1
05/03/2022 14:24:04 - INFO - train -  LOC	1619	418	218	1619	0.7948	0.8813	0.8358
05/03/2022 14:24:04 - INFO - train -  MISC	413	254	509	413	0.6192	0.4479	0.5198
05/03/2022 14:24:04 - INFO - train -  ORG	823	257	518	823	0.7620	0.6137	0.6799
05/03/2022 14:24:04 - INFO - train -  PER	1671	92	171	1671	0.9478	0.9072	0.9270
05/03/2022 14:24:04 - INFO - train -  ----------------------------------------------------------------------------------------------------
05/03/2022 14:24:04 - INFO - train -  Testing using best model ...
05/03/2022 14:24:19 - INFO - train -  Finish evaluation: 14.909777879714966 s
05/03/2022 14:24:19 - INFO - train -  micro-avg: acc 0.6517503805175038 - micro-avg-f1-score 0.789163287873203
05/03/2022 14:24:19 - INFO - train -  Class	TP	TP	FN	TN	Precision	Recall	F1
05/03/2022 14:24:19 - INFO - train -  LOC	1473	336	195	1473	0.8143	0.8831	0.8473
05/03/2022 14:24:19 - INFO - train -  MISC	311	195	391	311	0.6146	0.4430	0.5149
05/03/2022 14:24:19 - INFO - train -  ORG	1086	297	575	1086	0.7852	0.6538	0.7135
05/03/2022 14:24:19 - INFO - train -  PER	1412	94	205	1412	0.9376	0.8732	0.9043
05/06/2022 22:21:48 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=['LwTR'], data_folder='data', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=8, log_filepath='development.log', lr=3e-05, max_epochs=1000, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='lwtr.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=8, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/06/2022 22:21:49 - INFO - data -  Load 100 sentences from data/train.txt
05/06/2022 22:21:49 - INFO - data -  Load 3465 sentences from data/dev.txt
05/06/2022 22:21:49 - INFO - data -  Load 3683 sentences from data/test.txt
05/06/2022 22:41:38 - INFO - __main__ -  CONFIG: "Namespace(anneal_factor=0.5, anneal_patience=3, augmentation=['LwTR'], data_folder='data', debug=False, dev_filepath='data/dev.txt', device=0, dropout=0.4, early_stop_patience=10, embedding_type='bert', eval_bs=8, log_filepath='development.log', lr=3e-05, max_epochs=1000, min_lr=1e-08, num_generated_samples=1, optimizer='adam', output_dir='development', p_power=1.0, pretrained_dir='bert-base-uncased', replace_ratio=0.3, result={}, result_filepath='lwtr.json', seed=52, task_name='development', test_filepath='data/test.txt', train_bs=8, train_filepath='data/train.txt', variational_dropout=0.5, word_dropout=0.05)"
05/06/2022 22:41:39 - INFO - data -  Load 100 sentences from data/train.txt
05/06/2022 22:41:39 - INFO - data -  Load 3465 sentences from data/dev.txt
05/06/2022 22:41:40 - INFO - data -  Load 3683 sentences from data/test.txt
